[{"_path":"/news","_dir":"","_draft":false,"_partial":false,"_locale":"","title":"News","description":"","leadingImage":"me-news-google.png","disableFancyImage":true,"body":{"type":"root","children":[{"type":"element","tag":"MarkdownHeader","props":{"subtitle":"üì¢ Latest: I'm a Ph.D. candidate now!","title":"News"},"children":[]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"03/31/2023"}]},{"type":"text","value":" üéâ We have released the "},{"type":"element","tag":"a","props":{"href":"https://github.com/cake-lab/LitAR","rel":["nofollow"]},"children":[{"type":"text","value":"code"}]},{"type":"text","value":" of our UbiComp 2022 paper LitAR."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"12/15/2022"}]},{"type":"text","value":" üéâ Received student travel grant from HotMobile 2023, thank you!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"12/15/2022"}]},{"type":"text","value":" üéâ Passed my classes and research qualifications, I'm a Ph.D. candidate now!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"12/09/2022"}]},{"type":"text","value":" üéâ One paper accepted by HotMobile 2023!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"01/18/2022"}]},{"type":"text","value":" üéâ I joined the "},{"type":"element","tag":"a","props":{"href":"http://www.chongyangma.com/team/index.html","rel":["nofollow"]},"children":[{"type":"text","value":"Y-tech Graphics AI team"}]},{"type":"text","value":" as a research intern."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"05/17/2022"}]},{"type":"text","value":" üéâ Our paper "},{"type":"element","tag":"a","props":{"href":"/project/litar"},"children":[{"type":"text","value":"LitAR"}]},{"type":"text","value":" is accepted by UbiComp 2022!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"05/17/2022"}]},{"type":"text","value":" üéâ Our paper "},{"type":"element","tag":"a","props":{"href":"/project/privacy-preserving-reflection"},"children":[{"type":"text","value":"Privacy-preserving Reflection Rendering for Augmented Reality"}]},{"type":"text","value":" is accepted by ACM MM 2022!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"03/04/2022"}]},{"type":"text","value":" üéâ I will join Google as a research intern in the summer!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"01/18/2022"}]},{"type":"text","value":" üéâ I joined the "},{"type":"element","tag":"a","props":{"href":"http://www.chongyangma.com/team/index.html","rel":["nofollow"]},"children":[{"type":"text","value":"Y-tech Graphics AI team"}]},{"type":"text","value":" as a research intern."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"05/24/2021"}]},{"type":"text","value":" ‚ú® We just released the "},{"type":"element","tag":"a","props":{"href":"/project/point-ar"},"children":[{"type":"text","value":"Xihe"}]},{"type":"text","value":" source code! Check our "},{"type":"element","tag":"a","props":{"href":"https://github.com/cake-lab/Xihe","rel":["nofollow"]},"children":[{"type":"text","value":"GitHub"}]},{"type":"text","value":" repo."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"04/15/2021"}]},{"type":"text","value":" üéâ I will join the "},{"type":"element","tag":"a","props":{"href":"http://chongyangma.com/team/index.html","rel":["nofollow"]},"children":[{"type":"text","value":"Y-tech Graphics AI team"}]},{"type":"text","value":" as a research intern in next spring!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"04/15/2021"}]},{"type":"text","value":" üéâ I'm thrilled to announce that I will continue my Ph.D. study at "},{"type":"element","tag":"a","props":{"href":"https://cake.wpi.edu/","rel":["nofollow"]},"children":[{"type":"text","value":"The Cake Lab"}]},{"type":"text","value":" with "},{"type":"element","tag":"a","props":{"href":"https://tianguo.info","rel":["nofollow"]},"children":[{"type":"text","value":"Prof. Tian Guo"}]},{"type":"text","value":"."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"04/15/2021"}]},{"type":"text","value":" üéâ I've presented my M.S. Thesis."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"04/03/2021"}]},{"type":"text","value":" ‚ú® "},{"type":"element","tag":"a","props":{"href":"/project/point-ar"},"children":[{"type":"text","value":"PointAR"}]},{"type":"text","value":" source code is now released! Check our "},{"type":"element","tag":"a","props":{"href":"https://github.com/cake-lab/PointAR","rel":["nofollow"]},"children":[{"type":"text","value":"GitHub"}]},{"type":"text","value":" repo."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"03/25/2021"}]},{"type":"text","value":" üî• New paper on mobile system for 3D vision-based lighting estimation has been conditionally accepted to MobiSys 2021."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"08/25/2020"}]},{"type":"text","value":" üéôÔ∏è I presented our efficient mobile AR lighting estimation paper at ECCV 2020."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"07/22/2020"}]},{"type":"text","value":" üî• Our paper on efficient mobile AR lighting estimation neural network has been accepted to ECCV 2020."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"03/03/2020"}]},{"type":"text","value":" üéôÔ∏è I presented my poster at the HotMobile 2020 conference in Austin, TX."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"02/01/2020"}]},{"type":"text","value":" üî• Our poster on mobile AR lighting estimation has been accepted to HotMobile 2020."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"08/26/2019"}]},{"type":"text","value":" ü¶∏üèª‚Äç‚ôÇÔ∏è I joined Worcester Polytechnic Institute CakeLab."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"10/26/2018"}]},{"type":"text","value":" üéôÔ∏è I presented our paper on ASMMC-MMAC 2018 workshop."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"10/15/2018"}]},{"type":"text","value":" üèÜ I received Wang Kechang Technology innovation scholarship (<1%)."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"10/13/2018"}]},{"type":"text","value":" üèÜ I received annual special scholarship at Tianjin Normal University (top 5%)."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"08/15/2018"}]},{"type":"text","value":" üî• Our paper about human speech emotion in spectrogram representation has submitted to ACM Multimedia 2018 ASMMC-MMAC workshop!"}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"07/04/2018"}]},{"type":"text","value":" üë®üèª‚Äçüíª I joined the DuerOS department at Baidu, Inc as a frontend software engineer intern."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"09/30/2017"}]},{"type":"text","value":" üèÜ Ô£ø I received third prize of the 2017 China national Mobile Innovation Contest (top 6%)."}]},{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"strong","props":{},"children":[{"type":"text","value":"09/30/2016"}]},{"type":"text","value":" üèÜ Ô£ø I received third prize of the 2016 China national Mobile Innovation Contest (top 10%)."}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:news.md","_source":"content","_file":"news.md","_extension":"md"},{"_path":"/research","_dir":"","_draft":false,"_partial":false,"_locale":"","title":"Research","description":"","body":{"type":"root","children":[{"type":"element","tag":"MarkdownHeader","props":{"title":"Research Statement"},"children":[]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"I'm a computer science Ph.D. candidate at "},{"type":"element","tag":"a","props":{"href":"https://wpi.edu","rel":["nofollow"]},"children":[{"type":"text","value":"Worcester Polytechnic Institute"}]},{"type":"text","value":" and a member of "},{"type":"element","tag":"a","props":{"href":"https://cake.wpi.edu","rel":["nofollow"]},"children":[{"type":"text","value":"TheCakeLab"}]},{"type":"text","value":".\nMy research interest lies in ubiquitous computing, augmented reality, and computer vision.\nMy recent research projects have a strong focus on improving photorealism in mobile AR by developing novel environment lighting sensing systems.\nThe insights of my research are mainly derived from the investigation of mobile device dynamics, physical modeling of spatial transformations, and data-driven studies.\nIn the past, I have designed machine learning models and real-time systems for mobile AR environment lighting estimation.\nI‚Äôm also interested in security and privacy issues associated with photorealism in AR.\nI‚Äôm fortunate to have conducted my research works in these areas under the guidance of Prof. Tian Guo alongside many wonderful collaborators, and I‚Äôm passionate to continue studying these problems in my Ph.D."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Designing visual sensing systems has been a long-standing research topic for ubiquitous computing, mobile computing and computer vision.\nIn recent years, emerging AR applications raise new standards for environment sensing on mobile devices to satisfy the crave of increasing demand of photorealism and interactivity.\nLighting estimation, a task that aims to estimate omnidirectional lighting from limited environment observations, is at the key position of pursuing photorealistic and visually coherent rendering in AR.\nTraditionally, high-quality environment lighting is acquired using physical devices like light probes or 360¬∞ cameras.\nSuch physical approach has satisfied the needs of professional many users from filming industries and computer graphics researchers.\nHowever, the data acquisition process could be expensive and impractical for mobile AR applications."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"On a different vein, learning-based lighting estimation models have been adopted by the majority of AR frameworks in favor of their abilities to estimate environment lighting from single or multiple camera images.\nHowever, in complex real-world scenarios, such models often fail to adapt, as estimating 360¬∞ environment lighting from a low FoV camera image is a highly unconstrained task.\nThe deployment time difficulties challenges the traditional definition of lighting estimation, which aims to use image color and structure clues to estimate the environment lighting.\nMy past research has focused on leveraging user, device and environment dynamics to opportunistically generate lighting without interrupting user's application interaction."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"Check out my research project details "},{"type":"element","tag":"a","props":{"href":"/project/"},"children":[{"type":"text","value":"here"}]},{"type":"text","value":"."}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"em","props":{},"children":[{"type":"text","value":"I'm generally interested in collaborating with ubiquitous computing and machine learning projects related to AR/VR. If you share the same interests, "},{"type":"element","tag":"a","props":{"href":"mailto:yzhao11@wpi.edu"},"children":[{"type":"text","value":"please shoot me an email"}]},{"type":"text","value":"!"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[]}},"_type":"markdown","_id":"content:research.md","_source":"content","_file":"research.md","_extension":"md"}]
<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Home - Yiqin Zhao</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
<meta name="og:title" content="Home"><link rel="modulepreload" href="/_payload.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.1b6408d7.js"><link rel="preload" as="style" href="/_nuxt/entry.bc2958a6.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/query.5d7015b2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/query.bd53ac81.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/content.42ec3fb4.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.11dea0df.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.7958927d.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.90901a92.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.50598109.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_commonjsHelpers.0ee3bad0.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.05f8ba68.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/layout.28cf89de.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.d08b4b96.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.d50c958a.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.f587897a.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/qin-logo.ef293eae.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.7f085b8b.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.7631ac34.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.4618626e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/IndexHeader.4895a05e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.c27b6911.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.1121f5c1.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.872cb6fd.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseEm.0a7db5f8.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.89014535.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ShortNews.cc95d421.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ExperienceRow.2f41c222.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentSlot.a9c862e3.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.17cbe3da.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/PublicationRow.f724f577.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.7cb64d63.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.c819225a.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContactItem.e71548ac.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.59f6939b.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseImg.fd796330.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentNavigation.9f74c3c4.js"><link rel="prefetch" as="style" href="/_nuxt/ContentNavigation.2ce1c5fc.css"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.35d10298.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/Markdown.e6f32ff5.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ProseCode.10f91dc8.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.0fda1da3.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.f6dd7934.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.3a734749.js"><link rel="stylesheet" href="/_nuxt/entry.bc2958a6.css"><style>body{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}.dark body{--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><!--[--><div class="document-driven-page"><!--[--><!--[--><!--[--><div class="bg-transparent dark:bg-transparent hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class="opacity-0"><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/research/"><span class="transition-border hover:border-b-2 border-b-gray-400">Research</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/project/"><span class="transition-border hover:border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="hover:text-white transition-color py-3" href="/"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">Home</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/research/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Research</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/project/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Projects</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><div class="mb-16"><div class="container md:w-[140%] md:ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><div class="w-[55%] hidden md:flex flex-col items-center justify-start shadow-lg p-12 py-8 z-20 h-fit absolute left-0 bg-neutral-100 dark:bg-neutral-700 bottom-16"><p class="w-full text-6xl py-4 m-0">Yiqin Zhao</p><p class="w-full text-xl pl-3 prose dark:prose-invert m-0"> Ëµµ‰∏ÄÂã§ | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https://arvr.google.com">@GoogleARVR</a> <br> Research: Mobile System, AR, CV, CG </p><p class="mt-4 w-full pl-3 m-0"><span class="m-0"><a href="mailto:yiqinzhao@outlook.com"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/email.svg" alt=""></a><a href="https://github.com/YiqinZhao"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/github.svg" alt=""></a><a href="https://twitter.com/yiqin_zhao"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/twitter.svg" alt=""></a><a href="https://www.instagram.com/yiqinzhao1996"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/instagram.svg" alt=""></a></span></p></div><img class="w-full md:w-1/2 shadow-lg my-0 md:my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""><div class="absolute h-full w-[75%] left-0 z-[-1]"></div><img class="hidden md:block absolute w-3/5 top-[-8rem] left-[-5rem] dark:invert z-[-1] opacity-30" src="/assets/img/qin-logo.svg" alt=""></div></div><div class="hidden md:block w-full h-fit p-0 m-0 absolute mx-auto top-0 left-0 z-[-2] bg-neutral-200 dark:bg-neutral-800"><div class="max-w-prose mt-[3.4rem] opacity-0"><div class="container w-[140%] ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><img class="w-full md:w-1/2 shadow-lg my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""></div></div></div></div></div><h2 id="Ô∏è-about-me"><a href="#Ô∏è-about-me"><!--[-->ü¶∏üèª‚Äç‚ôÇÔ∏è About Me<!--]--></a></h2><p><!--[-->üîä <em><!--[-->My name pounces as: Yi-Chin<!--]--></em><!--]--></p><p><!--[-->I am a fourth-year Computer Science M.S./Ph.D. student at <a href="https://wpi.edu" rel="nofollow"><!--[-->Worcester Polytechnic Institute (WPI)<!--]--></a> and a proud member of <a href="https://cake-lab.github.io" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> research group.
I feel extremely fortunate to be advised by my kind and wise advisor <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.
I am interested in designing system supports and optimizations for Augmented Reality (AR) applications.
My recent research has a strong focus on designing system support for AR environment lighting understanding and photorealistic rendering.<!--]--></p><p><!--[-->Prior to WPI, I obtained my Bachelor&#39;s degree in Software Engineering from <a href="https://tjnu.edu.cn" rel="nofollow"><!--[-->Tianjin Normal University (TJNU)<!--]--></a>, Tianjin, China in 2019.
During my undergraduate study, I worked with <a href="https://www.researchgate.net/profile/Ziping-Zhao-2" rel="nofollow"><!--[-->Prof. Ziping Zhao<!--]--></a> on audio signal processing, speech emotion recognition, and affective computing.
In the past, I interned at <a href="https://baidu.com" rel="nofollow"><!--[-->Baidu<!--]--></a> (Summer 2018), <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Kuaishou Y-tech Graphics AI team<!--]--></a> in Spring 2022, and <a href="https://arvr.google.com" rel="nofollow"><!--[-->GoogleARVR<!--]--></a> in Summer/Fall 2022.<!--]--></p><h2 id="news"><a href="#news"><!--[-->üì∞ News<!--]--></a></h2><div class="[&amp;_li:nth-of-type(1n+7)]:hidden [&amp;_img]:hidden [&amp;_h1]:hidden [&amp;_h2]:hidden"><!--[--><div><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">News</h1><h2 class="dark:text-gray-200 text-center text-xl font-normal my-6 max-w-4xl mx-auto">üì¢ Latest: I&#39;m a Ph.D. candidate now!</h2><!--]--><p><!--[--><img src="/assets/img/me-news-google.png" alt><!--]--></p><ul><!--[--><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> üéâ Received student travel grant from HotMobile 2023, thank you!<!--]--></li><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> üéâ Passed my classes and research qualifications, I&#39;m a Ph.D. candidate now!<!--]--></li><li><!--[--><strong><!--[-->12/09/2022<!--]--></strong> üéâ One paper accepted by HotMobile 2023!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> üéâ I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> üéâ Our paper <a href="/project/litar" class=""><!--[-->LitAR<!--]--></a> is accepted by UbiComp 2022!<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> üéâ Our paper <a href="/project/privacy-preserving-reflection" class=""><!--[-->Privacy-preserving Reflection Rendering for Augmented Reality<!--]--></a> is accepted by ACM MM 2022!<!--]--></li><li><!--[--><strong><!--[-->03/04/2022<!--]--></strong> üéâ I will join Google as a research intern in the summer!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> üéâ I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/24/2021<!--]--></strong> ‚ú® We just released the <a href="/project/point-ar" class=""><!--[-->Xihe<!--]--></a> source code! Check our <a href="https://github.com/cake-lab/Xihe" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> üéâ I will join the <a href="http://chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern in next spring!<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> üéâ I&#39;m thrilled to announce that I will continue my Ph.D. study at <a href="https://cake.wpi.edu/" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> with <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> üéâ I&#39;ve presented my M.S. Thesis.<!--]--></li><li><!--[--><strong><!--[-->04/03/2021<!--]--></strong> ‚ú® <a href="/project/point-ar" class=""><!--[-->PointAR<!--]--></a> source code is now released! Check our <a href="https://github.com/cake-lab/PointAR" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->03/25/2021<!--]--></strong> üî• New paper on mobile system for 3D vision-based lighting estimation has been conditionally accepted to MobiSys 2021.<!--]--></li><li><!--[--><strong><!--[-->08/25/2020<!--]--></strong> üéôÔ∏è I presented our efficient mobile AR lighting estimation paper at ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->07/22/2020<!--]--></strong> üî• Our paper on efficient mobile AR lighting estimation neural network has been accepted to ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->03/03/2020<!--]--></strong> üéôÔ∏è I presented my poster at the HotMobile 2020 conference in Austin, TX.<!--]--></li><li><!--[--><strong><!--[-->02/01/2020<!--]--></strong> üî• Our poster on mobile AR lighting estimation has been accepted to HotMobile 2020.<!--]--></li><li><!--[--><strong><!--[-->08/26/2019<!--]--></strong> ü¶∏üèª‚Äç‚ôÇÔ∏è I joined Worcester Polytechnic Institute CakeLab.<!--]--></li><li><!--[--><strong><!--[-->10/26/2018<!--]--></strong> üéôÔ∏è I presented our paper on ASMMC-MMAC 2018 workshop.<!--]--></li><li><!--[--><strong><!--[-->10/15/2018<!--]--></strong> üèÜ I received Wang Kechang Technology innovation scholarship (&lt;1%).<!--]--></li><li><!--[--><strong><!--[-->10/13/2018<!--]--></strong> üèÜ I received annual special scholarship at Tianjin Normal University (top 5%).<!--]--></li><li><!--[--><strong><!--[-->08/15/2018<!--]--></strong> üî• Our paper about human speech emotion in spectrogram representation has submitted to ACM Multimedia 2018 ASMMC-MMAC workshop!<!--]--></li><li><!--[--><strong><!--[-->07/04/2018<!--]--></strong> üë®üèª‚Äçüíª I joined the DuerOS department at Baidu, Inc as a frontend software engineer intern.<!--]--></li><li><!--[--><strong><!--[-->09/30/2017<!--]--></strong> üèÜ Ô£ø I received third prize of the 2017 China national Mobile Innovation Contest (top 6%).<!--]--></li><li><!--[--><strong><!--[-->09/30/2016<!--]--></strong> üèÜ Ô£ø I received third prize of the 2016 China national Mobile Innovation Contest (top 10%).<!--]--></li><!--]--></ul></div><!--]--></div><p><!--[--><a href="/news/" class=""><!--[-->More news &gt;&gt;&gt;<!--]--></a><!--]--></p><h2 id="experiences"><a href="#experiences"><!--[-->ü•∑ Experiences<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-google.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/google.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Google, Mountain View, CA<!--]--></strong><br>
Student Researcher<br>
May 2022 - Present<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-wpi.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/wpi.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Worcester Polytechnic Institute, Worcester, MA<!--]--></strong><br>
Ph.D. Student in <a href="https://cake.wpi.edu" rel="nofollow"><!--[-->TheCakeLab<!--]--></a>, advised by <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a><br>
Aug 2021 - Dec, 2022<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-kuaishou.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/kuaishou.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Kuaishou Technology, Palo Alto, CA<!--]--></strong><br>
Research Intern<br>
Jan, 2022 - May, 2022<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-baidu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/baidu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Baidu, Beijing, China<!--]--></strong><br>
Software Engineering Intern<br>
Jun, 2018 - Sept, 2018<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-tjnu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/tjnu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Tianjin Normal University, Tianjin, China<!--]--></strong><br>
Bachelor of Engineering in Software Engineering<br>
Sept, 2015 - Jun, 2019<!--]--></p><!--]--><!--]--></div></div><h2 id="publications"><a href="#publications"><!--[-->üìÑ Publications<!--]--></a></h2><div class="flex flex-col md:flex-row py-2 items-start my-5" type="conference"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/dual-light-hotmobile2023.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality</div><div class="pt-1"><!--[--><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Sean Fanello, </span><span class="">Tian Guo</span><!--]--></div><div>The Twenty-fourth International Workshop on Mobile Computing Systems and Applications <b>(HotMobile&#39;23)</b></div><div><!--[--><span><a href="https://arxiv.org/pdf/2301.06143.pdf">[Paper]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="journal"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/litar-ubicomp22.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">LitAR: Visually Coherent Lighting for Mobile Augmented Reality</div><div class="pt-1"><!--[--><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Chongyang Ma, </span><span class="">Haibin Huang, </span><span class="">Tian Guo</span><!--]--></div><div>The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies <b>(IMWUT&#39;22)</b></div><div><!--[--><span><a href="https://arxiv.org/pdf/2301.06184.pdf">[Paper]</a><span>, </span></span><span><a href="/project/litar/">[Code (coming soon)]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="conference"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/privacy-preserving-reflection.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">Privacy-preserving Reflection Rendering for Augmented Reality</div><div class="pt-1"><!--[--><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Sheng Wei, </span><span class="">Tian Guo</span><!--]--></div><div>30th ACM International Conference on Multimedia <b>(ACMMM&#39;22)</b></div><div><!--[--><span><a href="https://arxiv.org/abs/2207.03056">[paper]</a><span>, </span></span><span><a href="/project/privacy-preserving-reflection">[project]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="workshop"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/fusedar-ieeevrw22.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering</div><div class="pt-1"><!--[--><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Tian Guo</span><!--]--></div><div>IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW) <b>(IEEEVRW&#39;22)</b></div><div><!--[--><span><a href="https://ieeexplore.ieee.org/document/9757380">[paper]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="conference"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/xihe-mobisys2021.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality</div><div class="pt-1"><!--[--><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Tian Guo</span><!--]--></div><div>The 19th ACM International Conference on Mobile Systems, Applications, and Services <b>(MobiSys&#39;21)</b></div><div><!--[--><span><a href="https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290">[paper]</a><span>, </span></span><span><a href="/project/xihe/">[project]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="conference"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/pointar-eccv.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">PointAR: Efficient Lighting Estimation for Mobile Augmented Reality</div><div class="pt-1"><!--[--><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Tian Guo</span><!--]--></div><div>16th European Conference on Computer Vision <b>(ECCV&#39;20)</b></div><div><!--[--><span><a href="https://arxiv.org/abs/2004.00006">[paper]</a><span>, </span></span><span><a href="/project/point-ar/">[project]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="journal"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/deep-spectrum-ieee.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition</div><div class="pt-1"><!--[--><span class="">Ziping Zhao, </span><span class="">Zhongtian Bao, </span><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Zixing Zhang, </span><span class="">Nicholas Cummins, </span><span class="">Zhao Ren, </span><span class="">Bj√∂rn Schuller</span><!--]--></div><div>IEEE Access <b>(Access&#39;19)</b></div><div><!--[--><span><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126">[paper]</a><span>, </span></span><span><a href="/project/deep-spectrum/">[project]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="conference"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/deep-spectrum-acmmm.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">Deep Spectrum Feature Representations for Speech Emotion Recognition</div><div class="pt-1"><!--[--><span class="">Ziping Zhao, </span><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Zhongtian Bao, </span><span class="">Haishuai Wang, </span><span class="">Zixing Zhang, </span><span class="">Chao Li</span><!--]--></div><div>4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data <b>(ASMMC-MMAC&#39;18)</b></div><div><!--[--><span><a href="https://dl.acm.org/citation.cfm?doid=3267935.3267948">[paper]</a><span>, </span></span><span><a href="/project/deep-spectrum/">[project]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><div class="flex flex-col md:flex-row py-2 items-start my-5" type="conference"><img class="mr-4 w-full md:w-32 my-2" src="/assets/img/publications/deep-spectrum-interspeech.png" alt=""><div class="prose dark:prose-invert max-w-none font-normal"><div class="dark:text-white font-bold mt-2 md:mt-0 md:text-lg">Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition</div><div class="pt-1"><!--[--><span class="">Ziping Zhao, </span><span class="">Yu Zheng, </span><span class="">Zixing Zhang, </span><span class="">Haishuai Wang, </span><span class="font-bold dark:text-white">Yiqin Zhao, </span><span class="">Chao Li</span><!--]--></div><div>Annual Conference of the International Speech Communication Association <b>(INTERSPEECH&#39;18)</b></div><div><!--[--><span><a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1477.pdf">[paper]</a><span>, </span></span><span><a href="/project/deep-spectrum/">[project]</a><span></span></span><!--]--></div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div><h2 id="Ô∏è-services-and-awards"><a href="#Ô∏è-services-and-awards"><!--[-->‚ù§Ô∏è Services and Awards<!--]--></a></h2><p><!--[--><strong><!--[-->Academic services<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->UbiComp 2022 student volunteer.<!--]--></li><!--]--></ul><p><!--[--><strong><!--[-->Awards<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->ACM HotMobile 2023 Student Travel Grant.<!--]--></li><li><!--[-->ACM HotMobile 2020 Student Travel Grant.<!--]--></li><li><!--[-->China Collegiate Computing Contest, jointly held by Tsinghua University, Zhejiang University and Apple, Inc.<ul><!--[--><li><!--[-->2017 national third prize, top 6%<!--]--></li><li><!--[-->2016 national third prize, top 10%<!--]--></li><!--]--></ul><!--]--></li><li><!--[-->University Scholarship, Tianjin Normal University<ul><!--[--><li><!--[-->2018 - 2019 academic first grade scholarship, top 10%<!--]--></li><li><!--[-->Wang Kechang Culture and Technology Innovation Scholarship, ‚â§ 1%<!--]--></li><li><!--[-->2017 - 2018 academic year top grade scholarship, top 5%<!--]--></li><li><!--[-->2016 - 2017 academic year second grade scholarship, top 20%<!--]--></li><li><!--[-->2015 - 2016 academic year first grade scholarship, top 10%<!--]--></li><!--]--></ul><!--]--></li><!--]--></ul><h2 id="contacts"><a href="#contacts"><!--[-->üìß Contacts<!--]--></a></h2><span><a href="mailto:yiqinzhao@outlook.com" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/email.svg" alt=""><!--[-->Email<!--]--></a></span><span><a href="https://github.com/YiqinZhao" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/github.svg" alt=""><!--[-->GitHub<!--]--></a></span><span><a href="https://twitter.com/yiqin_zhao" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/twitter.svg" alt=""><!--[-->Twitter<!--]--></a></span><span><a href="https://www.instagram.com/yiqinzhao1996" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/instagram.svg" alt=""><!--[-->Instagram<!--]--></a></span></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> Ëµµ‰∏ÄÂã§ | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. Candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https//arvr.google.com">@GoogleVRAR</a> <br> Research Interests: Mobile System, AR, CV, CG </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:yiqinzhao@outlook.com">E-Mail</a> <br><a href="https://github.com/YiqinZhao">GitHub</a> <br><a href="https://twitter.com/yiqin_zhao">Twitter</a> <br><a href="https://www.instagram.com/yiqinzhao1996">Instagram</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> ¬© <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2023. Last updated: 1/30/2023. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div></div><!--]--><!--]--></div><!--]--><!--]--></div><script type="module">import p from "/_payload.js";window.__NUXT__={...p,...((function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V){return {state:{"$scolor-mode":{preference:v,value:v,unknown:i,forced:f},"$sdd-pages":{"/":{_path:t,_dir:k,_draft:f,_partial:f,_locale:w,_empty:f,title:x,description:k,hideTitle:i,disableFancyImage:i,body:{type:"root",children:[{type:a,tag:"index-header",props:{},children:[]},{type:a,tag:o,props:{id:y},children:[{type:b,value:z}]},{type:a,tag:c,props:{},children:[{type:b,value:"üîä "},{type:a,tag:"em",props:{},children:[{type:b,value:"My name pounces as: Yi-Chin"}]}]},{type:a,tag:c,props:{},children:[{type:b,value:"I am a fourth-year Computer Science M.S.\u002FPh.D. student at "},{type:a,tag:e,props:{href:"https:\u002F\u002Fwpi.edu",rel:[g]},children:[{type:b,value:"Worcester Polytechnic Institute (WPI)"}]},{type:b,value:" and a proud member of "},{type:a,tag:e,props:{href:"https:\u002F\u002Fcake-lab.github.io",rel:[g]},children:[{type:b,value:"The Cake Lab"}]},{type:b,value:" research group.\nI feel extremely fortunate to be advised by my kind and wise advisor "},{type:a,tag:e,props:{href:A,rel:[g]},children:[{type:b,value:B}]},{type:b,value:".\nI am interested in designing system supports and optimizations for Augmented Reality (AR) applications.\nMy recent research has a strong focus on designing system support for AR environment lighting understanding and photorealistic rendering."}]},{type:a,tag:c,props:{},children:[{type:b,value:"Prior to WPI, I obtained my Bachelor's degree in Software Engineering from "},{type:a,tag:e,props:{href:"https:\u002F\u002Ftjnu.edu.cn",rel:[g]},children:[{type:b,value:"Tianjin Normal University (TJNU)"}]},{type:b,value:", Tianjin, China in 2019.\nDuring my undergraduate study, I worked with "},{type:a,tag:e,props:{href:"https:\u002F\u002Fwww.researchgate.net\u002Fprofile\u002FZiping-Zhao-2",rel:[g]},children:[{type:b,value:"Prof. Ziping Zhao"}]},{type:b,value:" on audio signal processing, speech emotion recognition, and affective computing.\nIn the past, I interned at "},{type:a,tag:e,props:{href:"https:\u002F\u002Fbaidu.com",rel:[g]},children:[{type:b,value:"Baidu"}]},{type:b,value:" (Summer 2018), "},{type:a,tag:e,props:{href:"http:\u002F\u002Fwww.chongyangma.com\u002Fteam\u002Findex.html",rel:[g]},children:[{type:b,value:"Kuaishou Y-tech Graphics AI team"}]},{type:b,value:" in Spring 2022, and "},{type:a,tag:e,props:{href:"https:\u002F\u002Farvr.google.com",rel:[g]},children:[{type:b,value:"GoogleARVR"}]},{type:b,value:" in Summer\u002FFall 2022."}]},{type:a,tag:o,props:{id:C},children:[{type:b,value:D}]},{type:a,tag:"short-news",props:{},children:[]},{type:a,tag:c,props:{},children:[{type:a,tag:e,props:{href:"\u002Fnews\u002F"},children:[{type:b,value:"More news \u003E\u003E\u003E"}]}]},{type:a,tag:o,props:{id:E},children:[{type:b,value:F}]},{type:a,tag:q,props:{icon:"google.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Google, Mountain View, CA"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nStudent Researcher"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nMay 2022 - Present"}]}]},{type:a,tag:q,props:{icon:"wpi.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Worcester Polytechnic Institute, Worcester, MA"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nPh.D. Student in "},{type:a,tag:e,props:{href:"https:\u002F\u002Fcake.wpi.edu",rel:[g]},children:[{type:b,value:"TheCakeLab"}]},{type:b,value:", advised by "},{type:a,tag:e,props:{href:A,rel:[g]},children:[{type:b,value:B}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nAug 2021 - Dec, 2022"}]}]},{type:a,tag:q,props:{icon:"kuaishou.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Kuaishou Technology, Palo Alto, CA"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nResearch Intern"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nJan, 2022 - May, 2022"}]}]},{type:a,tag:q,props:{icon:"baidu.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Baidu, Beijing, China"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nSoftware Engineering Intern"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nJun, 2018 - Sept, 2018"}]}]},{type:a,tag:q,props:{icon:"tjnu.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Tianjin Normal University, Tianjin, China"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nBachelor of Engineering in Software Engineering"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nSept, 2015 - Jun, 2019"}]}]},{type:a,tag:o,props:{id:G},children:[{type:b,value:H}]},{type:a,tag:j,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2301.06143.pdf\"}",":authors":"[\"Yiqin Zhao\",\"Sean Fanello\",\"Tian Guo\"]",":venue":"{\"acronym\":\"HotMobile\",\"year\":2023,\"name\":\"The Twenty-fourth International Workshop on Mobile Computing Systems and Applications\"}",thumbnail:"dual-light-hotmobile2023.png",title:"Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality",type:p},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2301.06184.pdf\",\"Code (coming soon)\":\"\u002Fproject\u002Flitar\u002F\"}",":authors":"[\"Yiqin Zhao\",\"Chongyang Ma\",\"Haibin Huang\",\"Tian Guo\"]",":venue":"{\"acronym\":\"IMWUT\",\"year\":2022,\"name\":\"The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\"}",thumbnail:"litar-ubicomp22.png",title:I,type:J},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"paper\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2207.03056\",\"project\":\"\u002Fproject\u002Fprivacy-preserving-reflection\"}",":authors":"[\"Yiqin Zhao\",\"Sheng Wei\",\"Tian Guo\"]",":venue":"{\"acronym\":\"ACMMM\",\"year\":2022,\"name\":\"30th ACM International Conference on Multimedia\"}",thumbnail:"privacy-preserving-reflection.png",title:K,type:p},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"paper\":\"https:\u002F\u002Fieeexplore.ieee.org\u002Fdocument\u002F9757380\"}",":authors":u,":venue":"{\"acronym\":\"IEEEVRW\",\"year\":2022,\"name\":\"IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\"}",thumbnail:"fusedar-ieeevrw22.png",title:"FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering",type:"workshop"},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3458864.3467886?cid=99659479290\",\"project\":\"\u002Fproject\u002Fxihe\u002F\"}",":authors":u,":venue":"{\"acronym\":\"MobiSys\",\"year\":2021,\"name\":\"The 19th ACM International Conference on Mobile Systems, Applications, and Services\"}",thumbnail:"xihe-mobisys2021.png",title:"Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality",type:p},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"paper\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.00006\",\"project\":\"\u002Fproject\u002Fpoint-ar\u002F\"}",":authors":u,":venue":"{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"16th European Conference on Computer Vision\"}",thumbnail:"pointar-eccv.png",title:L,type:p},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"paper\":\"https:\u002F\u002Fieeexplore.ieee.org\u002Fstamp\u002Fstamp.jsp?arnumber=8762126\",\"project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Zhongtian Bao\",\"Yiqin Zhao\",\"Zixing Zhang\",\"Nicholas Cummins\",\"Zhao Ren\",\"Bj√∂rn Schuller\"]",":venue":"{\"acronym\":\"Access\",\"year\":2019,\"name\":\"IEEE Access\"}",thumbnail:"deep-spectrum-ieee.png",title:"Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",type:J},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"paper\":\"https:\u002F\u002Fdl.acm.org\u002Fcitation.cfm?doid=3267935.3267948\",\"project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Yiqin Zhao\",\"Zhongtian Bao\",\"Haishuai Wang\",\"Zixing Zhang\",\"Chao Li\"]",":venue":"{\"acronym\":\"ASMMC-MMAC\",\"year\":2018,\"name\":\"4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data\"}",thumbnail:"deep-spectrum-acmmm.png",title:M,type:p},children:[]},{type:a,tag:j,props:{":artifactLinks":"{\"paper\":\"https:\u002F\u002Fwww.isca-speech.org\u002Farchive\u002FInterspeech_2018\u002Fpdfs\u002F1477.pdf\",\"project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Yu Zheng\",\"Zixing Zhang\",\"Haishuai Wang\",\"Yiqin Zhao\",\"Chao Li\"]",":venue":"{\"acronym\":\"INTERSPEECH\",\"year\":2018,\"name\":\"Annual Conference of the International Speech Communication Association\"}",thumbnail:"deep-spectrum-interspeech.png",title:"Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition",type:p},children:[]},{type:a,tag:o,props:{id:N},children:[{type:b,value:O}]},{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Academic services"}]}]},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"UbiComp 2022 student volunteer."}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Awards"}]}]},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"ACM HotMobile 2023 Student Travel Grant."}]},{type:a,tag:d,props:{},children:[{type:b,value:"ACM HotMobile 2020 Student Travel Grant."}]},{type:a,tag:d,props:{},children:[{type:b,value:"China Collegiate Computing Contest, jointly held by Tsinghua University, Zhejiang University and Apple, Inc."},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"2017 national third prize, top 6%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2016 national third prize, top 10%"}]}]}]},{type:a,tag:d,props:{},children:[{type:b,value:"University Scholarship, Tianjin Normal University"},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"2018 - 2019 academic first grade scholarship, top 10%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"Wang Kechang Culture and Technology Innovation Scholarship, ‚â§ 1%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2017 - 2018 academic year top grade scholarship, top 5%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2016 - 2017 academic year second grade scholarship, top 20%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2015 - 2016 academic year first grade scholarship, top 10%"}]}]}]}]},{type:a,tag:o,props:{id:P},children:[{type:b,value:Q}]},{type:a,tag:s,props:{icon:"email",url:"mailto:yiqinzhao@outlook.com"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"Email"}]}]},{type:a,tag:s,props:{icon:"github",url:"https:\u002F\u002Fgithub.com\u002FYiqinZhao"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"GitHub"}]}]},{type:a,tag:s,props:{icon:"twitter",url:"https:\u002F\u002Ftwitter.com\u002Fyiqin_zhao"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"Twitter"}]}]},{type:a,tag:s,props:{icon:"instagram",url:"https:\u002F\u002Fwww.instagram.com\u002Fyiqinzhao1996"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"Instagram"}]}]}],toc:{title:k,searchDepth:l,depth:l,links:[{id:y,depth:l,text:z},{id:C,depth:l,text:D},{id:E,depth:l,text:F},{id:G,depth:l,text:H},{id:N,depth:l,text:O},{id:P,depth:l,text:Q}]}},_type:R,_id:"content:index.md",_source:S,_file:"index.md",_extension:T,layout:n}},"$sdd-surrounds":{"/":[null,{_path:U,_dir:k,_draft:f,_partial:f,_locale:w,_empty:f,title:V,description:k,leadingImage:"me-news-google.png",disableFancyImage:i,_type:R,_id:"content:news.md",_source:S,_file:"news.md",_extension:T}]},"$sdd-globals":{},"$sdd-navigation":[{title:x,_path:t},{title:V,_path:U},{title:"Project",_path:"\u002Fproject",children:[{title:2048,_path:"\u002Fproject\u002F2048",layout:n},{title:M,_path:"\u002Fproject\u002Fdeep-spectrum",layout:n},{title:I,_path:"\u002Fproject\u002Flitar",layout:n},{title:L,_path:"\u002Fproject\u002Fpoint-ar",layout:n},{title:K,_path:"\u002Fproject\u002Fprivacy-preserving-reflection",layout:n},{title:"Xihe: A 3D Vision based Lighting Estimation for Mobile AR",_path:"\u002Fproject\u002Fxihe",layout:n}],layout:"cards"},{title:"Research",_path:"\u002Fresearch"}]},_errors:{},serverRendered:i,config:{public:{content:{locales:[],integrity:1675113041926,experimental:{stripQueryParameters:f,clientDB:f},api:{baseURL:"\u002Fapi\u002F_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:k,documentDriven:{page:i,navigation:i,surround:i,globals:{},layoutFallbacks:["theme"],injectPage:i},host:k,trailingSlash:f,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:t,buildAssetsDir:"\u002F_nuxt\u002F",cdnURL:k}},prerenderedAt:void 0}}("element","text","p","li","a",false,"nofollow","br",true,"publication-row","",2,"strong","default","h2","conference","experience-row","ul","contact-item","\u002F","[\"Yiqin Zhao\",\"Tian Guo\"]","system","en","Home","Ô∏è-about-me","ü¶∏üèª‚Äç‚ôÇÔ∏è About Me","https:\u002F\u002Ftianguo.info","Prof. Tian Guo","news","üì∞ News","experiences","ü•∑ Experiences","publications","üìÑ Publications","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","journal","Privacy-preserving Reflection Rendering for Augmented Reality","PointAR: Efficient Lighting Estimation for Mobile Augmented Reality","Deep Spectrum Feature Representations for Speech Emotion Recognition","Ô∏è-services-and-awards","‚ù§Ô∏è Services and Awards","contacts","üìß Contacts","markdown","content","md","\u002Fnews","News")))}</script><script type="module" src="/_nuxt/entry.1b6408d7.js" crossorigin></script><script type="module" src="/_nuxt/document-driven.11dea0df.js" crossorigin></script><script type="module" src="/_nuxt/default.d50c958a.js" crossorigin></script><script type="module" src="/_nuxt/Navigator.f587897a.js" crossorigin></script><script type="module" src="/_nuxt/ContentDoc.7f085b8b.js" crossorigin></script><script type="module" src="/_nuxt/Footer.4618626e.js" crossorigin></script><script type="module" src="/_nuxt/ContentRenderer.90901a92.js" crossorigin></script><script type="module" src="/_nuxt/ContentRendererMarkdown.50598109.js" crossorigin></script><script type="module" src="/_nuxt/IndexHeader.4895a05e.js" crossorigin></script><script type="module" src="/_nuxt/ProseH2.1121f5c1.js" crossorigin></script><script type="module" src="/_nuxt/ProseP.872cb6fd.js" crossorigin></script><script type="module" src="/_nuxt/ProseEm.0a7db5f8.js" crossorigin></script><script type="module" src="/_nuxt/ProseA.89014535.js" crossorigin></script><script type="module" src="/_nuxt/ShortNews.cc95d421.js" crossorigin></script><script type="module" src="/_nuxt/ExperienceRow.2f41c222.js" crossorigin></script><script type="module" src="/_nuxt/ContentSlot.a9c862e3.js" crossorigin></script><script type="module" src="/_nuxt/ProseStrong.17cbe3da.js" crossorigin></script><script type="module" src="/_nuxt/PublicationRow.f724f577.js" crossorigin></script><script type="module" src="/_nuxt/ProseUl.7cb64d63.js" crossorigin></script><script type="module" src="/_nuxt/ProseLi.c819225a.js" crossorigin></script><script type="module" src="/_nuxt/ContactItem.e71548ac.js" crossorigin></script><script type="module" src="/_nuxt/MarkdownHeader.59f6939b.js" crossorigin></script><script type="module" src="/_nuxt/ProseImg.fd796330.js" crossorigin></script></body>
</html>
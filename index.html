<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Home - Yiqin Zhao</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
<meta property="og:title" content="Home"><link rel="preload" as="fetch" crossorigin="anonymous" href="/_payload.json"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.5757841a.js"><link rel="preload" as="style" href="/_nuxt/entry.5328c45a.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.c777ac5c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.a18295cb.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.e640ef4e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.524c43d1.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/index.a6ef77ff.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.2a335c16.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.587d4048.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.79639543.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.e530131f.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/qin-logo.5b1ed4b2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.5e98ba61.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.58adc26e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/asyncData.a75bc970.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.c12c47fe.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/IndexHeader.f6c0ec96.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.c27b6911.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.0b88b931.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.26dd3982.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseEm.438d7f48.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.4dd527a0.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/nuxt-link.3c26aa84.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ShortNews.b974b696.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ExperienceRow.8acfb9a2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentSlot.4141d28f.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.51959a18.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/PublicationRow.b2beab5c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseImg.d73bcdf9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.80fe7fb2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.3f6e9c85.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContactItem.c81e97ab.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.4bdc8bde.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.5cf1691c.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.547b377d.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.28fd0842.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.6336bcf2.js"><link rel="stylesheet" href="/_nuxt/entry.5328c45a.css"><style>body{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}:is(.dark body){--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><div class="document-driven-page"><!--[--><!--[--><div class="bg-transparent dark:bg-transparent hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class="opacity-0"><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium flex items-center" href="/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium flex items-center" href="/research/"><span class="transition-border hover:border-b-2 border-b-gray-400">Research</span></a><a class="pl-10 font-medium flex items-center" href="/project/"><span class="transition-border hover:border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="translate-y-[-100vh] fixed w-full h-full top-0 left-0 z-20 bg-black transition-opacity opacity-0"></div><div class="duration-0 translate-y-[-100vh] opacity-0 md:hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20 transition-transform duration-500"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="transition-color py-3" href="/"><div class="flex justify-between"><span class="dark:text-white font-medium">Home</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/research/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Research</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/project/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Projects</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><div class="mb-16"><div class="container md:w-[140%] md:ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><div class="w-[55%] hidden md:flex flex-col items-center justify-start shadow-lg p-12 py-8 z-20 h-fit absolute left-0 bg-neutral-100 dark:bg-neutral-700 bottom-16"><p class="w-full text-6xl py-4 m-0">Yiqin Zhao</p><p class="w-full text-xl pl-3 prose dark:prose-invert m-0"> 赵一勤 | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Research: Mobile System, AR, CV, CG </p><p class="mt-4 w-full pl-3 m-0"><span class="m-0"><a href="mailto:yiqinzhao@outlook.com"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/email.svg" alt=""></a><a href="https://github.com/YiqinZhao"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/github.svg" alt=""></a><a href="https://scholar.google.com/citations?user=2Dq4bAcAAAAJ&amp;hl=en"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/google-scholar.svg" alt=""></a><a href="https://twitter.com/yiqin_zhao"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/twitter.svg" alt=""></a></span></p></div><img class="w-full md:w-1/2 shadow-lg my-0 md:my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""><div class="absolute h-full w-[75%] left-0 z-[-1]"></div><img class="hidden md:block absolute w-3/5 top-[-8rem] left-[-5rem] dark:invert z-[-1] opacity-30" src="/assets/img/qin-logo.svg" alt=""></div></div><div class="hidden md:block w-full h-fit p-0 m-0 absolute mx-auto top-0 left-0 z-[-2] bg-neutral-200 dark:bg-neutral-800"><div class="max-w-prose mt-[3.4rem] opacity-0"><div class="container w-[140%] ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><img class="w-full md:w-1/2 shadow-lg my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""></div></div></div></div></div><h2 id="️-about-me"><a href="#️-about-me"><!--[-->🦸🏻‍♂️ About Me<!--]--></a></h2><p><!--[-->🔊 <em><!--[-->My name pounces as: Yi-Chin<!--]--></em><!--]--></p><p><!--[-->I am a fourth-year Computer Science M.S./Ph.D. candidate at <a href="https://wpi.edu" rel="nofollow"><!--[-->Worcester Polytechnic Institute (WPI)<!--]--></a> and a proud member of <a href="https://cake-lab.github.io" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> research group.
I feel extremely fortunate to be advised by my kind and wise advisor <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.
I am interested in designing system supports and optimizations for Augmented Reality (AR) applications.
My recent research has a strong focus on designing system support for AR environment lighting understanding and photorealistic rendering.<!--]--></p><p><!--[-->In the past, I have interned at <a href="https://baidu.com" rel="nofollow"><!--[-->Baidu<!--]--></a> (Summer 2018), <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Kuaishou Y-tech Graphics AI team<!--]--></a> in Spring 2022, and <a href="https://arvr.google.com" rel="nofollow"><!--[-->GoogleARVR<!--]--></a> in Summer, Fall 2022 and Spring 2023.
In my spare time, I enjoy hiking, road tripping, and work on my <a href="https://github.com/YiqinZhao/yiqinzhao.me-source" rel="nofollow"><!--[-->website templates<!--]--></a>.<!--]--></p><h2 id="news"><a href="#news"><!--[-->📰 News<!--]--></a></h2><div class="[&amp;_li:nth-of-type(1n+7)]:hidden [&amp;_img]:hidden [&amp;_h1]:hidden [&amp;_h2]:hidden"><!--[--><div><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">News</h1><h2 class="dark:text-gray-200 text-center text-xl font-normal my-6 max-w-4xl mx-auto">📢 Latest: I&#39;m a Ph.D. candidate now!</h2><!--]--><ul><!--[--><li><!--[--><strong><!--[-->03/31/2023<!--]--></strong> 🎉 We have released the <a href="https://github.com/cake-lab/LitAR" rel="nofollow"><!--[-->code<!--]--></a> of our UbiComp 2022 paper LitAR.<!--]--></li><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> 🎉 Received student travel grant from HotMobile 2023, thank you!<!--]--></li><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> 🎉 Passed my classes and research qualifications, I&#39;m a Ph.D. candidate now!<!--]--></li><li><!--[--><strong><!--[-->12/09/2022<!--]--></strong> 🎉 One paper accepted by HotMobile 2023!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> 🎉 I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> 🎉 Our paper <a href="/project/litar" class=""><!--[-->LitAR<!--]--></a> is accepted by UbiComp 2022!<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> 🎉 Our paper <a href="/project/privacy-preserving-reflection" class=""><!--[-->Privacy-preserving Reflection Rendering for Augmented Reality<!--]--></a> is accepted by ACM MM 2022!<!--]--></li><li><!--[--><strong><!--[-->03/04/2022<!--]--></strong> 🎉 I will join Google as a research intern in the summer!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> 🎉 I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/24/2021<!--]--></strong> ✨ We just released the <a href="/project/point-ar" class=""><!--[-->Xihe<!--]--></a> source code! Check our <a href="https://github.com/cake-lab/Xihe" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> 🎉 I will join the <a href="http://chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern in next spring!<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> 🎉 I&#39;m thrilled to announce that I will continue my Ph.D. study at <a href="https://cake.wpi.edu/" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> with <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> 🎉 I&#39;ve presented my M.S. Thesis.<!--]--></li><li><!--[--><strong><!--[-->04/03/2021<!--]--></strong> ✨ <a href="/project/point-ar" class=""><!--[-->PointAR<!--]--></a> source code is now released! Check our <a href="https://github.com/cake-lab/PointAR" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->03/25/2021<!--]--></strong> 🔥 New paper on mobile system for 3D vision-based lighting estimation has been conditionally accepted to MobiSys 2021.<!--]--></li><li><!--[--><strong><!--[-->08/25/2020<!--]--></strong> 🎙️ I presented our efficient mobile AR lighting estimation paper at ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->07/22/2020<!--]--></strong> 🔥 Our paper on efficient mobile AR lighting estimation neural network has been accepted to ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->03/03/2020<!--]--></strong> 🎙️ I presented my poster at the HotMobile 2020 conference in Austin, TX.<!--]--></li><li><!--[--><strong><!--[-->02/01/2020<!--]--></strong> 🔥 Our poster on mobile AR lighting estimation has been accepted to HotMobile 2020.<!--]--></li><li><!--[--><strong><!--[-->08/26/2019<!--]--></strong> 🦸🏻‍♂️ I joined Worcester Polytechnic Institute CakeLab.<!--]--></li><li><!--[--><strong><!--[-->10/26/2018<!--]--></strong> 🎙️ I presented our paper on ASMMC-MMAC 2018 workshop.<!--]--></li><li><!--[--><strong><!--[-->10/15/2018<!--]--></strong> 🏆 I received Wang Kechang Technology innovation scholarship (&lt;1%).<!--]--></li><li><!--[--><strong><!--[-->10/13/2018<!--]--></strong> 🏆 I received annual special scholarship at Tianjin Normal University (top 5%).<!--]--></li><li><!--[--><strong><!--[-->08/15/2018<!--]--></strong> 🔥 Our paper about human speech emotion in spectrogram representation has submitted to ACM Multimedia 2018 ASMMC-MMAC workshop!<!--]--></li><li><!--[--><strong><!--[-->07/04/2018<!--]--></strong> 👨🏻‍💻 I joined the DuerOS department at Baidu, Inc as a frontend software engineer intern.<!--]--></li><li><!--[--><strong><!--[-->09/30/2017<!--]--></strong> 🏆  I received third prize of the 2017 China national Mobile Innovation Contest (top 6%).<!--]--></li><li><!--[--><strong><!--[-->09/30/2016<!--]--></strong> 🏆  I received third prize of the 2016 China national Mobile Innovation Contest (top 10%).<!--]--></li><!--]--></ul></div><!--]--></div><p><!--[--><a href="/news/" class=""><!--[-->More news &gt;&gt;&gt;<!--]--></a><!--]--></p><h2 id="experiences"><a href="#experiences"><!--[-->🥷 Experiences<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-google.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/google.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Google, Mountain View, CA<!--]--></strong><br>
Student Researcher<br>
May 2022 - May 2023<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-wpi.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/wpi.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Worcester Polytechnic Institute, Worcester, MA<!--]--></strong><br>
Ph.D. Student in <a href="https://cake.wpi.edu" rel="nofollow"><!--[-->TheCakeLab<!--]--></a>, advised by <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a><br>
Aug 2021 - Present<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-kuaishou.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/kuaishou.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Kuaishou Technology, Palo Alto, CA<!--]--></strong><br>
Research Intern<br>
Jan, 2022 - May, 2022<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-baidu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/baidu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Baidu, Beijing, China<!--]--></strong><br>
Software Engineering Intern<br>
Jun, 2018 - Sept, 2018<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-tjnu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/tjnu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Tianjin Normal University, Tianjin, China<!--]--></strong><br>
Bachelor of Engineering in Software Engineering<br>
Sept, 2015 - Jun, 2019<!--]--></p><!--]--><!--]--></div></div><h2 id="publications"><a href="#publications"><!--[-->📄 Publications<!--]--></a></h2><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">HotMobile&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/10.1145/3572864.3580337">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2301.06143.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6/view?usp=sharing">Poster</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI/edit?usp=sharing">Slides</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/dual-light-hotmobile2023.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Sean Fanello</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">The Twenty-fourth International Workshop on Mobile Computing Systems and Applications</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="journal"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">IMWUT&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/abs/10.1145/3550291">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2301.06184.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE/edit?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/cake-lab/LitAR">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/litar/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">LitAR: Visually Coherent Lighting for Mobile Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/litar-ubicomp22.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Chongyang Ma</span><span>, </span></span><span><span class="">Haibin Huang</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ACMMM&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/abs/10.1145/3503161.3548386">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2207.03056">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk/edit?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/privacy-preserving-reflection">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Privacy-preserving Reflection Rendering for Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/privacy-preserving-reflection.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Sheng Wei</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">30th ACM International Conference on Multimedia</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="workshop"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">IEEEVRW&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://ieeexplore.ieee.org/document/9757380">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA/view?usp=sharing">Poster</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/fusedar-ieeevrw22.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">MobiSys&#39;21</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2106.15280">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa/view?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/xihe/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/xihe-mobisys2021.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">The 19th ACM International Conference on Mobile Systems, Applications, and Services</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><span class="text-red-600"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg" alt class="inline w-4 my-0 mt-[-0.2em]"> Artifacts Evaluated – Functional v1.1</span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ECCV&#39;20</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2004.00006">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2004.00006">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp/view?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/point-ar/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">PointAR: Efficient Lighting Estimation for Mobile Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/pointar-eccv.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">16th European Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="journal"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">Access&#39;19</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/deep-spectrum/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deep-spectrum-ieee.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Ziping Zhao</span><span>, </span></span><span><span class="">Zhongtian Bao</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Zixing Zhang</span><span>, </span></span><span><span class="">Nicholas Cummins</span><span>, </span></span><span><span class="">Zhao Ren</span><span>, </span></span><span><span class="">Björn Schuller</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">IEEE Access</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ASMMC-MMAC&#39;18</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/citation.cfm?doid=3267935.3267948">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/deep-spectrum/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Deep Spectrum Feature Representations for Speech Emotion Recognition</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deep-spectrum-acmmm.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Ziping Zhao</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Zhongtian Bao</span><span>, </span></span><span><span class="">Haishuai Wang</span><span>, </span></span><span><span class="">Zixing Zhang</span><span>, </span></span><span><span class="">Chao Li</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">INTERSPEECH&#39;18</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1477.html">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/deep-spectrum/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deep-spectrum-interspeech.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Ziping Zhao</span><span>, </span></span><span><span class="">Yu Zheng</span><span>, </span></span><span><span class="">Zixing Zhang</span><span>, </span></span><span><span class="">Haishuai Wang</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Chao Li</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Annual Conference of the International Speech Communication Association</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><h2 id="️-services-and-awards"><a href="#️-services-and-awards"><!--[-->❤️ Services and Awards<!--]--></a></h2><p><!--[--><strong><!--[-->Academic services<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->UbiComp 2022 student volunteer.<!--]--></li><!--]--></ul><p><!--[--><strong><!--[-->Awards<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->ACM HotMobile 2023 Student Travel Grant.<!--]--></li><li><!--[-->ACM HotMobile 2020 Student Travel Grant.<!--]--></li><li><!--[-->China Collegiate Computing Contest, jointly held by Tsinghua University, Zhejiang University and Apple, Inc.<ul><!--[--><li><!--[-->2017 national third prize, top 6%<!--]--></li><li><!--[-->2016 national third prize, top 10%<!--]--></li><!--]--></ul><!--]--></li><li><!--[-->University Scholarship, Tianjin Normal University<ul><!--[--><li><!--[-->2018 - 2019 academic first grade scholarship, top 10%<!--]--></li><li><!--[-->Wang Kechang Culture and Technology Innovation Scholarship, ≤ 1%<!--]--></li><li><!--[-->2017 - 2018 academic year top grade scholarship, top 5%<!--]--></li><li><!--[-->2016 - 2017 academic year second grade scholarship, top 20%<!--]--></li><li><!--[-->2015 - 2016 academic year first grade scholarship, top 10%<!--]--></li><!--]--></ul><!--]--></li><!--]--></ul><h2 id="find-me"><a href="#find-me"><!--[-->📧 Find Me<!--]--></a></h2><span><a href="mailto:yiqinzhao@outlook.com" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/email.svg" alt=""><!--[-->Email<!--]--></a></span><span><a href="https://github.com/YiqinZhao" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/github.svg" alt=""><!--[-->GitHub<!--]--></a></span><span><a href="https://twitter.com/yiqin_zhao" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/twitter.svg" alt=""><!--[-->Twitter<!--]--></a></span><span><a href="https://www.instagram.com/yiqinzhao1996" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/instagram.svg" alt=""><!--[-->Instagram<!--]--></a></span></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> 赵一勤 | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. Candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https//arvr.google.com">@GoogleVRAR</a> <br> Research Interests: Mobile System, AR, CV, CG </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:yiqinzhao@outlook.com">E-Mail</a> <br><a href="https://github.com/YiqinZhao">GitHub</a> <br><a href="https://twitter.com/yiqin_zhao">Twitter</a> <br><a href="https://www.instagram.com/yiqinzhao1996">Instagram</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> © <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2023. Last updated: 5/18/2023. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div></div><!--]--></div><!--]--></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true" data-src="/_payload.json">[{"state":1,"_errors":562,"serverRendered":5,"prerenderedAt":-1},["Reactive",2],{"$scolor-mode":3,"$sdd-pages":7,"$sdd-surrounds":527,"$sdd-globals":536,"$sdd-navigation":537},{"preference":4,"value":4,"unknown":5,"forced":6},"system",true,false,{"/":8},{"_path":9,"_dir":10,"_draft":6,"_partial":6,"_locale":10,"_empty":6,"title":11,"description":10,"hideTitle":5,"disableFancyImage":5,"body":12,"_type":521,"_id":522,"_source":523,"_file":524,"_extension":525,"layout":526},"/","","Home",{"type":13,"children":14,"toc":512},"root",[15,20,28,40,74,115,121,125,134,140,165,201,223,245,267,273,283,292,300,309,337,344,352,360,369,375,383,393,401,465,471,482,492,502],{"type":16,"tag":17,"props":18,"children":19},"element","index-header",{},[],{"type":16,"tag":21,"props":22,"children":24},"h2",{"id":23},"️-about-me",[25],{"type":26,"value":27},"text","🦸🏻‍♂️ About Me",{"type":16,"tag":29,"props":30,"children":31},"p",{},[32,34],{"type":26,"value":33},"🔊 ",{"type":16,"tag":35,"props":36,"children":37},"em",{},[38],{"type":26,"value":39},"My name pounces as: Yi-Chin",{"type":16,"tag":29,"props":41,"children":42},{},[43,45,54,56,63,65,72],{"type":26,"value":44},"I am a fourth-year Computer Science M.S./Ph.D. candidate at ",{"type":16,"tag":46,"props":47,"children":51},"a",{"href":48,"rel":49},"https://wpi.edu",[50],"nofollow",[52],{"type":26,"value":53},"Worcester Polytechnic Institute (WPI)",{"type":26,"value":55}," and a proud member of ",{"type":16,"tag":46,"props":57,"children":60},{"href":58,"rel":59},"https://cake-lab.github.io",[50],[61],{"type":26,"value":62},"The Cake Lab",{"type":26,"value":64}," research group.\nI feel extremely fortunate to be advised by my kind and wise advisor ",{"type":16,"tag":46,"props":66,"children":69},{"href":67,"rel":68},"https://tianguo.info",[50],[70],{"type":26,"value":71},"Prof. Tian Guo",{"type":26,"value":73},".\nI am interested in designing system supports and optimizations for Augmented Reality (AR) applications.\nMy recent research has a strong focus on designing system support for AR environment lighting understanding and photorealistic rendering.",{"type":16,"tag":29,"props":75,"children":76},{},[77,79,86,88,95,97,104,106,113],{"type":26,"value":78},"In the past, I have interned at ",{"type":16,"tag":46,"props":80,"children":83},{"href":81,"rel":82},"https://baidu.com",[50],[84],{"type":26,"value":85},"Baidu",{"type":26,"value":87}," (Summer 2018), ",{"type":16,"tag":46,"props":89,"children":92},{"href":90,"rel":91},"http://www.chongyangma.com/team/index.html",[50],[93],{"type":26,"value":94},"Kuaishou Y-tech Graphics AI team",{"type":26,"value":96}," in Spring 2022, and ",{"type":16,"tag":46,"props":98,"children":101},{"href":99,"rel":100},"https://arvr.google.com",[50],[102],{"type":26,"value":103},"GoogleARVR",{"type":26,"value":105}," in Summer, Fall 2022 and Spring 2023.\nIn my spare time, I enjoy hiking, road tripping, and work on my ",{"type":16,"tag":46,"props":107,"children":110},{"href":108,"rel":109},"https://github.com/YiqinZhao/yiqinzhao.me-source",[50],[111],{"type":26,"value":112},"website templates",{"type":26,"value":114},".",{"type":16,"tag":21,"props":116,"children":118},{"id":117},"news",[119],{"type":26,"value":120},"📰 News",{"type":16,"tag":122,"props":123,"children":124},"short-news",{},[],{"type":16,"tag":29,"props":126,"children":127},{},[128],{"type":16,"tag":46,"props":129,"children":131},{"href":130},"/news/",[132],{"type":26,"value":133},"More news >>>",{"type":16,"tag":21,"props":135,"children":137},{"id":136},"experiences",[138],{"type":26,"value":139},"🥷 Experiences",{"type":16,"tag":141,"props":142,"children":144},"experience-row",{"icon":143},"google.png",[145],{"type":16,"tag":29,"props":146,"children":147},{},[148,154,158,160,163],{"type":16,"tag":149,"props":150,"children":151},"strong",{},[152],{"type":26,"value":153},"Google, Mountain View, CA",{"type":16,"tag":155,"props":156,"children":157},"br",{},[],{"type":26,"value":159},"\nStudent Researcher",{"type":16,"tag":155,"props":161,"children":162},{},[],{"type":26,"value":164},"\nMay 2022 - May 2023",{"type":16,"tag":141,"props":166,"children":168},{"icon":167},"wpi.png",[169],{"type":16,"tag":29,"props":170,"children":171},{},[172,177,180,182,189,191,196,199],{"type":16,"tag":149,"props":173,"children":174},{},[175],{"type":26,"value":176},"Worcester Polytechnic Institute, Worcester, MA",{"type":16,"tag":155,"props":178,"children":179},{},[],{"type":26,"value":181},"\nPh.D. Student in ",{"type":16,"tag":46,"props":183,"children":186},{"href":184,"rel":185},"https://cake.wpi.edu",[50],[187],{"type":26,"value":188},"TheCakeLab",{"type":26,"value":190},", advised by ",{"type":16,"tag":46,"props":192,"children":194},{"href":67,"rel":193},[50],[195],{"type":26,"value":71},{"type":16,"tag":155,"props":197,"children":198},{},[],{"type":26,"value":200},"\nAug 2021 - Present",{"type":16,"tag":141,"props":202,"children":204},{"icon":203},"kuaishou.png",[205],{"type":16,"tag":29,"props":206,"children":207},{},[208,213,216,218,221],{"type":16,"tag":149,"props":209,"children":210},{},[211],{"type":26,"value":212},"Kuaishou Technology, Palo Alto, CA",{"type":16,"tag":155,"props":214,"children":215},{},[],{"type":26,"value":217},"\nResearch Intern",{"type":16,"tag":155,"props":219,"children":220},{},[],{"type":26,"value":222},"\nJan, 2022 - May, 2022",{"type":16,"tag":141,"props":224,"children":226},{"icon":225},"baidu.png",[227],{"type":16,"tag":29,"props":228,"children":229},{},[230,235,238,240,243],{"type":16,"tag":149,"props":231,"children":232},{},[233],{"type":26,"value":234},"Baidu, Beijing, China",{"type":16,"tag":155,"props":236,"children":237},{},[],{"type":26,"value":239},"\nSoftware Engineering Intern",{"type":16,"tag":155,"props":241,"children":242},{},[],{"type":26,"value":244},"\nJun, 2018 - Sept, 2018",{"type":16,"tag":141,"props":246,"children":248},{"icon":247},"tjnu.png",[249],{"type":16,"tag":29,"props":250,"children":251},{},[252,257,260,262,265],{"type":16,"tag":149,"props":253,"children":254},{},[255],{"type":26,"value":256},"Tianjin Normal University, Tianjin, China",{"type":16,"tag":155,"props":258,"children":259},{},[],{"type":26,"value":261},"\nBachelor of Engineering in Software Engineering",{"type":16,"tag":155,"props":263,"children":264},{},[],{"type":26,"value":266},"\nSept, 2015 - Jun, 2019",{"type":16,"tag":21,"props":268,"children":270},{"id":269},"publications",[271],{"type":26,"value":272},"📄 Publications",{"type":16,"tag":274,"props":275,"children":282},"publication-row",{":artifactLinks":276,":authors":277,":venue":278,"thumbnail":279,"title":280,"type":281},"{\"Paper\":\"https://dl.acm.org/doi/10.1145/3572864.3580337\",\"arXiv\":\"https://arxiv.org/pdf/2301.06143.pdf\",\"Poster\":\"https://drive.google.com/file/d/1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6/view?usp=sharing\",\"Slides\":\"https://docs.google.com/presentation/d/1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI/edit?usp=sharing\"}","[\"Yiqin Zhao\",\"Sean Fanello\",\"Tian Guo\"]","{\"acronym\":\"HotMobile\",\"year\":2023,\"name\":\"The Twenty-fourth International Workshop on Mobile Computing Systems and Applications\"}","dual-light-hotmobile2023.png","Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality","conference",[],{"type":16,"tag":274,"props":284,"children":291},{":artifactLinks":285,":authors":286,":venue":287,"thumbnail":288,"title":289,"type":290},"{\"Paper\":\"https://dl.acm.org/doi/abs/10.1145/3550291\",\"arXiv\":\"https://arxiv.org/pdf/2301.06184.pdf\",\"Slides\":\"https://docs.google.com/presentation/d/1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE/edit?usp=sharing\",\"Code\":\"https://github.com/cake-lab/LitAR\",\"Project\":\"/project/litar/\"}","[\"Yiqin Zhao\",\"Chongyang Ma\",\"Haibin Huang\",\"Tian Guo\"]","{\"acronym\":\"IMWUT\",\"year\":2022,\"name\":\"The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\"}","litar-ubicomp22.png","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","journal",[],{"type":16,"tag":274,"props":293,"children":299},{":artifactLinks":294,":authors":295,":venue":296,"thumbnail":297,"title":298,"type":281},"{\"Paper\":\"https://dl.acm.org/doi/abs/10.1145/3503161.3548386\",\"arXiv\":\"https://arxiv.org/abs/2207.03056\",\"Slides\":\"https://docs.google.com/presentation/d/1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk/edit?usp=sharing\",\"Project\":\"/project/privacy-preserving-reflection\"}","[\"Yiqin Zhao\",\"Sheng Wei\",\"Tian Guo\"]","{\"acronym\":\"ACMMM\",\"year\":2022,\"name\":\"30th ACM International Conference on Multimedia\"}","privacy-preserving-reflection.png","Privacy-preserving Reflection Rendering for Augmented Reality",[],{"type":16,"tag":274,"props":301,"children":308},{":artifactLinks":302,":authors":303,":venue":304,"thumbnail":305,"title":306,"type":307},"{\"Paper\":\"https://ieeexplore.ieee.org/document/9757380\",\"Poster\":\"https://drive.google.com/file/d/1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA/view?usp=sharing\"}","[\"Yiqin Zhao\",\"Tian Guo\"]","{\"acronym\":\"IEEEVRW\",\"year\":2022,\"name\":\"IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\"}","fusedar-ieeevrw22.png","FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering","workshop",[],{"type":16,"tag":274,"props":310,"children":315},{":artifactLinks":311,":authors":303,":venue":312,"thumbnail":313,"title":314,"type":281},"{\"Paper\":\"https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290\",\"arXiv\":\"https://arxiv.org/abs/2106.15280\",\"Slides\":\"https://drive.google.com/file/d/1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa/view?usp=sharing\",\"Project\":\"/project/xihe/\"}","{\"acronym\":\"MobiSys\",\"year\":2021,\"name\":\"The 19th ACM International Conference on Mobile Systems, Applications, and Services\"}","xihe-mobisys2021.png","Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality",[316],{"type":16,"tag":29,"props":317,"children":318},{},[319],{"type":16,"tag":320,"props":321,"children":324},"span",{"className":322},[323],"text-red-600",[325,335],{"type":16,"tag":326,"props":327,"children":334},"img",{"className":328,"src":333},[329,330,331,332],"inline","w-4","my-0","mt-[-0.2em]","https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg",[],{"type":26,"value":336}," Artifacts Evaluated – Functional v1.1",{"type":16,"tag":274,"props":338,"children":343},{":artifactLinks":339,":authors":303,":venue":340,"thumbnail":341,"title":342,"type":281},"{\"Paper\":\"https://arxiv.org/abs/2004.00006\",\"arXiv\":\"https://arxiv.org/abs/2004.00006\",\"Slides\":\"https://drive.google.com/file/d/1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp/view?usp=sharing\",\"Project\":\"/project/point-ar/\"}","{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"16th European Conference on Computer Vision\"}","pointar-eccv.png","PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",[],{"type":16,"tag":274,"props":345,"children":351},{":artifactLinks":346,":authors":347,":venue":348,"thumbnail":349,"title":350,"type":290},"{\"Paper\":\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126\",\"Project\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Zhongtian Bao\",\"Yiqin Zhao\",\"Zixing Zhang\",\"Nicholas Cummins\",\"Zhao Ren\",\"Björn Schuller\"]","{\"acronym\":\"Access\",\"year\":2019,\"name\":\"IEEE Access\"}","deep-spectrum-ieee.png","Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",[],{"type":16,"tag":274,"props":353,"children":359},{":artifactLinks":354,":authors":355,":venue":356,"thumbnail":357,"title":358,"type":281},"{\"Paper\":\"https://dl.acm.org/citation.cfm?doid=3267935.3267948\",\"Project\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yiqin Zhao\",\"Zhongtian Bao\",\"Haishuai Wang\",\"Zixing Zhang\",\"Chao Li\"]","{\"acronym\":\"ASMMC-MMAC\",\"year\":2018,\"name\":\"4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data\"}","deep-spectrum-acmmm.png","Deep Spectrum Feature Representations for Speech Emotion Recognition",[],{"type":16,"tag":274,"props":361,"children":368},{":artifactLinks":362,":authors":363,":venue":364,"thumbnail":365,"title":366,"type":281,":hideBottomBorder":367},"{\"Paper\":\"https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1477.html\",\"Project\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yu Zheng\",\"Zixing Zhang\",\"Haishuai Wang\",\"Yiqin Zhao\",\"Chao Li\"]","{\"acronym\":\"INTERSPEECH\",\"year\":2018,\"name\":\"Annual Conference of the International Speech Communication Association\"}","deep-spectrum-interspeech.png","Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition","true",[],{"type":16,"tag":21,"props":370,"children":372},{"id":371},"️-services-and-awards",[373],{"type":26,"value":374},"❤️ Services and Awards",{"type":16,"tag":29,"props":376,"children":377},{},[378],{"type":16,"tag":149,"props":379,"children":380},{},[381],{"type":26,"value":382},"Academic services",{"type":16,"tag":384,"props":385,"children":386},"ul",{},[387],{"type":16,"tag":388,"props":389,"children":390},"li",{},[391],{"type":26,"value":392},"UbiComp 2022 student volunteer.",{"type":16,"tag":29,"props":394,"children":395},{},[396],{"type":16,"tag":149,"props":397,"children":398},{},[399],{"type":26,"value":400},"Awards",{"type":16,"tag":384,"props":402,"children":403},{},[404,409,414,432],{"type":16,"tag":388,"props":405,"children":406},{},[407],{"type":26,"value":408},"ACM HotMobile 2023 Student Travel Grant.",{"type":16,"tag":388,"props":410,"children":411},{},[412],{"type":26,"value":413},"ACM HotMobile 2020 Student Travel Grant.",{"type":16,"tag":388,"props":415,"children":416},{},[417,419],{"type":26,"value":418},"China Collegiate Computing Contest, jointly held by Tsinghua University, Zhejiang University and Apple, Inc.",{"type":16,"tag":384,"props":420,"children":421},{},[422,427],{"type":16,"tag":388,"props":423,"children":424},{},[425],{"type":26,"value":426},"2017 national third prize, top 6%",{"type":16,"tag":388,"props":428,"children":429},{},[430],{"type":26,"value":431},"2016 national third prize, top 10%",{"type":16,"tag":388,"props":433,"children":434},{},[435,437],{"type":26,"value":436},"University Scholarship, Tianjin Normal University",{"type":16,"tag":384,"props":438,"children":439},{},[440,445,450,455,460],{"type":16,"tag":388,"props":441,"children":442},{},[443],{"type":26,"value":444},"2018 - 2019 academic first grade scholarship, top 10%",{"type":16,"tag":388,"props":446,"children":447},{},[448],{"type":26,"value":449},"Wang Kechang Culture and Technology Innovation Scholarship, ≤ 1%",{"type":16,"tag":388,"props":451,"children":452},{},[453],{"type":26,"value":454},"2017 - 2018 academic year top grade scholarship, top 5%",{"type":16,"tag":388,"props":456,"children":457},{},[458],{"type":26,"value":459},"2016 - 2017 academic year second grade scholarship, top 20%",{"type":16,"tag":388,"props":461,"children":462},{},[463],{"type":26,"value":464},"2015 - 2016 academic year first grade scholarship, top 10%",{"type":16,"tag":21,"props":466,"children":468},{"id":467},"find-me",[469],{"type":26,"value":470},"📧 Find Me",{"type":16,"tag":472,"props":473,"children":476},"contact-item",{"icon":474,"url":475},"email","mailto:yiqinzhao@outlook.com",[477],{"type":16,"tag":29,"props":478,"children":479},{},[480],{"type":26,"value":481},"Email",{"type":16,"tag":472,"props":483,"children":486},{"icon":484,"url":485},"github","https://github.com/YiqinZhao",[487],{"type":16,"tag":29,"props":488,"children":489},{},[490],{"type":26,"value":491},"GitHub",{"type":16,"tag":472,"props":493,"children":496},{"icon":494,"url":495},"twitter","https://twitter.com/yiqin_zhao",[497],{"type":16,"tag":29,"props":498,"children":499},{},[500],{"type":26,"value":501},"Twitter",{"type":16,"tag":472,"props":503,"children":506},{"icon":504,"url":505},"instagram","https://www.instagram.com/yiqinzhao1996",[507],{"type":16,"tag":29,"props":508,"children":509},{},[510],{"type":26,"value":511},"Instagram",{"title":10,"searchDepth":513,"depth":513,"links":514},2,[515,516,517,518,519,520],{"id":23,"depth":513,"text":27},{"id":117,"depth":513,"text":120},{"id":136,"depth":513,"text":139},{"id":269,"depth":513,"text":272},{"id":371,"depth":513,"text":374},{"id":467,"depth":513,"text":470},"markdown","content:index.md","content","index.md","md","default",{"/":528},[529,530],null,{"_path":531,"_dir":10,"_draft":6,"_partial":6,"_locale":10,"_empty":6,"title":532,"description":10,"leadingImage":533,"disableFancyImage":5,"_type":521,"_id":534,"_source":523,"_file":535,"_extension":525},"/news","News","me-news-google.png","content:news.md","news.md",{},[538,539,540,559],{"title":11,"_path":9},{"title":532,"_path":531},{"title":541,"_path":542,"children":543,"layout":558},"Project","/project",[544,547,549,551,553,555],{"title":545,"_path":546,"layout":526},2048,"/project/2048",{"title":358,"_path":548,"layout":526},"/project/deep-spectrum",{"title":289,"_path":550,"layout":526},"/project/litar",{"title":342,"_path":552,"layout":526},"/project/point-ar",{"title":298,"_path":554,"layout":526},"/project/privacy-preserving-reflection",{"title":556,"_path":557,"layout":526},"Xihe: A 3D Vision based Lighting Estimation for Mobile AR","/project/xihe","cards",{"title":560,"_path":561},"Research","/research",["Reactive",563],{"content-query-1DxZ1vYQk5":529,"content-query-B6mqoO8PxR":529}]</script><script>window.__NUXT__={};window.__NUXT__.config={public:{content:{locales:[],defaultLocale:"",integrity:1684421366486,experimental:{stripQueryParameters:false,clientDB:false,advancedIgnoresPattern:false},api:{baseURL:"/api/_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:"",documentDriven:{page:true,navigation:true,surround:true,globals:{},layoutFallbacks:["theme"],injectPage:true},host:"",trailingSlash:false,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:"/",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script><script type="module" src="/_nuxt/entry.5757841a.js" crossorigin></script></body>
</html>
<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Home - Yiqin Zhao</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
<meta name="og:title" content="Home"><link rel="modulepreload" href="/_payload.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.03c81885.js"><link rel="preload" as="style" href="/_nuxt/entry.0d6ce1d7.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.59779b55.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.a0493bd4.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.18572a1b.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.63b1e8f7.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/index.a6ef77ff.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.f74c6421.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.c6ff5edc.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.52378aa3.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.fbff0f57.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/qin-logo.c25c6313.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.4e939d29.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.7b5fdca2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/asyncData.df0c9dd4.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.0867a79c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/IndexHeader.914a3b6a.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.c27b6911.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.1b2a03a6.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.3b64db1e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseEm.98103bf7.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.b022b3f1.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/nuxt-link.0dad4690.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ShortNews.30d88f17.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ExperienceRow.d5439b57.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentSlot.6b5fc1e8.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.a8d6c6de.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/PublicationRow.cd0fbb77.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseImg.099f33c5.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseUl.df87ca14.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseLi.a80c067a.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContactItem.275c840e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.279771fa.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.46a33f16.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.ecdfa679.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.0aab6246.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.643cffd7.js"><link rel="stylesheet" href="/_nuxt/entry.0d6ce1d7.css"><style>body{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}.dark body{--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><!--[--><div class="document-driven-page"><!--[--><!--[--><!--[--><div class="bg-transparent dark:bg-transparent hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class="opacity-0"><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/research/"><span class="transition-border hover:border-b-2 border-b-gray-400">Research</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/project/"><span class="transition-border hover:border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Home</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="translate-y-[-100vh] fixed w-full h-full top-0 left-0 z-20 bg-black transform-gpu transition-opacity opacity-0"></div><div class="translate-y-[-100vh] fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20 transform-gpu transition-transform duration-700"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="hover:text-white transition-color py-3" href="/"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">Home</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/research/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Research</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/project/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Projects</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><div class="mb-16"><div class="container md:w-[140%] md:ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><div class="w-[55%] hidden md:flex flex-col items-center justify-start shadow-lg p-12 py-8 z-20 h-fit absolute left-0 bg-neutral-100 dark:bg-neutral-700 bottom-16"><p class="w-full text-6xl py-4 m-0">Yiqin Zhao</p><p class="w-full text-xl pl-3 prose dark:prose-invert m-0"> Ëµµ‰∏ÄÂã§ | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https://arvr.google.com">@GoogleARVR</a> <br> Research: Mobile System, AR, CV, CG </p><p class="mt-4 w-full pl-3 m-0"><span class="m-0"><a href="mailto:yiqinzhao@outlook.com"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/email.svg" alt=""></a><a href="https://github.com/YiqinZhao"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/github.svg" alt=""></a><a href="https://twitter.com/yiqin_zhao"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/twitter.svg" alt=""></a><a href="https://www.instagram.com/yiqinzhao1996"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/instagram.svg" alt=""></a></span></p></div><img class="w-full md:w-1/2 shadow-lg my-0 md:my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""><div class="absolute h-full w-[75%] left-0 z-[-1]"></div><img class="hidden md:block absolute w-3/5 top-[-8rem] left-[-5rem] dark:invert z-[-1] opacity-30" src="/assets/img/qin-logo.svg" alt=""></div></div><div class="hidden md:block w-full h-fit p-0 m-0 absolute mx-auto top-0 left-0 z-[-2] bg-neutral-200 dark:bg-neutral-800"><div class="max-w-prose mt-[3.4rem] opacity-0"><div class="container w-[140%] ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><img class="w-full md:w-1/2 shadow-lg my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""></div></div></div></div></div><h2 id="Ô∏è-about-me"><a href="#Ô∏è-about-me"><!--[-->ü¶∏üèª‚Äç‚ôÇÔ∏è About Me<!--]--></a></h2><p><!--[-->üîä <em><!--[-->My name pounces as: Yi-Chin<!--]--></em><!--]--></p><p><!--[-->I am a fourth-year Computer Science M.S./Ph.D. candidate at <a href="https://wpi.edu" rel="nofollow"><!--[-->Worcester Polytechnic Institute (WPI)<!--]--></a> and a proud member of <a href="https://cake-lab.github.io" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> research group.
I feel extremely fortunate to be advised by my kind and wise advisor <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.
I am interested in designing system supports and optimizations for Augmented Reality (AR) applications.
My recent research has a strong focus on designing system support for AR environment lighting understanding and photorealistic rendering.<!--]--></p><p><!--[-->Prior to WPI, I obtained my Bachelor&#39;s degree in Software Engineering from <a href="https://tjnu.edu.cn" rel="nofollow"><!--[-->Tianjin Normal University (TJNU)<!--]--></a>, Tianjin, China in 2019.
During my undergraduate study, I worked with <a href="https://www.researchgate.net/profile/Ziping-Zhao-2" rel="nofollow"><!--[-->Prof. Ziping Zhao<!--]--></a> on audio signal processing, speech emotion recognition, and affective computing.
In the past, I interned at <a href="https://baidu.com" rel="nofollow"><!--[-->Baidu<!--]--></a> (Summer 2018), <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Kuaishou Y-tech Graphics AI team<!--]--></a> in Spring 2022, and <a href="https://arvr.google.com" rel="nofollow"><!--[-->GoogleARVR<!--]--></a> in Summer/Fall 2022.<!--]--></p><h2 id="news"><a href="#news"><!--[-->üì∞ News<!--]--></a></h2><div class="[&amp;_li:nth-of-type(1n+7)]:hidden [&amp;_img]:hidden [&amp;_h1]:hidden [&amp;_h2]:hidden"><!--[--><div><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">News</h1><h2 class="dark:text-gray-200 text-center text-xl font-normal my-6 max-w-4xl mx-auto">üì¢ Latest: I&#39;m a Ph.D. candidate now!</h2><!--]--><p><!--[--><img src="/assets/img/me-news-google.png" alt><!--]--></p><ul><!--[--><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> üéâ Received student travel grant from HotMobile 2023, thank you!<!--]--></li><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> üéâ Passed my classes and research qualifications, I&#39;m a Ph.D. candidate now!<!--]--></li><li><!--[--><strong><!--[-->12/09/2022<!--]--></strong> üéâ One paper accepted by HotMobile 2023!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> üéâ I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> üéâ Our paper <a href="/project/litar" class=""><!--[-->LitAR<!--]--></a> is accepted by UbiComp 2022!<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> üéâ Our paper <a href="/project/privacy-preserving-reflection" class=""><!--[-->Privacy-preserving Reflection Rendering for Augmented Reality<!--]--></a> is accepted by ACM MM 2022!<!--]--></li><li><!--[--><strong><!--[-->03/04/2022<!--]--></strong> üéâ I will join Google as a research intern in the summer!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> üéâ I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/24/2021<!--]--></strong> ‚ú® We just released the <a href="/project/point-ar" class=""><!--[-->Xihe<!--]--></a> source code! Check our <a href="https://github.com/cake-lab/Xihe" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> üéâ I will join the <a href="http://chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern in next spring!<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> üéâ I&#39;m thrilled to announce that I will continue my Ph.D. study at <a href="https://cake.wpi.edu/" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> with <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> üéâ I&#39;ve presented my M.S. Thesis.<!--]--></li><li><!--[--><strong><!--[-->04/03/2021<!--]--></strong> ‚ú® <a href="/project/point-ar" class=""><!--[-->PointAR<!--]--></a> source code is now released! Check our <a href="https://github.com/cake-lab/PointAR" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->03/25/2021<!--]--></strong> üî• New paper on mobile system for 3D vision-based lighting estimation has been conditionally accepted to MobiSys 2021.<!--]--></li><li><!--[--><strong><!--[-->08/25/2020<!--]--></strong> üéôÔ∏è I presented our efficient mobile AR lighting estimation paper at ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->07/22/2020<!--]--></strong> üî• Our paper on efficient mobile AR lighting estimation neural network has been accepted to ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->03/03/2020<!--]--></strong> üéôÔ∏è I presented my poster at the HotMobile 2020 conference in Austin, TX.<!--]--></li><li><!--[--><strong><!--[-->02/01/2020<!--]--></strong> üî• Our poster on mobile AR lighting estimation has been accepted to HotMobile 2020.<!--]--></li><li><!--[--><strong><!--[-->08/26/2019<!--]--></strong> ü¶∏üèª‚Äç‚ôÇÔ∏è I joined Worcester Polytechnic Institute CakeLab.<!--]--></li><li><!--[--><strong><!--[-->10/26/2018<!--]--></strong> üéôÔ∏è I presented our paper on ASMMC-MMAC 2018 workshop.<!--]--></li><li><!--[--><strong><!--[-->10/15/2018<!--]--></strong> üèÜ I received Wang Kechang Technology innovation scholarship (&lt;1%).<!--]--></li><li><!--[--><strong><!--[-->10/13/2018<!--]--></strong> üèÜ I received annual special scholarship at Tianjin Normal University (top 5%).<!--]--></li><li><!--[--><strong><!--[-->08/15/2018<!--]--></strong> üî• Our paper about human speech emotion in spectrogram representation has submitted to ACM Multimedia 2018 ASMMC-MMAC workshop!<!--]--></li><li><!--[--><strong><!--[-->07/04/2018<!--]--></strong> üë®üèª‚Äçüíª I joined the DuerOS department at Baidu, Inc as a frontend software engineer intern.<!--]--></li><li><!--[--><strong><!--[-->09/30/2017<!--]--></strong> üèÜ Ô£ø I received third prize of the 2017 China national Mobile Innovation Contest (top 6%).<!--]--></li><li><!--[--><strong><!--[-->09/30/2016<!--]--></strong> üèÜ Ô£ø I received third prize of the 2016 China national Mobile Innovation Contest (top 10%).<!--]--></li><!--]--></ul></div><!--]--></div><p><!--[--><a href="/news/" class=""><!--[-->More news &gt;&gt;&gt;<!--]--></a><!--]--></p><h2 id="experiences"><a href="#experiences"><!--[-->ü•∑ Experiences<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-google.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/google.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Google, Mountain View, CA<!--]--></strong><br>
Student Researcher<br>
May 2022 - Present<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-wpi.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/wpi.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Worcester Polytechnic Institute, Worcester, MA<!--]--></strong><br>
Ph.D. Student in <a href="https://cake.wpi.edu" rel="nofollow"><!--[-->TheCakeLab<!--]--></a>, advised by <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a><br>
Aug 2021 - Present<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-kuaishou.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/kuaishou.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Kuaishou Technology, Palo Alto, CA<!--]--></strong><br>
Research Intern<br>
Jan, 2022 - May, 2022<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-baidu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/baidu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Baidu, Beijing, China<!--]--></strong><br>
Software Engineering Intern<br>
Jun, 2018 - Sept, 2018<!--]--></p><!--]--><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-tjnu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/tjnu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><!--[--><p><!--[--><strong><!--[-->Tianjin Normal University, Tianjin, China<!--]--></strong><br>
Bachelor of Engineering in Software Engineering<br>
Sept, 2015 - Jun, 2019<!--]--></p><!--]--><!--]--></div></div><h2 id="publications"><a href="#publications"><!--[-->üìÑ Publications<!--]--></a></h2><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">HotMobile&#39;23</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/10.1145/3572864.3580337">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2301.06143.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6/view?usp=sharing">Poster</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI/edit?usp=sharing">Slides</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/dual-light-hotmobile2023.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Sean Fanello, </span><span class="">Tian Guo</span><!--]--></div><div class="text-gray-500 text-sm">The Twenty-fourth International Workshop on Mobile Computing Systems and Applications</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="journal"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">IMWUT&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/abs/10.1145/3550291">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2301.06184.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE/edit?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/litar/">Code (coming soon)</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/litar/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">LitAR: Visually Coherent Lighting for Mobile Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/litar-ubicomp22.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Chongyang Ma, </span><span class="">Haibin Huang, </span><span class="">Tian Guo</span><!--]--></div><div class="text-gray-500 text-sm">The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ACMMM&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/abs/10.1145/3503161.3548386">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2207.03056">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk/edit?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/privacy-preserving-reflection">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Privacy-preserving Reflection Rendering for Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/privacy-preserving-reflection.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Sheng Wei, </span><span class="">Tian Guo</span><!--]--></div><div class="text-gray-500 text-sm">30th ACM International Conference on Multimedia</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="workshop"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">IEEEVRW&#39;22</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://ieeexplore.ieee.org/document/9757380">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA/view?usp=sharing">Poster</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/fusedar-ieeevrw22.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Tian Guo</span><!--]--></div><div class="text-gray-500 text-sm">IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">MobiSys&#39;21</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2106.15280">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa/view?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/xihe/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/xihe-mobisys2021.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Tian Guo</span><!--]--></div><div class="text-gray-500 text-sm">The 19th ACM International Conference on Mobile Systems, Applications, and Services</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><span class="text-red-600"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg" alt class="inline w-4 my-0 mt-[-0.2em]"> Artifacts Evaluated ‚Äì Functional v1.1</span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ECCV&#39;20</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2004.00006">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2004.00006">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp/view?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/point-ar/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">PointAR: Efficient Lighting Estimation for Mobile Augmented Reality</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/pointar-eccv.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Tian Guo</span><!--]--></div><div class="text-gray-500 text-sm">16th European Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="journal"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">Access&#39;19</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/deep-spectrum/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deep-spectrum-ieee.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="">Ziping Zhao, </span><span class="">Zhongtian Bao, </span><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Zixing Zhang, </span><span class="">Nicholas Cummins, </span><span class="">Zhao Ren, </span><span class="">Bj√∂rn Schuller</span><!--]--></div><div class="text-gray-500 text-sm">IEEE Access</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8 border-b-2" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">ASMMC-MMAC&#39;18</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/citation.cfm?doid=3267935.3267948">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/deep-spectrum/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Deep Spectrum Feature Representations for Speech Emotion Recognition</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deep-spectrum-acmmm.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="">Ziping Zhao, </span><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Zhongtian Bao, </span><span class="">Haishuai Wang, </span><span class="">Zixing Zhang, </span><span class="">Chao Li</span><!--]--></div><div class="text-gray-500 text-sm">4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-8 pb-8" type="conference"><div class="prose dark:prose-invert max-w-none font-normal"><div><span class="mr-2 bg-gray-200 text-black py-[0.2em] text-sm px-2">INTERSPEECH&#39;18</span><span class="mr-2">|</span><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1477.pdf">Paper</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/deep-spectrum/">Project</a></span><!--]--></div><div class="dark:text-white font-bold my-4 text-2xl md:text-2xl">Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition</div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-40 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deep-spectrum-interspeech.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span class="">Ziping Zhao, </span><span class="">Yu Zheng, </span><span class="">Zixing Zhang, </span><span class="">Haishuai Wang, </span><span class="font-bold dark:text-white underline">Yiqin Zhao, </span><span class="">Chao Li</span><!--]--></div><div class="text-gray-500 text-sm">Annual Conference of the International Speech Communication Association</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><div></div></div></div></div></div></div><h2 id="Ô∏è-services-and-awards"><a href="#Ô∏è-services-and-awards"><!--[-->‚ù§Ô∏è Services and Awards<!--]--></a></h2><p><!--[--><strong><!--[-->Academic services<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->UbiComp 2022 student volunteer.<!--]--></li><!--]--></ul><p><!--[--><strong><!--[-->Awards<!--]--></strong><!--]--></p><ul><!--[--><li><!--[-->ACM HotMobile 2023 Student Travel Grant.<!--]--></li><li><!--[-->ACM HotMobile 2020 Student Travel Grant.<!--]--></li><li><!--[-->China Collegiate Computing Contest, jointly held by Tsinghua University, Zhejiang University and Apple, Inc.<ul><!--[--><li><!--[-->2017 national third prize, top 6%<!--]--></li><li><!--[-->2016 national third prize, top 10%<!--]--></li><!--]--></ul><!--]--></li><li><!--[-->University Scholarship, Tianjin Normal University<ul><!--[--><li><!--[-->2018 - 2019 academic first grade scholarship, top 10%<!--]--></li><li><!--[-->Wang Kechang Culture and Technology Innovation Scholarship, ‚â§ 1%<!--]--></li><li><!--[-->2017 - 2018 academic year top grade scholarship, top 5%<!--]--></li><li><!--[-->2016 - 2017 academic year second grade scholarship, top 20%<!--]--></li><li><!--[-->2015 - 2016 academic year first grade scholarship, top 10%<!--]--></li><!--]--></ul><!--]--></li><!--]--></ul><h2 id="contacts"><a href="#contacts"><!--[-->üìß Contacts<!--]--></a></h2><span><a href="mailto:yiqinzhao@outlook.com" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/email.svg" alt=""><!--[-->Email<!--]--></a></span><span><a href="https://github.com/YiqinZhao" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/github.svg" alt=""><!--[-->GitHub<!--]--></a></span><span><a href="https://twitter.com/yiqin_zhao" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/twitter.svg" alt=""><!--[-->Twitter<!--]--></a></span><span><a href="https://www.instagram.com/yiqinzhao1996" class="mr-4"><img class="w-6 inline dark:invert mr-2 my-0" src="/assets/img/icons/instagram.svg" alt=""><!--[-->Instagram<!--]--></a></span></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> Ëµµ‰∏ÄÂã§ | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. Candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https//arvr.google.com">@GoogleVRAR</a> <br> Research Interests: Mobile System, AR, CV, CG </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:yiqinzhao@outlook.com">E-Mail</a> <br><a href="https://github.com/YiqinZhao">GitHub</a> <br><a href="https://twitter.com/yiqin_zhao">Twitter</a> <br><a href="https://www.instagram.com/yiqinzhao1996">Instagram</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> ¬© <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2023. Last updated: 2/26/2023. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div></div><!--]--><!--]--></div><!--]--><!--]--></div><script type="module">import p from "/_payload.js";window.__NUXT__={...p,...((function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U){return {state:{"$scolor-mode":{preference:v,value:v,unknown:j,forced:g},"$sdd-pages":{"/":{_path:t,_dir:e,_draft:g,_partial:g,_locale:e,_empty:g,title:w,description:e,hideTitle:j,disableFancyImage:j,body:{type:"root",children:[{type:a,tag:"index-header",props:{},children:[]},{type:a,tag:o,props:{id:x},children:[{type:b,value:y}]},{type:a,tag:c,props:{},children:[{type:b,value:"üîä "},{type:a,tag:"em",props:{},children:[{type:b,value:"My name pounces as: Yi-Chin"}]}]},{type:a,tag:c,props:{},children:[{type:b,value:"I am a fourth-year Computer Science M.S.\u002FPh.D. candidate at "},{type:a,tag:f,props:{href:"https:\u002F\u002Fwpi.edu",rel:[h]},children:[{type:b,value:"Worcester Polytechnic Institute (WPI)"}]},{type:b,value:" and a proud member of "},{type:a,tag:f,props:{href:"https:\u002F\u002Fcake-lab.github.io",rel:[h]},children:[{type:b,value:"The Cake Lab"}]},{type:b,value:" research group.\nI feel extremely fortunate to be advised by my kind and wise advisor "},{type:a,tag:f,props:{href:z,rel:[h]},children:[{type:b,value:A}]},{type:b,value:".\nI am interested in designing system supports and optimizations for Augmented Reality (AR) applications.\nMy recent research has a strong focus on designing system support for AR environment lighting understanding and photorealistic rendering."}]},{type:a,tag:c,props:{},children:[{type:b,value:"Prior to WPI, I obtained my Bachelor's degree in Software Engineering from "},{type:a,tag:f,props:{href:"https:\u002F\u002Ftjnu.edu.cn",rel:[h]},children:[{type:b,value:"Tianjin Normal University (TJNU)"}]},{type:b,value:", Tianjin, China in 2019.\nDuring my undergraduate study, I worked with "},{type:a,tag:f,props:{href:"https:\u002F\u002Fwww.researchgate.net\u002Fprofile\u002FZiping-Zhao-2",rel:[h]},children:[{type:b,value:"Prof. Ziping Zhao"}]},{type:b,value:" on audio signal processing, speech emotion recognition, and affective computing.\nIn the past, I interned at "},{type:a,tag:f,props:{href:"https:\u002F\u002Fbaidu.com",rel:[h]},children:[{type:b,value:"Baidu"}]},{type:b,value:" (Summer 2018), "},{type:a,tag:f,props:{href:"http:\u002F\u002Fwww.chongyangma.com\u002Fteam\u002Findex.html",rel:[h]},children:[{type:b,value:"Kuaishou Y-tech Graphics AI team"}]},{type:b,value:" in Spring 2022, and "},{type:a,tag:f,props:{href:"https:\u002F\u002Farvr.google.com",rel:[h]},children:[{type:b,value:"GoogleARVR"}]},{type:b,value:" in Summer\u002FFall 2022."}]},{type:a,tag:o,props:{id:B},children:[{type:b,value:C}]},{type:a,tag:"short-news",props:{},children:[]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{href:"\u002Fnews\u002F"},children:[{type:b,value:"More news \u003E\u003E\u003E"}]}]},{type:a,tag:o,props:{id:D},children:[{type:b,value:E}]},{type:a,tag:q,props:{icon:"google.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Google, Mountain View, CA"}]},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nStudent Researcher"},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nMay 2022 - Present"}]}]},{type:a,tag:q,props:{icon:"wpi.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Worcester Polytechnic Institute, Worcester, MA"}]},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nPh.D. Student in "},{type:a,tag:f,props:{href:"https:\u002F\u002Fcake.wpi.edu",rel:[h]},children:[{type:b,value:"TheCakeLab"}]},{type:b,value:", advised by "},{type:a,tag:f,props:{href:z,rel:[h]},children:[{type:b,value:A}]},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nAug 2021 - Present"}]}]},{type:a,tag:q,props:{icon:"kuaishou.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Kuaishou Technology, Palo Alto, CA"}]},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nResearch Intern"},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nJan, 2022 - May, 2022"}]}]},{type:a,tag:q,props:{icon:"baidu.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Baidu, Beijing, China"}]},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nSoftware Engineering Intern"},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nJun, 2018 - Sept, 2018"}]}]},{type:a,tag:q,props:{icon:"tjnu.png"},children:[{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Tianjin Normal University, Tianjin, China"}]},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nBachelor of Engineering in Software Engineering"},{type:a,tag:i,props:{},children:[]},{type:b,value:"\nSept, 2015 - Jun, 2019"}]}]},{type:a,tag:o,props:{id:F},children:[{type:b,value:G}]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3572864.3580337\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2301.06143.pdf\",\"Poster\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6\u002Fview?usp=sharing\",\"Slides\":\"https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI\u002Fedit?usp=sharing\"}",":authors":"[\"Yiqin Zhao\",\"Sean Fanello\",\"Tian Guo\"]",":venue":"{\"acronym\":\"HotMobile\",\"year\":2023,\"name\":\"The Twenty-fourth International Workshop on Mobile Computing Systems and Applications\"}",thumbnail:"dual-light-hotmobile2023.png",title:"Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality",type:p},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3550291\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2301.06184.pdf\",\"Slides\":\"https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE\u002Fedit?usp=sharing\",\"Code (coming soon)\":\"\u002Fproject\u002Flitar\u002F\",\"Project\":\"\u002Fproject\u002Flitar\u002F\"}",":authors":"[\"Yiqin Zhao\",\"Chongyang Ma\",\"Haibin Huang\",\"Tian Guo\"]",":venue":"{\"acronym\":\"IMWUT\",\"year\":2022,\"name\":\"The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\"}",thumbnail:"litar-ubicomp22.png",title:H,type:I},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3503161.3548386\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2207.03056\",\"Slides\":\"https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk\u002Fedit?usp=sharing\",\"Project\":\"\u002Fproject\u002Fprivacy-preserving-reflection\"}",":authors":"[\"Yiqin Zhao\",\"Sheng Wei\",\"Tian Guo\"]",":venue":"{\"acronym\":\"ACMMM\",\"year\":2022,\"name\":\"30th ACM International Conference on Multimedia\"}",thumbnail:"privacy-preserving-reflection.png",title:J,type:p},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fieeexplore.ieee.org\u002Fdocument\u002F9757380\",\"Poster\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA\u002Fview?usp=sharing\"}",":authors":u,":venue":"{\"acronym\":\"IEEEVRW\",\"year\":2022,\"name\":\"IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\"}",thumbnail:"fusedar-ieeevrw22.png",title:"FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering",type:"workshop"},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3458864.3467886?cid=99659479290\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2106.15280\",\"Slides\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa\u002Fview?usp=sharing\",\"Project\":\"\u002Fproject\u002Fxihe\u002F\"}",":authors":u,":venue":"{\"acronym\":\"MobiSys\",\"year\":2021,\"name\":\"The 19th ACM International Conference on Mobile Systems, Applications, and Services\"}",thumbnail:"xihe-mobisys2021.png",title:"Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality",type:p},children:[{type:a,tag:c,props:{},children:[{type:a,tag:"span",props:{className:["text-red-600"]},children:[{type:a,tag:"img",props:{className:["inline","w-4","my-0","mt-[-0.2em]"],src:"https:\u002F\u002Fwww.acm.org\u002Fbinaries\u002Fcontent\u002Fgallery\u002Facm\u002Fpublications\u002Freplication-badges\u002Fartifacts_evaluated_functional_dl.jpg"},children:[]},{type:b,value:" Artifacts Evaluated ‚Äì Functional v1.1"}]}]}]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.00006\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.00006\",\"Slides\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp\u002Fview?usp=sharing\",\"Project\":\"\u002Fproject\u002Fpoint-ar\u002F\"}",":authors":u,":venue":"{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"16th European Conference on Computer Vision\"}",thumbnail:"pointar-eccv.png",title:K,type:p},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fieeexplore.ieee.org\u002Fstamp\u002Fstamp.jsp?arnumber=8762126\",\"Project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Zhongtian Bao\",\"Yiqin Zhao\",\"Zixing Zhang\",\"Nicholas Cummins\",\"Zhao Ren\",\"Bj√∂rn Schuller\"]",":venue":"{\"acronym\":\"Access\",\"year\":2019,\"name\":\"IEEE Access\"}",thumbnail:"deep-spectrum-ieee.png",title:"Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",type:I},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fcitation.cfm?doid=3267935.3267948\",\"Project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Yiqin Zhao\",\"Zhongtian Bao\",\"Haishuai Wang\",\"Zixing Zhang\",\"Chao Li\"]",":venue":"{\"acronym\":\"ASMMC-MMAC\",\"year\":2018,\"name\":\"4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data\"}",thumbnail:"deep-spectrum-acmmm.png",title:L,type:p},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fwww.isca-speech.org\u002Farchive\u002FInterspeech_2018\u002Fpdfs\u002F1477.pdf\",\"Project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Yu Zheng\",\"Zixing Zhang\",\"Haishuai Wang\",\"Yiqin Zhao\",\"Chao Li\"]",":venue":"{\"acronym\":\"INTERSPEECH\",\"year\":2018,\"name\":\"Annual Conference of the International Speech Communication Association\"}",thumbnail:"deep-spectrum-interspeech.png",title:"Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition",type:p,":hideBottomBorder":"true"},children:[]},{type:a,tag:o,props:{id:M},children:[{type:b,value:N}]},{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Academic services"}]}]},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"UbiComp 2022 student volunteer."}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:m,props:{},children:[{type:b,value:"Awards"}]}]},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"ACM HotMobile 2023 Student Travel Grant."}]},{type:a,tag:d,props:{},children:[{type:b,value:"ACM HotMobile 2020 Student Travel Grant."}]},{type:a,tag:d,props:{},children:[{type:b,value:"China Collegiate Computing Contest, jointly held by Tsinghua University, Zhejiang University and Apple, Inc."},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"2017 national third prize, top 6%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2016 national third prize, top 10%"}]}]}]},{type:a,tag:d,props:{},children:[{type:b,value:"University Scholarship, Tianjin Normal University"},{type:a,tag:r,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"2018 - 2019 academic first grade scholarship, top 10%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"Wang Kechang Culture and Technology Innovation Scholarship, ‚â§ 1%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2017 - 2018 academic year top grade scholarship, top 5%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2016 - 2017 academic year second grade scholarship, top 20%"}]},{type:a,tag:d,props:{},children:[{type:b,value:"2015 - 2016 academic year first grade scholarship, top 10%"}]}]}]}]},{type:a,tag:o,props:{id:O},children:[{type:b,value:P}]},{type:a,tag:s,props:{icon:"email",url:"mailto:yiqinzhao@outlook.com"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"Email"}]}]},{type:a,tag:s,props:{icon:"github",url:"https:\u002F\u002Fgithub.com\u002FYiqinZhao"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"GitHub"}]}]},{type:a,tag:s,props:{icon:"twitter",url:"https:\u002F\u002Ftwitter.com\u002Fyiqin_zhao"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"Twitter"}]}]},{type:a,tag:s,props:{icon:"instagram",url:"https:\u002F\u002Fwww.instagram.com\u002Fyiqinzhao1996"},children:[{type:a,tag:c,props:{},children:[{type:b,value:"Instagram"}]}]}],toc:{title:e,searchDepth:l,depth:l,links:[{id:x,depth:l,text:y},{id:B,depth:l,text:C},{id:D,depth:l,text:E},{id:F,depth:l,text:G},{id:M,depth:l,text:N},{id:O,depth:l,text:P}]}},_type:Q,_id:"content:index.md",_source:R,_file:"index.md",_extension:S,layout:n}},"$sdd-surrounds":{"/":[null,{_path:T,_dir:e,_draft:g,_partial:g,_locale:e,_empty:g,title:U,description:e,leadingImage:"me-news-google.png",disableFancyImage:j,_type:Q,_id:"content:news.md",_source:R,_file:"news.md",_extension:S}]},"$sdd-globals":{},"$sdd-navigation":[{title:w,_path:t},{title:U,_path:T},{title:"Project",_path:"\u002Fproject",children:[{title:2048,_path:"\u002Fproject\u002F2048",layout:n},{title:L,_path:"\u002Fproject\u002Fdeep-spectrum",layout:n},{title:H,_path:"\u002Fproject\u002Flitar",layout:n},{title:K,_path:"\u002Fproject\u002Fpoint-ar",layout:n},{title:J,_path:"\u002Fproject\u002Fprivacy-preserving-reflection",layout:n},{title:"Xihe: A 3D Vision based Lighting Estimation for Mobile AR",_path:"\u002Fproject\u002Fxihe",layout:n}],layout:"cards"},{title:"Research",_path:"\u002Fresearch"}]},_errors:{},serverRendered:j,config:{public:{content:{locales:[],defaultLocale:e,integrity:1677447161162,experimental:{stripQueryParameters:g,clientDB:g},api:{baseURL:"\u002Fapi\u002F_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:e,documentDriven:{page:j,navigation:j,surround:j,globals:{},layoutFallbacks:["theme"],injectPage:j},host:e,trailingSlash:g,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:t,buildAssetsDir:"\u002F_nuxt\u002F",cdnURL:e}},prerenderedAt:void 0}}("element","text","p","li","","a",false,"nofollow","br",true,"publication-row",2,"strong","default","h2","conference","experience-row","ul","contact-item","\u002F","[\"Yiqin Zhao\",\"Tian Guo\"]","system","Home","Ô∏è-about-me","ü¶∏üèª‚Äç‚ôÇÔ∏è About Me","https:\u002F\u002Ftianguo.info","Prof. Tian Guo","news","üì∞ News","experiences","ü•∑ Experiences","publications","üìÑ Publications","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","journal","Privacy-preserving Reflection Rendering for Augmented Reality","PointAR: Efficient Lighting Estimation for Mobile Augmented Reality","Deep Spectrum Feature Representations for Speech Emotion Recognition","Ô∏è-services-and-awards","‚ù§Ô∏è Services and Awards","contacts","üìß Contacts","markdown","content","md","\u002Fnews","News")))}</script><script type="module" src="/_nuxt/entry.03c81885.js" crossorigin></script><script type="module" src="/_nuxt/document-driven.59779b55.js" crossorigin></script><script type="module" src="/_nuxt/default.52378aa3.js" crossorigin></script><script type="module" src="/_nuxt/Navigator.fbff0f57.js" crossorigin></script><script type="module" src="/_nuxt/ContentDoc.4e939d29.js" crossorigin></script><script type="module" src="/_nuxt/ContentQuery.7b5fdca2.js" crossorigin></script><script type="module" src="/_nuxt/Footer.0867a79c.js" crossorigin></script><script type="module" src="/_nuxt/ContentRenderer.18572a1b.js" crossorigin></script><script type="module" src="/_nuxt/ContentRendererMarkdown.63b1e8f7.js" crossorigin></script><script type="module" src="/_nuxt/IndexHeader.914a3b6a.js" crossorigin></script><script type="module" src="/_nuxt/ProseH2.1b2a03a6.js" crossorigin></script><script type="module" src="/_nuxt/ProseP.3b64db1e.js" crossorigin></script><script type="module" src="/_nuxt/ProseEm.98103bf7.js" crossorigin></script><script type="module" src="/_nuxt/ProseA.b022b3f1.js" crossorigin></script><script type="module" src="/_nuxt/ShortNews.30d88f17.js" crossorigin></script><script type="module" src="/_nuxt/ExperienceRow.d5439b57.js" crossorigin></script><script type="module" src="/_nuxt/ContentSlot.6b5fc1e8.js" crossorigin></script><script type="module" src="/_nuxt/ProseStrong.a8d6c6de.js" crossorigin></script><script type="module" src="/_nuxt/PublicationRow.cd0fbb77.js" crossorigin></script><script type="module" src="/_nuxt/ProseImg.099f33c5.js" crossorigin></script><script type="module" src="/_nuxt/ProseUl.df87ca14.js" crossorigin></script><script type="module" src="/_nuxt/ProseLi.a80c067a.js" crossorigin></script><script type="module" src="/_nuxt/ContactItem.275c840e.js" crossorigin></script><script type="module" src="/_nuxt/MarkdownHeader.279771fa.js" crossorigin></script></body>
</html>
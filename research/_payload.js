export default (function(a,b,c,d,e,f,g,h){return {data:{"content-query-JkF68eOZpz":{_path:"\u002Fresearch",_dir:e,_draft:f,_partial:f,_locale:"en",_empty:f,title:"Research",description:e,body:{type:"root",children:[{type:b,tag:"markdown-header",props:{subtitle:"ðŸ“¢ NEW: one paper accepted to HotMobile'23!",title:"Research Statement"},children:[]},{type:b,tag:c,props:{},children:[{type:a,value:"I'm a computer science Ph.D. candidate at "},{type:b,tag:d,props:{href:"https:\u002F\u002Fwpi.edu",rel:[g]},children:[{type:a,value:"Worcester Polytechnic Institute"}]},{type:a,value:" and a member of "},{type:b,tag:d,props:{href:"https:\u002F\u002Fcake.wpi.edu",rel:[g]},children:[{type:a,value:"TheCakeLab"}]},{type:a,value:".\nMy research interest lies in designing mobile augmented reality (AR) systems and algorithms. My recent research has a strong focus on improving mobile AR lighting estimation to enable photorealistic AR experiences. In the past, Iâ€™ve designed algorithms (HotMobileâ€™20, ECCVâ€™20) and edge-assisted real-time systems (IMWUTâ€™22, IEEEVRWâ€™22, MobiSysâ€™21, HotMobileâ€™22) for mobile AR environment lighting estimation. Iâ€™m also interested in security issues associated with photorealism in AR (ACM MMâ€™22). Iâ€™m fortunate to have conducted my research works in these areas under the guidance of Prof. Tian Guo alongside many wonderful collaborators, and Iâ€™m passionate to continue studying these problems in my Ph.D."}]},{type:b,tag:c,props:{},children:[{type:a,value:"Designing mobile systems for sensing environments has been a long-standing research topic. In recent years, emerging AR applications raise new standards for environment sensing on mobile devices in favor of the pursuit of photorealism. Lighting estimation, a task that aims to estimate omnidirectional lighting from limited environment observations, is at the key position of pursuing photorealistic and visually coherent rendering in AR. Traditionally, high-quality environment lighting is acquired using physical devices like light probes or 360Â° cameras. But such devices are often practically inaccessible to mobile devices and daily AR applications users."}]},{type:b,tag:c,props:{},children:[{type:a,value:"On a different vein, learning-based lighting estimation models have been adopted by the majority of AR frameworks in favor of their abilities to estimate environment lighting from single or multiple camera images. However, in complex real-world scenarios, such models often fail to adapt, as estimating 360Â° environment lighting from a low FoV camera image is a highly unconstrained task. My past research works on lighting estimation are focused on leveraging multi-sensor and temporal data to improve the estimation accuracy."}]},{type:b,tag:c,props:{},children:[{type:a,value:"Check out my research project details "},{type:b,tag:d,props:{href:"\u002Fproject\u002F"},children:[{type:a,value:"here"}]},{type:a,value:"."}]},{type:b,tag:c,props:{},children:[{type:b,tag:"em",props:{},children:[{type:a,value:"I'm generally interested in developing novel systems for future AR and HCI. If you are in interested in collaboration, "},{type:b,tag:d,props:{href:"mailto:yzhao11@wpi.edu"},children:[{type:a,value:"shoot me an email"}]},{type:a,value:"!"}]}]}],toc:{title:e,searchDepth:h,depth:h,links:[]}},_type:"markdown",_id:"content:research.md",_source:"content",_file:"research.md",_extension:"md"}},prerenderedAt:void 0}}("text","element","p","a","",false,"nofollow",2))
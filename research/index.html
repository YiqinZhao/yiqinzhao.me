<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Research - Yiqin Zhao</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
<meta property="og:title" content="Research"><link rel="preload" as="fetch" crossorigin="anonymous" href="/research/_payload.json"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.5757841a.js"><link rel="preload" as="style" href="/_nuxt/entry.5328c45a.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.c777ac5c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.a18295cb.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.e640ef4e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.524c43d1.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/index.a6ef77ff.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.2a335c16.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.587d4048.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.79639543.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.e530131f.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/qin-logo.5b1ed4b2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.5e98ba61.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.58adc26e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/asyncData.a75bc970.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.c12c47fe.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.4bdc8bde.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.26dd3982.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.c27b6911.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.4dd527a0.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/nuxt-link.3c26aa84.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseEm.438d7f48.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.5cf1691c.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.547b377d.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.28fd0842.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.6336bcf2.js"><link rel="stylesheet" href="/_nuxt/entry.5328c45a.css"><style>body{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}:is(.dark body){--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><div class="document-driven-page"><!--[--><!--[--><div class="hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class=""><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium flex items-center" href="/"><span class="transition-border hover:border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium flex items-center" href="/research/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Research</span></a><a class="pl-10 font-medium flex items-center" href="/project/"><span class="transition-border hover:border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Research</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Research</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="translate-y-[-100vh] fixed w-full h-full top-0 left-0 z-20 bg-black transition-opacity opacity-0"></div><div class="duration-0 translate-y-[-100vh] opacity-0 md:hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20 transition-transform duration-500"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="transition-color py-3" href="/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Home</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/research/"><div class="flex justify-between"><span class="dark:text-white font-medium">Research</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/project/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Projects</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="[&amp;_p_img]:md:max-w-[140%] [&amp;_p_img]:md:mx-[-20%] pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">Research Statement</h1><h2 class="dark:text-gray-200 text-center text-xl font-normal my-6 max-w-4xl mx-auto">ðŸ“¢ NEW: one paper accepted to HotMobile&#39;23!</h2><!--]--><p><!--[-->I&#39;m a computer science Ph.D. candidate at <a href="https://wpi.edu" rel="nofollow"><!--[-->Worcester Polytechnic Institute<!--]--></a> and a member of <a href="https://cake.wpi.edu" rel="nofollow"><!--[-->TheCakeLab<!--]--></a>.
My research interest lies in designing mobile augmented reality (AR) systems and algorithms. My recent research has a strong focus on improving mobile AR lighting estimation to enable photorealistic AR experiences. In the past, Iâ€™ve designed algorithms (HotMobileâ€™20, ECCVâ€™20) and edge-assisted real-time systems (IMWUTâ€™22, IEEEVRWâ€™22, MobiSysâ€™21, HotMobileâ€™22) for mobile AR environment lighting estimation. Iâ€™m also interested in security issues associated with photorealism in AR (ACM MMâ€™22). Iâ€™m fortunate to have conducted my research works in these areas under the guidance of Prof. Tian Guo alongside many wonderful collaborators, and Iâ€™m passionate to continue studying these problems in my Ph.D.<!--]--></p><p><!--[-->Designing mobile systems for sensing environments has been a long-standing research topic. In recent years, emerging AR applications raise new standards for environment sensing on mobile devices in favor of the pursuit of photorealism. Lighting estimation, a task that aims to estimate omnidirectional lighting from limited environment observations, is at the key position of pursuing photorealistic and visually coherent rendering in AR. Traditionally, high-quality environment lighting is acquired using physical devices like light probes or 360Â° cameras. But such devices are often practically inaccessible to mobile devices and daily AR applications users.<!--]--></p><p><!--[-->On a different vein, learning-based lighting estimation models have been adopted by the majority of AR frameworks in favor of their abilities to estimate environment lighting from single or multiple camera images. However, in complex real-world scenarios, such models often fail to adapt, as estimating 360Â° environment lighting from a low FoV camera image is a highly unconstrained task. My past research works on lighting estimation are focused on leveraging multi-sensor and temporal data to improve the estimation accuracy.<!--]--></p><p><!--[-->Check out my research project details <a href="/project/" class=""><!--[-->here<!--]--></a>.<!--]--></p><p><!--[--><em><!--[-->I&#39;m generally interested in developing novel systems for future AR and HCI. If you are in interested in collaboration, <a href="mailto:yzhao11@wpi.edu" rel="noopener noreferrer"><!--[-->shoot me an email<!--]--></a>!<!--]--></em><!--]--></p></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> èµµä¸€å‹¤ | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. Candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https//arvr.google.com">@GoogleVRAR</a> <br> Research Interests: Mobile System, AR, CV, CG </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:yiqinzhao@outlook.com">E-Mail</a> <br><a href="https://github.com/YiqinZhao">GitHub</a> <br><a href="https://twitter.com/yiqin_zhao">Twitter</a> <br><a href="https://www.instagram.com/yiqinzhao1996">Instagram</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> Â© <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2023. Last updated: 5/18/2023. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div></div><!--]--></div><!--]--></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true" data-src="/research/_payload.json">[{"state":1,"_errors":140,"serverRendered":5,"prerenderedAt":-1},["Reactive",2],{"$scolor-mode":3,"$sdd-pages":7,"$sdd-surrounds":98,"$sdd-globals":110,"$sdd-navigation":111},{"preference":4,"value":4,"unknown":5,"forced":6},"system",true,false,{"/research":8},{"_path":9,"_dir":10,"_draft":6,"_partial":6,"_locale":10,"_empty":6,"title":11,"description":10,"body":12,"_type":92,"_id":93,"_source":94,"_file":95,"_extension":96,"layout":97},"/research","","Research",{"type":13,"children":14,"toc":89},"root",[15,22,49,54,59,72],{"type":16,"tag":17,"props":18,"children":21},"element","markdown-header",{"subtitle":19,"title":20},"ðŸ“¢ NEW: one paper accepted to HotMobile'23!","Research Statement",[],{"type":16,"tag":23,"props":24,"children":25},"p",{},[26,29,38,40,47],{"type":27,"value":28},"text","I'm a computer science Ph.D. candidate at ",{"type":16,"tag":30,"props":31,"children":35},"a",{"href":32,"rel":33},"https://wpi.edu",[34],"nofollow",[36],{"type":27,"value":37},"Worcester Polytechnic Institute",{"type":27,"value":39}," and a member of ",{"type":16,"tag":30,"props":41,"children":44},{"href":42,"rel":43},"https://cake.wpi.edu",[34],[45],{"type":27,"value":46},"TheCakeLab",{"type":27,"value":48},".\nMy research interest lies in designing mobile augmented reality (AR) systems and algorithms. My recent research has a strong focus on improving mobile AR lighting estimation to enable photorealistic AR experiences. In the past, Iâ€™ve designed algorithms (HotMobileâ€™20, ECCVâ€™20) and edge-assisted real-time systems (IMWUTâ€™22, IEEEVRWâ€™22, MobiSysâ€™21, HotMobileâ€™22) for mobile AR environment lighting estimation. Iâ€™m also interested in security issues associated with photorealism in AR (ACM MMâ€™22). Iâ€™m fortunate to have conducted my research works in these areas under the guidance of Prof. Tian Guo alongside many wonderful collaborators, and Iâ€™m passionate to continue studying these problems in my Ph.D.",{"type":16,"tag":23,"props":50,"children":51},{},[52],{"type":27,"value":53},"Designing mobile systems for sensing environments has been a long-standing research topic. In recent years, emerging AR applications raise new standards for environment sensing on mobile devices in favor of the pursuit of photorealism. Lighting estimation, a task that aims to estimate omnidirectional lighting from limited environment observations, is at the key position of pursuing photorealistic and visually coherent rendering in AR. Traditionally, high-quality environment lighting is acquired using physical devices like light probes or 360Â° cameras. But such devices are often practically inaccessible to mobile devices and daily AR applications users.",{"type":16,"tag":23,"props":55,"children":56},{},[57],{"type":27,"value":58},"On a different vein, learning-based lighting estimation models have been adopted by the majority of AR frameworks in favor of their abilities to estimate environment lighting from single or multiple camera images. However, in complex real-world scenarios, such models often fail to adapt, as estimating 360Â° environment lighting from a low FoV camera image is a highly unconstrained task. My past research works on lighting estimation are focused on leveraging multi-sensor and temporal data to improve the estimation accuracy.",{"type":16,"tag":23,"props":60,"children":61},{},[62,64,70],{"type":27,"value":63},"Check out my research project details ",{"type":16,"tag":30,"props":65,"children":67},{"href":66},"/project/",[68],{"type":27,"value":69},"here",{"type":27,"value":71},".",{"type":16,"tag":23,"props":73,"children":74},{},[75],{"type":16,"tag":76,"props":77,"children":78},"em",{},[79,81,87],{"type":27,"value":80},"I'm generally interested in developing novel systems for future AR and HCI. If you are in interested in collaboration, ",{"type":16,"tag":30,"props":82,"children":84},{"href":83},"mailto:yzhao11@wpi.edu",[85],{"type":27,"value":86},"shoot me an email",{"type":27,"value":88},"!",{"title":10,"searchDepth":90,"depth":90,"links":91},2,[],"markdown","content:research.md","content","research.md","md","default",{"/research":99},[100,109],{"_path":101,"_dir":102,"_draft":6,"_partial":6,"_locale":10,"_empty":6,"title":103,"description":10,"date":104,"thumbnail":105,"tag":106,"layout":97,"_type":92,"_id":107,"_source":94,"_file":108,"_extension":96},"/project/xihe","project","Xihe: A 3D Vision based Lighting Estimation for Mobile AR","2021-08-23T00:00:00.000Z","/assets/img/project/xihe/thumbnail.png","research","content:project:xihe.md","project/xihe.md",null,{},[112,115,118,139],{"title":113,"_path":114},"Home","/",{"title":116,"_path":117},"News","/news",{"title":119,"_path":120,"children":121,"layout":138},"Project","/project",[122,125,128,131,134,137],{"title":123,"_path":124,"layout":97},2048,"/project/2048",{"title":126,"_path":127,"layout":97},"Deep Spectrum Feature Representations for Speech Emotion Recognition","/project/deep-spectrum",{"title":129,"_path":130,"layout":97},"LitAR: Visually Coherent Lighting for Mobile Augmented Reality","/project/litar",{"title":132,"_path":133,"layout":97},"PointAR: Efficient Lighting Estimation for Mobile Augmented Reality","/project/point-ar",{"title":135,"_path":136,"layout":97},"Privacy-preserving Reflection Rendering for Augmented Reality","/project/privacy-preserving-reflection",{"title":103,"_path":101,"layout":97},"cards",{"title":11,"_path":9},["Reactive",141],{"content-query-JkF68eOZpz":109}]</script><script>window.__NUXT__={};window.__NUXT__.config={public:{content:{locales:[],defaultLocale:"",integrity:1684421366486,experimental:{stripQueryParameters:false,clientDB:false,advancedIgnoresPattern:false},api:{baseURL:"/api/_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:"",documentDriven:{page:true,navigation:true,surround:true,globals:{},layoutFallbacks:["theme"],injectPage:true},host:"",trailingSlash:false,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:"/",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script><script type="module" src="/_nuxt/entry.5757841a.js" crossorigin></script></body>
</html>
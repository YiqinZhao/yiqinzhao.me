[{"data":1,"prerenderedAt":167},["Reactive",2],{"content-query-FpPJaOzdgK":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":5,"title":7,"description":5,"body":8,"_type":162,"_id":163,"_source":164,"_file":165,"_extension":166},"/publication","",false,"Publications",{"type":9,"children":10,"toc":159},"root",[11,16],{"type":12,"tag":13,"props":14,"children":15},"element","MarkdownHeader",{"title":7},[],{"type":12,"tag":17,"props":18,"children":19},"UltraWideRow",{},[20,30,38,46,68,76,85,93,101,127,134,142,150],{"type":12,"tag":21,"props":22,"children":29},"PublicationRow",{":artifactLinks":23,":authors":24,":venue":25,"thumbnail":26,"title":27,"type":28},"{\"arXiv\":\"https://arxiv.org/pdf/2411.02179\"}","[\"Yiqin Zhao\",\"Mallesham Dasri\",\"Tian Guo\"]","{\"acronym\":\"arXiv\",\"year\":2024,\"name\":\"arXiv\"}","clear.png","CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality","demo",[],{"type":12,"tag":21,"props":31,"children":37},{":artifactLinks":32,":authors":33,":venue":34,"thumbnail":35,"title":36,"type":28},"{\"Website\":\"https://cake.wpi.edu/ARFlow/\",\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3638550.3643617\",\"Code\":\"https://github.com/cake-lab/ARFlow\"}","[\"Yiqin Zhao\",\"Tian Guo\"]","{\"acronym\":\"HotMobile\",\"year\":2024,\"name\":\"25th International Workshop on Mobile Computing Systems and Applications\"}","arflow.jpeg","Demo: ARFlow: A Framework for Simplifying AR Experimentation Workflow",[],{"type":12,"tag":21,"props":39,"children":45},{":artifactLinks":40,":authors":41,":venue":34,"thumbnail":42,"title":43,"type":44},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3638550.3641122\",\"arXiv (extended version)\":\"https://arxiv.org/abs/2310.14437\"}","[\"Ashkan Ganj\",\"Yiqin Zhao\",\"Hang Su\",\"Tian Guo\"]","depth-estimation.png","Mobile AR Depth Estimation: Challenges & Prospects","conference",[],{"type":12,"tag":21,"props":47,"children":53},{":artifactLinks":48,":authors":49,":venue":50,"thumbnail":51,"title":52,"type":44},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3615452.3617941\",\"arXiv\":\"https://arxiv.org/abs/2307.08587\",\"Website\":\"https://cake.wpi.edu/expar/\"}","[\"Ashkan Ganj\",\"Yiqin Zhao\",\"Federico Galbiati\",\"Tian Guo\"]","{\"acronym\":\"ImmerCom\",\"year\":2023,\"name\":\"1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems\"}","expar.png","Toward Scalable and Controllable AR Experimentation",[54],{"type":12,"tag":55,"props":56,"children":57},"p",{},[58],{"type":12,"tag":59,"props":60,"children":64},"span",{"className":61},[62,63],"text-red-600","font-bold",[65],{"type":66,"value":67},"text","üèÜ Best Paper Runner-up.",{"type":12,"tag":21,"props":69,"children":75},{":artifactLinks":70,":authors":71,":venue":72,"thumbnail":73,"title":74,"type":44},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3572864.3580337\",\"arXiv\":\"https://arxiv.org/pdf/2301.06143.pdf\",\"Poster\":\"https://drive.google.com/file/d/1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6/view?usp=sharing\",\"Slides\":\"https://docs.google.com/presentation/d/1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI/edit?usp=sharing\"}","[\"Yiqin Zhao\",\"Sean Fanello\",\"Tian Guo\"]","{\"acronym\":\"HotMobile\",\"year\":2023,\"name\":\"The Twenty-fourth International Workshop on Mobile Computing Systems and Applications\"}","dual-light-hotmobile2023.png","Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality",[],{"type":12,"tag":21,"props":77,"children":84},{":artifactLinks":78,":authors":79,":venue":80,"thumbnail":81,"title":82,"type":83},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3550291\",\"arXiv\":\"https://arxiv.org/pdf/2301.06184.pdf\",\"Slides\":\"https://docs.google.com/presentation/d/1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE/edit?usp=sharing\",\"Code\":\"https://github.com/cake-lab/LitAR\",\"Website\":\"/project/litar/\"}","[\"Yiqin Zhao\",\"Chongyang Ma\",\"Haibin Huang\",\"Tian Guo\"]","{\"acronym\":\"IMWUT\",\"year\":2022,\"name\":\"The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\"}","litar-ubicomp22.png","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","journal",[],{"type":12,"tag":21,"props":86,"children":92},{":artifactLinks":87,":authors":88,":venue":89,"thumbnail":90,"title":91,"type":44},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3503161.3548386\",\"arXiv\":\"https://arxiv.org/abs/2207.03056\",\"Slides\":\"https://docs.google.com/presentation/d/1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk/edit?usp=sharing\",\"Website\":\"/project/privacy-preserving-reflection\"}","[\"Yiqin Zhao\",\"Sheng Wei\",\"Tian Guo\"]","{\"acronym\":\"ACMMM\",\"year\":2022,\"name\":\"30th ACM International Conference on Multimedia\"}","privacy-preserving-reflection.png","Privacy-preserving Reflection Rendering for Augmented Reality",[],{"type":12,"tag":21,"props":94,"children":100},{":artifactLinks":95,":authors":33,":venue":96,"thumbnail":97,"title":98,"type":99},"{\"Proceeding\":\"https://ieeexplore.ieee.org/document/9757380\",\"Poster\":\"https://drive.google.com/file/d/1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA/view?usp=sharing\"}","{\"acronym\":\"IEEEVRW\",\"year\":2022,\"name\":\"IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\"}","fusedar-ieeevrw22.png","FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering","workshop",[],{"type":12,"tag":21,"props":102,"children":107},{":artifactLinks":103,":authors":33,":venue":104,"thumbnail":105,"title":106,"type":44},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290\",\"arXiv\":\"https://arxiv.org/abs/2106.15280\",\"Slides\":\"https://drive.google.com/file/d/1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa/view?usp=sharing\",\"Website\":\"/project/xihe/\"}","{\"acronym\":\"MobiSys\",\"year\":2021,\"name\":\"The 19th ACM International Conference on Mobile Systems, Applications, and Services\"}","xihe-mobisys2021.png","Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality",[108],{"type":12,"tag":55,"props":109,"children":110},{},[111],{"type":12,"tag":59,"props":112,"children":114},{"className":113},[62],[115,125],{"type":12,"tag":116,"props":117,"children":124},"img",{"className":118,"src":123},[119,120,121,122],"inline","w-4","my-0","mt-[-0.2em]","/assets/img/icons/artifacts_evaluated_functional_dl.jpg",[],{"type":66,"value":126}," Artifacts Evaluated ‚Äì Functional v1.1",{"type":12,"tag":21,"props":128,"children":133},{":artifactLinks":129,":authors":33,":venue":130,"thumbnail":131,"title":132,"type":44},"{\"Proceeding\":\"https://arxiv.org/abs/2004.00006\",\"arXiv\":\"https://arxiv.org/abs/2004.00006\",\"Slides\":\"https://drive.google.com/file/d/1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp/view?usp=sharing\",\"Website\":\"/project/point-ar/\"}","{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"16th European Conference on Computer Vision\"}","pointar-eccv.png","PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",[],{"type":12,"tag":21,"props":135,"children":141},{":artifactLinks":136,":authors":137,":venue":138,"thumbnail":139,"title":140,"type":83},"{\"Proceeding\":\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Zhongtian Bao\",\"Yiqin Zhao\",\"Zixing Zhang\",\"Nicholas Cummins\",\"Zhao Ren\",\"Bj√∂rn Schuller\"]","{\"acronym\":\"Access\",\"year\":2019,\"name\":\"IEEE Access\"}","deep-spectrum-ieee.png","Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",[],{"type":12,"tag":21,"props":143,"children":149},{":artifactLinks":144,":authors":145,":venue":146,"thumbnail":147,"title":148,"type":44},"{\"Proceeding\":\"https://dl.acm.org/citation.cfm?doid=3267935.3267948\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yiqin Zhao\",\"Zhongtian Bao\",\"Haishuai Wang\",\"Zixing Zhang\",\"Chao Li\"]","{\"acronym\":\"ASMMC-MMAC\",\"year\":2018,\"name\":\"4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data\"}","deep-spectrum-acmmm.png","Deep Spectrum Feature Representations for Speech Emotion Recognition",[],{"type":12,"tag":21,"props":151,"children":158},{":artifactLinks":152,":authors":153,":venue":154,"thumbnail":155,"title":156,"type":44,":hideBottomBorder":157},"{\"Proceeding\":\"https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1477.html\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yu Zheng\",\"Zixing Zhang\",\"Haishuai Wang\",\"Yiqin Zhao\",\"Chao Li\"]","{\"acronym\":\"INTERSPEECH\",\"year\":2018,\"name\":\"Annual Conference of the International Speech Communication Association\"}","deep-spectrum-interspeech.png","Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition","true",[],{"title":5,"searchDepth":160,"depth":160,"links":161},2,[],"markdown","content:publication.md","content","publication.md","md",1737647961262]
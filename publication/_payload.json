[{"data":1,"prerenderedAt":159},["Reactive",2],{"content-query-FpPJaOzdgK":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":5,"title":7,"description":5,"body":8,"_type":154,"_id":155,"_source":156,"_file":157,"_extension":158},"/publication","",false,"Publications",{"type":9,"children":10,"toc":151},"root",[11,16],{"type":12,"tag":13,"props":14,"children":15},"element","MarkdownHeader",{"title":7},[],{"type":12,"tag":17,"props":18,"children":19},"UltraWideRow",{},[20,30,38,60,68,77,85,93,119,126,134,142],{"type":12,"tag":21,"props":22,"children":29},"PublicationRow",{":artifactLinks":23,":authors":24,":venue":25,"thumbnail":26,"title":27,"type":28},"{\"Website\":\"https://cake.wpi.edu/ARFlow/\",\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3638550.3643617\",\"Code\":\"https://github.com/cake-lab/ARFlow\"}","[\"Yiqin Zhao\",\"Tian Guo\"]","{\"acronym\":\"HotMobile\",\"year\":2024,\"name\":\"25th International Workshop on Mobile Computing Systems and Applications\"}","arflow.jpeg","Demo: ARFlow: A Framework for Simplifying AR Experimentation Workflow","demo",[],{"type":12,"tag":21,"props":31,"children":37},{":artifactLinks":32,":authors":33,":venue":25,"thumbnail":34,"title":35,"type":36},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3638550.3641122\",\"arXiv (extended version)\":\"https://arxiv.org/abs/2310.14437\"}","[\"Ashkan Ganj\",\"Yiqin Zhao\",\"Hang Su\",\"Tian Guo\"]","depth-estimation.png","Mobile AR Depth Estimation: Challenges & Prospects","conference",[],{"type":12,"tag":21,"props":39,"children":45},{":artifactLinks":40,":authors":41,":venue":42,"thumbnail":43,"title":44,"type":36},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3615452.3617941\",\"arXiv\":\"https://arxiv.org/abs/2307.08587\",\"Website\":\"https://cake.wpi.edu/expar/\"}","[\"Ashkan Ganj\",\"Yiqin Zhao\",\"Federico Galbiati\",\"Tian Guo\"]","{\"acronym\":\"ImmerCom\",\"year\":2023,\"name\":\"1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems\"}","expar.png","Toward Scalable and Controllable AR Experimentation",[46],{"type":12,"tag":47,"props":48,"children":49},"p",{},[50],{"type":12,"tag":51,"props":52,"children":56},"span",{"className":53},[54,55],"text-red-600","font-bold",[57],{"type":58,"value":59},"text","üèÜ Best Paper Runner-up.",{"type":12,"tag":21,"props":61,"children":67},{":artifactLinks":62,":authors":63,":venue":64,"thumbnail":65,"title":66,"type":36},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3572864.3580337\",\"arXiv\":\"https://arxiv.org/pdf/2301.06143.pdf\",\"Poster\":\"https://drive.google.com/file/d/1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6/view?usp=sharing\",\"Slides\":\"https://docs.google.com/presentation/d/1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI/edit?usp=sharing\"}","[\"Yiqin Zhao\",\"Sean Fanello\",\"Tian Guo\"]","{\"acronym\":\"HotMobile\",\"year\":2023,\"name\":\"The Twenty-fourth International Workshop on Mobile Computing Systems and Applications\"}","dual-light-hotmobile2023.png","Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality",[],{"type":12,"tag":21,"props":69,"children":76},{":artifactLinks":70,":authors":71,":venue":72,"thumbnail":73,"title":74,"type":75},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3550291\",\"arXiv\":\"https://arxiv.org/pdf/2301.06184.pdf\",\"Slides\":\"https://docs.google.com/presentation/d/1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE/edit?usp=sharing\",\"Code\":\"https://github.com/cake-lab/LitAR\",\"Website\":\"/project/litar/\"}","[\"Yiqin Zhao\",\"Chongyang Ma\",\"Haibin Huang\",\"Tian Guo\"]","{\"acronym\":\"IMWUT\",\"year\":2022,\"name\":\"The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\"}","litar-ubicomp22.png","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","journal",[],{"type":12,"tag":21,"props":78,"children":84},{":artifactLinks":79,":authors":80,":venue":81,"thumbnail":82,"title":83,"type":36},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3503161.3548386\",\"arXiv\":\"https://arxiv.org/abs/2207.03056\",\"Slides\":\"https://docs.google.com/presentation/d/1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk/edit?usp=sharing\",\"Website\":\"/project/privacy-preserving-reflection\"}","[\"Yiqin Zhao\",\"Sheng Wei\",\"Tian Guo\"]","{\"acronym\":\"ACMMM\",\"year\":2022,\"name\":\"30th ACM International Conference on Multimedia\"}","privacy-preserving-reflection.png","Privacy-preserving Reflection Rendering for Augmented Reality",[],{"type":12,"tag":21,"props":86,"children":92},{":artifactLinks":87,":authors":24,":venue":88,"thumbnail":89,"title":90,"type":91},"{\"Proceeding\":\"https://ieeexplore.ieee.org/document/9757380\",\"Poster\":\"https://drive.google.com/file/d/1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA/view?usp=sharing\"}","{\"acronym\":\"IEEEVRW\",\"year\":2022,\"name\":\"IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\"}","fusedar-ieeevrw22.png","FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering","workshop",[],{"type":12,"tag":21,"props":94,"children":99},{":artifactLinks":95,":authors":24,":venue":96,"thumbnail":97,"title":98,"type":36},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290\",\"arXiv\":\"https://arxiv.org/abs/2106.15280\",\"Slides\":\"https://drive.google.com/file/d/1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa/view?usp=sharing\",\"Website\":\"/project/xihe/\"}","{\"acronym\":\"MobiSys\",\"year\":2021,\"name\":\"The 19th ACM International Conference on Mobile Systems, Applications, and Services\"}","xihe-mobisys2021.png","Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality",[100],{"type":12,"tag":47,"props":101,"children":102},{},[103],{"type":12,"tag":51,"props":104,"children":106},{"className":105},[54],[107,117],{"type":12,"tag":108,"props":109,"children":116},"img",{"className":110,"src":115},[111,112,113,114],"inline","w-4","my-0","mt-[-0.2em]","/assets/img/icons/artifacts_evaluated_functional_dl.jpg",[],{"type":58,"value":118}," Artifacts Evaluated ‚Äì Functional v1.1",{"type":12,"tag":21,"props":120,"children":125},{":artifactLinks":121,":authors":24,":venue":122,"thumbnail":123,"title":124,"type":36},"{\"Proceeding\":\"https://arxiv.org/abs/2004.00006\",\"arXiv\":\"https://arxiv.org/abs/2004.00006\",\"Slides\":\"https://drive.google.com/file/d/1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp/view?usp=sharing\",\"Website\":\"/project/point-ar/\"}","{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"16th European Conference on Computer Vision\"}","pointar-eccv.png","PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",[],{"type":12,"tag":21,"props":127,"children":133},{":artifactLinks":128,":authors":129,":venue":130,"thumbnail":131,"title":132,"type":75},"{\"Proceeding\":\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Zhongtian Bao\",\"Yiqin Zhao\",\"Zixing Zhang\",\"Nicholas Cummins\",\"Zhao Ren\",\"Bj√∂rn Schuller\"]","{\"acronym\":\"Access\",\"year\":2019,\"name\":\"IEEE Access\"}","deep-spectrum-ieee.png","Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",[],{"type":12,"tag":21,"props":135,"children":141},{":artifactLinks":136,":authors":137,":venue":138,"thumbnail":139,"title":140,"type":36},"{\"Proceeding\":\"https://dl.acm.org/citation.cfm?doid=3267935.3267948\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yiqin Zhao\",\"Zhongtian Bao\",\"Haishuai Wang\",\"Zixing Zhang\",\"Chao Li\"]","{\"acronym\":\"ASMMC-MMAC\",\"year\":2018,\"name\":\"4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data\"}","deep-spectrum-acmmm.png","Deep Spectrum Feature Representations for Speech Emotion Recognition",[],{"type":12,"tag":21,"props":143,"children":150},{":artifactLinks":144,":authors":145,":venue":146,"thumbnail":147,"title":148,"type":36,":hideBottomBorder":149},"{\"Proceeding\":\"https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1477.html\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yu Zheng\",\"Zixing Zhang\",\"Haishuai Wang\",\"Yiqin Zhao\",\"Chao Li\"]","{\"acronym\":\"INTERSPEECH\",\"year\":2018,\"name\":\"Annual Conference of the International Speech Communication Association\"}","deep-spectrum-interspeech.png","Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition","true",[],{"title":5,"searchDepth":152,"depth":152,"links":153},2,[],"markdown","content:publication.md","content","publication.md","md",1732028745007]
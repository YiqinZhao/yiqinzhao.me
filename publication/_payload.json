[{"data":1,"prerenderedAt":155},["Reactive",2],{"content-query-FpPJaOzdgK":3},{"_path":4,"_dir":5,"_draft":6,"_partial":6,"_locale":5,"title":7,"description":5,"body":8,"_type":150,"_id":151,"_source":152,"_file":153,"_extension":154},"/publication","",false,"Publications",{"type":9,"children":10,"toc":147},"root",[11,16,26,33,55,63,72,80,89,115,122,130,138],{"type":12,"tag":13,"props":14,"children":15},"element","MarkdownHeader",{"title":7},[],{"type":12,"tag":17,"props":18,"children":25},"PublicationRow",{":artifactLinks":19,":authors":20,":venue":21,"thumbnail":22,"title":23,"type":24},"{\"arXiv\":\"https://arxiv.org/abs/2310.10821\"}","[\"Yiqin Zhao\",\"Ashkan Ganj\",\"Tian Guo\"]","{\"acronym\":\"arXiv\",\"year\":2023,\"name\":\"In submission.\"}","get-a-sense-hotmobile.png","Get-A-Sense: Designing Spatial Context Awareness for Mobile AR Environment Understanding","conference",[],{"type":12,"tag":17,"props":27,"children":32},{":artifactLinks":28,":authors":29,":venue":21,"thumbnail":30,"title":31,"type":24},"{\"arXiv\":\"https://arxiv.org/abs/2310.14437\"}","[\"Ashkan Ganj\",\"Yiqin Zhao\",\"Hang Su\",\"Tian Guo\"]","depth-estimation.png","Mobile AR Depth Estimation: Challenges & Prospects -- Extended Version",[],{"type":12,"tag":17,"props":34,"children":40},{":artifactLinks":35,":authors":36,":venue":37,"thumbnail":38,"title":39,"type":24},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3615452.3617941\",\"arXiv\":\"https://arxiv.org/abs/2307.08587\",\"Website\":\"https://cake.wpi.edu/expar/\"}","[\"Ashkan Ganj\",\"Yiqin Zhao\",\"Federico Galbiati\",\"Tian Guo\"]","{\"acronym\":\"ImmerCom\",\"year\":2023,\"name\":\"1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems\"}","expar.png","Toward Scalable and Controllable AR Experimentation",[41],{"type":12,"tag":42,"props":43,"children":44},"p",{},[45],{"type":12,"tag":46,"props":47,"children":51},"span",{"className":48},[49,50],"text-red-600","font-bold",[52],{"type":53,"value":54},"text","üèÜ Best Paper Runner-up.",{"type":12,"tag":17,"props":56,"children":62},{":artifactLinks":57,":authors":58,":venue":59,"thumbnail":60,"title":61,"type":24},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3572864.3580337\",\"arXiv\":\"https://arxiv.org/pdf/2301.06143.pdf\",\"Poster\":\"https://drive.google.com/file/d/1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6/view?usp=sharing\",\"Slides\":\"https://docs.google.com/presentation/d/1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI/edit?usp=sharing\"}","[\"Yiqin Zhao\",\"Sean Fanello\",\"Tian Guo\"]","{\"acronym\":\"HotMobile\",\"year\":2023,\"name\":\"The Twenty-fourth International Workshop on Mobile Computing Systems and Applications\"}","dual-light-hotmobile2023.png","Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality",[],{"type":12,"tag":17,"props":64,"children":71},{":artifactLinks":65,":authors":66,":venue":67,"thumbnail":68,"title":69,"type":70},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3550291\",\"arXiv\":\"https://arxiv.org/pdf/2301.06184.pdf\",\"Slides\":\"https://docs.google.com/presentation/d/1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE/edit?usp=sharing\",\"Code\":\"https://github.com/cake-lab/LitAR\",\"Website\":\"/project/litar/\"}","[\"Yiqin Zhao\",\"Chongyang Ma\",\"Haibin Huang\",\"Tian Guo\"]","{\"acronym\":\"IMWUT\",\"year\":2022,\"name\":\"The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\"}","litar-ubicomp22.png","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","journal",[],{"type":12,"tag":17,"props":73,"children":79},{":artifactLinks":74,":authors":75,":venue":76,"thumbnail":77,"title":78,"type":24},"{\"Proceeding\":\"https://dl.acm.org/doi/abs/10.1145/3503161.3548386\",\"arXiv\":\"https://arxiv.org/abs/2207.03056\",\"Slides\":\"https://docs.google.com/presentation/d/1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk/edit?usp=sharing\",\"Website\":\"/project/privacy-preserving-reflection\"}","[\"Yiqin Zhao\",\"Sheng Wei\",\"Tian Guo\"]","{\"acronym\":\"ACMMM\",\"year\":2022,\"name\":\"30th ACM International Conference on Multimedia\"}","privacy-preserving-reflection.png","Privacy-preserving Reflection Rendering for Augmented Reality",[],{"type":12,"tag":17,"props":81,"children":88},{":artifactLinks":82,":authors":83,":venue":84,"thumbnail":85,"title":86,"type":87},"{\"Proceeding\":\"https://ieeexplore.ieee.org/document/9757380\",\"Poster\":\"https://drive.google.com/file/d/1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA/view?usp=sharing\"}","[\"Yiqin Zhao\",\"Tian Guo\"]","{\"acronym\":\"IEEEVRW\",\"year\":2022,\"name\":\"IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\"}","fusedar-ieeevrw22.png","FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering","workshop",[],{"type":12,"tag":17,"props":90,"children":95},{":artifactLinks":91,":authors":83,":venue":92,"thumbnail":93,"title":94,"type":24},"{\"Proceeding\":\"https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290\",\"arXiv\":\"https://arxiv.org/abs/2106.15280\",\"Slides\":\"https://drive.google.com/file/d/1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa/view?usp=sharing\",\"Website\":\"/project/xihe/\"}","{\"acronym\":\"MobiSys\",\"year\":2021,\"name\":\"The 19th ACM International Conference on Mobile Systems, Applications, and Services\"}","xihe-mobisys2021.png","Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality",[96],{"type":12,"tag":42,"props":97,"children":98},{},[99],{"type":12,"tag":46,"props":100,"children":102},{"className":101},[49],[103,113],{"type":12,"tag":104,"props":105,"children":112},"img",{"className":106,"src":111},[107,108,109,110],"inline","w-4","my-0","mt-[-0.2em]","https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg",[],{"type":53,"value":114}," Artifacts Evaluated ‚Äì Functional v1.1",{"type":12,"tag":17,"props":116,"children":121},{":artifactLinks":117,":authors":83,":venue":118,"thumbnail":119,"title":120,"type":24},"{\"Proceeding\":\"https://arxiv.org/abs/2004.00006\",\"arXiv\":\"https://arxiv.org/abs/2004.00006\",\"Slides\":\"https://drive.google.com/file/d/1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp/view?usp=sharing\",\"Website\":\"/project/point-ar/\"}","{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"16th European Conference on Computer Vision\"}","pointar-eccv.png","PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",[],{"type":12,"tag":17,"props":123,"children":129},{":artifactLinks":124,":authors":125,":venue":126,"thumbnail":127,"title":128,"type":70},"{\"Proceeding\":\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Zhongtian Bao\",\"Yiqin Zhao\",\"Zixing Zhang\",\"Nicholas Cummins\",\"Zhao Ren\",\"Bj√∂rn Schuller\"]","{\"acronym\":\"Access\",\"year\":2019,\"name\":\"IEEE Access\"}","deep-spectrum-ieee.png","Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",[],{"type":12,"tag":17,"props":131,"children":137},{":artifactLinks":132,":authors":133,":venue":134,"thumbnail":135,"title":136,"type":24},"{\"Proceeding\":\"https://dl.acm.org/citation.cfm?doid=3267935.3267948\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yiqin Zhao\",\"Zhongtian Bao\",\"Haishuai Wang\",\"Zixing Zhang\",\"Chao Li\"]","{\"acronym\":\"ASMMC-MMAC\",\"year\":2018,\"name\":\"4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data\"}","deep-spectrum-acmmm.png","Deep Spectrum Feature Representations for Speech Emotion Recognition",[],{"type":12,"tag":17,"props":139,"children":146},{":artifactLinks":140,":authors":141,":venue":142,"thumbnail":143,"title":144,"type":24,":hideBottomBorder":145},"{\"Proceeding\":\"https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1477.html\",\"Website\":\"/project/deep-spectrum/\"}","[\"Ziping Zhao\",\"Yu Zheng\",\"Zixing Zhang\",\"Haishuai Wang\",\"Yiqin Zhao\",\"Chao Li\"]","{\"acronym\":\"INTERSPEECH\",\"year\":2018,\"name\":\"Annual Conference of the International Speech Communication Association\"}","deep-spectrum-interspeech.png","Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition","true",[],{"title":5,"searchDepth":148,"depth":148,"links":149},2,[],"markdown","content:publication.md","content","publication.md","md",1698121395311]
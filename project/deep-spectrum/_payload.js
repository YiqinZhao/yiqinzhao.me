export default (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V){return {data:{"content-query-PXuiWKKLR0":{_path:"\u002Fproject\u002Fdeep-spectrum",_dir:"project",_draft:y,_partial:y,_locale:r,_empty:y,title:v,description:r,date:"2018-06-12T00:00:00.000Z",thumbnail:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail.png",tag:"research",layout:"default",body:{type:"root",children:[{type:a,tag:"markdown-header",props:{title:v},children:[]},{type:a,tag:w,props:{id:I},children:[{type:b,value:v}]},{type:a,tag:p,props:{},children:[{type:b,value:"Zhao, Ziping and "},{type:a,tag:s,props:{},children:[{type:b,value:"Zhao, Yiqin"}]},{type:b,value:" and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao"}]},{type:a,tag:p,props:{},children:[{type:b,value:"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data ("},{type:a,tag:s,props:{},children:[{type:b,value:J}]},{type:b,value:")"}]},{type:a,tag:p,props:{},children:[{type:a,tag:x,props:{href:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3267935.3267948",rel:[z]},children:[{type:a,tag:s,props:{},children:[{type:a,tag:A,props:{alt:r,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-asmmc-18.png"},children:[]}]}]}]},{type:a,tag:t,props:{code:"@inproceedings{deep_spectrum_2018,\n    author = {Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao},\n    title = {Deep Spectrum Feature Representations for Speech Emotion Recognition},\n    booktitle = {Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia\n    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data},\n    series = {ASMMC-MMAC'18},\n    year = {2018},\n    isbn = {978-1-4503-5985-6},\n    location = {Seoul, Republic of Korea},\n    pages = {27--33},\n    numpages = {7},\n    url = {http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3267935.3267948},\n    doi = {10.1145\u002F3267935.3267948},\n    acmid = {3267948},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n    keywords = {attention mechanism, bidirectional long short-term memory,\n    fully convolutional networks, spectrogram representation, speech emotion recognition},\n}\n",language:B,meta:C},children:[{type:a,tag:D,props:{},children:[{type:a,tag:t,props:{__ignoreMap:r},children:[{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:i},children:[{type:b,value:"@inproceedings"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"deep_spectrum_2018"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:E}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:F}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:v}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"booktitle"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia"}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:"    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"series"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:J}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:G}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:K}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"isbn"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"978-1-4503-5985-6"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"location"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"Seoul, Republic of Korea"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:L}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"27--33"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"numpages"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:M}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"url"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3267935.3267948"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"doi"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"10.1145\u002F3267935.3267948"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"acmid"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"3267948"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:N}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"ACM"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"address"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"New York, NY, USA"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:o}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"keywords"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:h}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"attention mechanism, bidirectional long short-term memory,"}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:"    fully convolutional networks, spectrogram representation, speech emotion recognition"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:l}]}]}]}]}]},{type:a,tag:O,props:{},children:[]},{type:a,tag:w,props:{id:P},children:[{type:b,value:Q}]},{type:a,tag:p,props:{},children:[{type:b,value:"Ziping Zhao, Zhongtian Bao, "},{type:a,tag:s,props:{},children:[{type:b,value:H}]},{type:b,value:", Zixing Zhang, Nicholas Cummins, Zhao Ren, Björn Schuller"}]},{type:a,tag:p,props:{},children:[{type:a,tag:s,props:{},children:[{type:b,value:"IEEE Access 2019"}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:x,props:{href:"https:\u002F\u002Fieeexplore.ieee.org\u002Fstamp\u002Fstamp.jsp?arnumber=8762126",rel:[z]},children:[{type:a,tag:s,props:{},children:[{type:a,tag:A,props:{alt:r,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-ieee-19.png"},children:[]}]}]}]},{type:a,tag:t,props:{code:"@article{zhao2019exploring,\n  title={Exploring deep spectrum representations via attention-based recurrent and\n  convolutional neural networks for speech emotion recognition},\n  author={\n    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,\n    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn},\n  journal={IEEE Access},\n  volume={7},\n  pages={97515--97525},\n  year={2019},\n  publisher={IEEE}\n}\n",language:B,meta:C},children:[{type:a,tag:D,props:{},children:[{type:a,tag:t,props:{__ignoreMap:r},children:[{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:i},children:[{type:b,value:R}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"zhao2019exploring"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:F}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"Exploring deep spectrum representations via attention-based recurrent and"}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:"  convolutional neural networks for speech emotion recognition"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:E}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:"    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,"}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:"    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"journal"}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"IEEE Access"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"volume"}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:M}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:L}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"97515--97525"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:G}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"2019"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:N}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"IEEE"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:l}]}]}]}]}]},{type:a,tag:O,props:{},children:[]},{type:a,tag:w,props:{id:S},children:[{type:b,value:T}]},{type:a,tag:p,props:{},children:[{type:b,value:"Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, "},{type:a,tag:s,props:{},children:[{type:b,value:H}]},{type:b,value:", Chao Li."}]},{type:a,tag:p,props:{},children:[{type:b,value:"Annual Conference of the International Speech Communication Association, "},{type:a,tag:s,props:{},children:[{type:b,value:"INTERSPEECH 2018"}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:x,props:{href:"https:\u002F\u002Fwww.isca-speech.org\u002Farchive\u002FInterspeech_2018\u002Fpdfs\u002F1477.pdf",rel:[z]},children:[{type:a,tag:s,props:{},children:[{type:a,tag:A,props:{alt:r,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-interspeech-18.png"},children:[]}]}]}]},{type:a,tag:t,props:{code:"@article{zhao2018exploring,\n  title={Exploring spatio-temporal representations by integrating\n  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition},\n  author={Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao},\n  year={2018}\n}\n",language:B,meta:C},children:[{type:a,tag:D,props:{},children:[{type:a,tag:t,props:{__ignoreMap:r},children:[{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:i},children:[{type:b,value:R}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:"zhao2018exploring"}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:F}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"Exploring spatio-temporal representations by integrating"}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:"  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:E}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:"Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao"}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:m}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:q}]},{type:a,tag:c,props:{class:k},children:[{type:b,value:G}]},{type:a,tag:c,props:{class:i},children:[{type:b,value:n}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:j}]},{type:a,tag:c,props:{class:d},children:[{type:b,value:K}]},{type:a,tag:c,props:{class:e},children:[{type:b,value:l}]}]},{type:a,tag:f,props:{class:g},children:[{type:a,tag:c,props:{class:d},children:[{type:b,value:l}]}]}]}]}]},{type:a,tag:w,props:{id:U},children:[{type:b,value:V}]},{type:a,tag:p,props:{},children:[{type:b,value:"If you have any questions, please feel free to contact "},{type:a,tag:x,props:{href:"mailto:yiqinzhao@outlook.com"},children:[{type:b,value:H}]},{type:b,value:"."}]},{type:a,tag:"style",children:[{type:b,value:".ct-bd108a{color:#E9F284}\n.ct-8756c3{color:#8BE9FD}\n.ct-27df84{color:#F8F8F2}\n.ct-6b21f7{color:#FF79C6}"}]}],toc:{title:r,searchDepth:u,depth:u,links:[{id:I,depth:u,text:v},{id:P,depth:u,text:Q},{id:S,depth:u,text:T},{id:U,depth:u,text:V}]}},_type:"markdown",_id:"content:project:deep-spectrum.md",_source:"content",_file:"project\u002Fdeep-spectrum.md",_extension:"md"}},prerenderedAt:void 0}}("element","text","span","ct-27df84","ct-bd108a","div","line"," ","ct-6b21f7","{","ct-8756c3","}",",","=","    ","p","  ","","strong","code",2,"Deep Spectrum Feature Representations for Speech Emotion Recognition","h2","a",false,"nofollow","img","bibtex",null,"pre","author","title","year","Yiqin Zhao","deep-spectrum-feature-representations-for-speech-emotion-recognition","ASMMC-MMAC'18","2018","pages","7","publisher","hr","exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition","Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition","@article","exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition","Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition","contact","Contact"))
export default (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U){return {data:{"content-query-PXuiWKKLR0":{_path:"\u002Fproject\u002Fdeep-spectrum",_dir:"project",_draft:x,_partial:x,_locale:"en",_empty:x,title:u,description:r,date:"2018-06-12T00:00:00.000Z",thumbnail:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail.png",tag:"research",layout:"default",body:{type:"root",children:[{type:a,tag:"markdown-header",props:{title:u},children:[]},{type:a,tag:v,props:{id:H},children:[{type:c,value:u}]},{type:a,tag:o,props:{},children:[{type:c,value:"Zhao, Ziping and "},{type:a,tag:q,props:{},children:[{type:c,value:"Zhao, Yiqin"}]},{type:c,value:" and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao"}]},{type:a,tag:o,props:{},children:[{type:c,value:"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data ("},{type:a,tag:q,props:{},children:[{type:c,value:I}]},{type:c,value:")"}]},{type:a,tag:o,props:{},children:[{type:a,tag:w,props:{href:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3267935.3267948",rel:[y]},children:[{type:a,tag:q,props:{},children:[{type:a,tag:z,props:{alt:r,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-asmmc-18.png"},children:[]}]}]}]},{type:a,tag:s,props:{code:"@inproceedings{deep_spectrum_2018,\n    author = {Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao},\n    title = {Deep Spectrum Feature Representations for Speech Emotion Recognition},\n    booktitle = {Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia\n    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data},\n    series = {ASMMC-MMAC'18},\n    year = {2018},\n    isbn = {978-1-4503-5985-6},\n    location = {Seoul, Republic of Korea},\n    pages = {27--33},\n    numpages = {7},\n    url = {http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3267935.3267948},\n    doi = {10.1145\u002F3267935.3267948},\n    acmid = {3267948},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n    keywords = {attention mechanism, bidirectional long short-term memory,\n    fully convolutional networks, spectrogram representation, speech emotion recognition},\n}\n",language:A,meta:B},children:[{type:a,tag:C,props:{},children:[{type:a,tag:s,props:{__ignoreMap:r},children:[{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:h},children:[{type:c,value:"@inproceedings"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"deep_spectrum_2018"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:D}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:E}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:u}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"booktitle"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"series"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:I}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:F}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:J}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"isbn"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"978-1-4503-5985-6"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"location"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Seoul, Republic of Korea"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:K}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"27--33"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"numpages"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:L}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"url"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3267935.3267948"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"doi"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"10.1145\u002F3267935.3267948"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"acmid"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"3267948"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:M}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"ACM"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"address"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"New York, NY, USA"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"keywords"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"attention mechanism, bidirectional long short-term memory,"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    fully convolutional networks, spectrogram representation, speech emotion recognition"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:k}]}]}]}]}]},{type:a,tag:N,props:{},children:[]},{type:a,tag:v,props:{id:O},children:[{type:c,value:P}]},{type:a,tag:o,props:{},children:[{type:c,value:"Ziping Zhao, Zhongtian Bao, "},{type:a,tag:q,props:{},children:[{type:c,value:G}]},{type:c,value:", Zixing Zhang, Nicholas Cummins, Zhao Ren, Bj√∂rn Schuller"}]},{type:a,tag:o,props:{},children:[{type:a,tag:q,props:{},children:[{type:c,value:"IEEE Access 2019"}]}]},{type:a,tag:o,props:{},children:[{type:a,tag:w,props:{href:"https:\u002F\u002Fieeexplore.ieee.org\u002Fstamp\u002Fstamp.jsp?arnumber=8762126",rel:[y]},children:[{type:a,tag:q,props:{},children:[{type:a,tag:z,props:{alt:r,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-ieee-19.png"},children:[]}]}]}]},{type:a,tag:s,props:{code:"@article{zhao2019exploring,\n  title={Exploring deep spectrum representations via attention-based recurrent and\n  convolutional neural networks for speech emotion recognition},\n  author={\n    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,\n    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn},\n  journal={IEEE Access},\n  volume={7},\n  pages={97515--97525},\n  year={2019},\n  publisher={IEEE}\n}\n",language:A,meta:B},children:[{type:a,tag:C,props:{},children:[{type:a,tag:s,props:{__ignoreMap:r},children:[{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:h},children:[{type:c,value:Q}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"zhao2019exploring"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:E}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Exploring deep spectrum representations via attention-based recurrent and"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"  convolutional neural networks for speech emotion recognition"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:D}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"journal"}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"IEEE Access"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"volume"}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:L}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:K}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"97515--97525"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:F}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"2019"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:M}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"IEEE"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:k}]}]}]}]}]},{type:a,tag:N,props:{},children:[]},{type:a,tag:v,props:{id:R},children:[{type:c,value:S}]},{type:a,tag:o,props:{},children:[{type:c,value:"Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, "},{type:a,tag:q,props:{},children:[{type:c,value:G}]},{type:c,value:", Chao Li."}]},{type:a,tag:o,props:{},children:[{type:c,value:"Annual Conference of the International Speech Communication Association, "},{type:a,tag:q,props:{},children:[{type:c,value:"INTERSPEECH 2018"}]}]},{type:a,tag:o,props:{},children:[{type:a,tag:w,props:{href:"https:\u002F\u002Fwww.isca-speech.org\u002Farchive\u002FInterspeech_2018\u002Fpdfs\u002F1477.pdf",rel:[y]},children:[{type:a,tag:q,props:{},children:[{type:a,tag:z,props:{alt:r,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-interspeech-18.png"},children:[]}]}]}]},{type:a,tag:s,props:{code:"@article{zhao2018exploring,\n  title={Exploring spatio-temporal representations by integrating\n  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition},\n  author={Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao},\n  year={2018}\n}\n",language:A,meta:B},children:[{type:a,tag:C,props:{},children:[{type:a,tag:s,props:{__ignoreMap:r},children:[{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:h},children:[{type:c,value:Q}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"zhao2018exploring"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:E}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Exploring spatio-temporal representations by integrating"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:D}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:p}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:F}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:J}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:k}]}]}]}]}]},{type:a,tag:v,props:{id:T},children:[{type:c,value:U}]},{type:a,tag:o,props:{},children:[{type:c,value:"If you have any questions, please feel free to contact "},{type:a,tag:w,props:{href:"mailto:yiqinzhao@outlook.com"},children:[{type:c,value:G}]},{type:c,value:"."}]},{type:a,tag:"style",children:[{type:c,value:".ct-53f381{color:#E9F284}\n.ct-1b927c{color:#8BE9FD}\n.ct-aa6a8e{color:#F8F8F2}\n.ct-fd24fe{color:#FF79C6}"}]}],toc:{title:r,searchDepth:t,depth:t,links:[{id:H,depth:t,text:u},{id:O,depth:t,text:P},{id:R,depth:t,text:S},{id:T,depth:t,text:U}]}},_type:"markdown",_id:"content:project:deep-spectrum.md",_source:"content",_file:"project\u002Fdeep-spectrum.md",_extension:"md"}},prerenderedAt:void 0}}("element","span","text","ct-aa6a8e","ct-53f381","line"," ","ct-fd24fe","{","ct-1b927c","}",",","=","    ","p","  ","strong","","code",2,"Deep Spectrum Feature Representations for Speech Emotion Recognition","h2","a",false,"nofollow","img","bibtex",null,"pre","author","title","year","Yiqin Zhao","deep-spectrum-feature-representations-for-speech-emotion-recognition","ASMMC-MMAC'18","2018","pages","7","publisher","hr","exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition","Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition","@article","exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition","Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition","contact","Contact"))
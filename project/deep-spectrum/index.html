<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css"><style>body{--tw-bg-opacity:1;background-color:rgb(250 250 249/var(--tw-bg-opacity,1))}body:is(.dark *){--tw-bg-opacity:1;background-color:rgb(17 24 39/var(--tw-bg-opacity,1))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:#0006!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><link rel="stylesheet" href="/_nuxt/entry.DCs3ND5O.css" crossorigin><link rel="preload" as="fetch" crossorigin="anonymous" href="/project/deep-spectrum/_payload.json?2ef8585d-159c-4f13-a4df-aa53e0e600f9"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DYmjSiVF.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DaUdGB5m.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/6yFTc7Fw.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DlAUqK2U.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DlfXHo_8.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/BTBoc2Al.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ZStNhbFg.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CsbG8TY_.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/BNR96ijr.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DmFVGg19.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DWpGnOrq.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CFOfaOcn.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Dr_CAw2C.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/B-mGzBuR.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/D_DA8g_m.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CVTXYNh4.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CMygHXRe.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ByhZittZ.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/D2YmCN_j.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Q_DT4r4T.js"><link rel="preload" as="fetch" fetchpriority="low" crossorigin="anonymous" href="/_nuxt/builds/meta/2ef8585d-159c-4f13-a4df-aa53e0e600f9.json"><link rel="prefetch" as="script" crossorigin href="/_nuxt/BsK0jYO4.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/C8KsRPk9.js"><title>Yiqin Zhao</title><link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico"><script type="module" src="/_nuxt/DYmjSiVF.js" crossorigin></script><script>"use strict";(()=>{const t=window,e=document.documentElement,c=["dark","light"],n=getStorageValue("localStorage","nuxt-color-mode")||"system";let i=n==="system"?u():n;const r=e.getAttribute("data-color-mode-forced");r&&(i=r),l(i),t["__NUXT_COLOR_MODE__"]={preference:n,value:i,getColorScheme:u,addColorScheme:l,removeColorScheme:d};function l(o){const s=""+o+"-mode",a="";e.classList?e.classList.add(s):e.className+=" "+s,a&&e.setAttribute("data-"+a,o)}function d(o){const s=""+o+"-mode",a="";e.classList?e.classList.remove(s):e.className=e.className.replace(new RegExp(s,"g"),""),a&&e.removeAttribute("data-"+a)}function f(o){return t.matchMedia("(prefers-color-scheme"+o+")")}function u(){if(t.matchMedia&&f("").media!=="not all"){for(const o of c)if(f(":"+o).matches)return o}return"light"}})();function getStorageValue(t,e){switch(t){case"localStorage":return window.localStorage.getItem(e);case"sessionStorage":return window.sessionStorage.getItem(e);case"cookie":return getCookie(e);default:return null}}function getCookie(t){const c=("; "+window.document.cookie).split("; "+t+"=");if(c.length===2)return c.pop()?.split(";").shift()}</script></head><body><div id="__nuxt"><!--[--><!----><!----><!--[--><!--[--><div class="hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class=""><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium flex items-center" href="/"><span class="transition-border hover:border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium flex items-center" href="/publication/"><span class="transition-border hover:border-b-2 border-b-gray-400">Publication</span></a><a class="pl-10 font-medium flex items-center" href="/project/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium flex items-center" href="/personal/"><span class="transition-border hover:border-b-2 border-b-gray-400">Personal</span></a><a class="pl-10 font-medium flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="translate-y-[-100vh] fixed w-full h-full top-0 left-0 z-20 bg-black transition-opacity opacity-0"></div><div class="duration-0 translate-y-[-100vh] opacity-0 md:hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20 transition-transform duration-500"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="transition-color py-3" href="/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Home</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/publication/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Publication</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/project/"><div class="flex justify-between"><span class="dark:text-white font-medium">Projects</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/personal/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Personal</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-lg [&amp;_h1]:mt-12"><div class="mb-16"><div class="container md:w-[140%] md:ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><div class="w-[55%] hidden md:flex flex-col items-center justify-start shadow-lg p-12 py-8 z-20 h-fit absolute left-0 bg-neutral-100 dark:bg-neutral-700 bottom-16"><p class="w-full text-6xl py-4 m-0 font-bold">Yiqin Zhao</p><p class="w-full text-xl pl-3 prose dark:prose-invert m-0 text-left text-gray-500"> 赵一勤 | Yiqin (Pronunciation: ee-cheen) <br> CS Ph.D. candidate <a href="https://cake.wpi.edu" class="text-gray-500">@wpicakelab</a> <br> Incoming Assistant Professor <a href="https://rit.edu" class="text-gray-500">@RIT</a> <br></p><p class="w-full text-xl pl-3 prose dark:prose-invert mt-2 mb-0 text-left text-gray-500"><i>Building dynamic intelligent systems for immersive mobile computing.</i></p><p class="mt-4 w-full pl-3 m-0"><span class="m-0"><a href="mailto:yiqinzhao@outlook.com"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/email.svg" alt=""></a><a href="https://github.com/YiqinZhao"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/github.svg" alt=""></a><a href="https://scholar.google.com/citations?user=2Dq4bAcAAAAJ&amp;hl=en"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/google-scholar.svg" alt=""></a><a href="https://bsky.app/profile/yiqinzhao.bsky.social"><img class="inline dark:invert w-6 mr-3 opacity-75 hover:opacity-100 transition-opacity m-0" src="/assets/img/icons/bluesky.svg" alt=""></a></span></p></div><img class="w-full md:w-1/2 shadow-lg my-0 md:my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""><div class="absolute h-full w-[75%] left-0 z-[-1]"></div><img class="hidden md:block absolute w-3/5 top-[-8rem] left-[-5rem] dark:invert z-[-1] opacity-30" src="/assets/img/qin-logo.svg" alt=""></div></div><div class="hidden md:block w-full h-fit p-0 m-0 absolute mx-auto top-0 left-0 z-[-2] bg-neutral-200 dark:bg-neutral-800"><div class="max-w-prose mt-[3.4rem] opacity-0"><div class="container w-[140%] ml-[-20%] px-0 md:pt-0"><div class="flex py-0 dark:text-white relative justify-end items-center mx-auto"><img class="w-full md:w-1/2 shadow-lg my-12 z-10" src="/assets/img/hero-3-4.jpg" alt=""></div></div></div></div></div><div><div class="xl:w-[175%] xl:ml-[-37.5%]"><!--[--><div class="bg-gray-100 p-5 text-red-600 text-justify">
🔊 Super excited to announce that I will be joining <a href="https://www.rit.edu/computing/school-interactive-games-and-media" rel="noopener noreferrer" target="_blank" class="text-red-600"><!--[-->IGM@RIT<!--]--></a> as a tenure-track assistant professor in Fall 2025.
</div><!--]--></div></div><div class="xl:flex xl:ml-[-37.5%] xl:w-[175%] xl:justify-between"><div class="xl:w-[55%]"><!--[--><h2 id="️-about-me"><a href="#️-about-me"><!--[-->🦸🏻‍♂️ About Me<!--]--></a></h2><p><!--[-->I am a final-year Computer Science Ph.D. candidate at <a href="https://wpi.edu" rel="nofollow"><!--[-->Worcester Polytechnic Institute (WPI)<!--]--></a> and a proud member of <a href="https://cake-lab.github.io" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> research group.
I feel extremely fortunate to be advised by my kind and wise advisor <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.<!--]--></p><p><!--[-->My research includes building AI models and AI system supports for dynamic application scenarios.
In particular, my research pays special interest in exploring the emerging area of immersive computing.
Specifically, my works aim to safely and robustly blend computing into physical environments.
My work explores problems and solutions that allow mobile computing systems to adapt to the complex dynamics of key mobile computing stakeholders–user, device, environment, and AI system.
Centered around this objective, I have worked on environment sensing and perception systems, context-aware generative AI systems, privacy-preserving AI content generation, and infrastructure projects for AR experimentation.<!--]--></p><p><!--[-->In the past, I had the fortunate to work with and study from many awesome industry researchers during my time at Adobe Research, Google AR&amp;VR, Kuaishou Y-tech Graphics AI team, and Baidu.<!--]--></p><!--]--></div><div class="xl:w-[40%]"><!--[--><h2 id="news"><a href="#news"><!--[-->📰 News<!--]--></a></h2><div class="[&amp;_li:nth-of-type(1n+7)]:hidden [&amp;_img]:hidden [&amp;_h1]:hidden [&amp;_h2]:hidden"><div><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">News</h1><h2 class="dark:text-gray-200 text-center text-xl font-normal my-6 max-w-4xl mx-auto">📢 I will be joining IGM@RIT as a tenure track assistant professor in Fall 2025!</h2><!--]--><ul><!--[--><li><!--[--><strong><!--[-->03/27/2025<!--]--></strong> 🎉 I will be joining IGM@RIT as a tenure track assistant professor in Fall 2025!<!--]--></li><li><!--[--><strong><!--[-->08/11/2024<!--]--></strong> 🎉 One paper accepted at ImmerCom 2024!<!--]--></li><li><!--[--><strong><!--[-->05/13/2024<!--]--></strong> 🎉 I joined <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Adobe Research<!--]--></a> as a research scientist intern.<!--]--></li><li><!--[--><strong><!--[-->03/01/2024<!--]--></strong> 🎉 Our demo <a href="https://cake.wpi.edu/ARFlow/" rel="nofollow"><!--[-->ARFlow: A Framework for Simplifying AR Experimentation Workflow<!--]--></a> has been accepted by HotMobile 2024!<!--]--></li><li><!--[--><strong><!--[-->02/17/2024<!--]--></strong> 🎉 Our paper <a href="https://arxiv.org/pdf/2310.14437" rel="nofollow"><!--[-->Mobile AR Depth Estimation: Challenges &amp; Prospects<!--]--></a> has been accepted by HotMobile 2024!<!--]--></li><li><!--[--><strong><!--[-->06/10/2023<!--]--></strong> 🏆 Our paper, <em><!--[-->Toward Scalable and Controllable AR Experimentation<!--]--></em>, received <strong><!--[-->best paper runner-up<!--]--></strong> award at ImmerCom&#39;23.<!--]--></li><li><!--[--><strong><!--[-->03/31/2023<!--]--></strong> 🎉 We have released the <a href="https://github.com/cake-lab/LitAR" rel="nofollow"><!--[-->code<!--]--></a> of our UbiComp 2022 paper LitAR.<!--]--></li><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> 🎉 Received student travel grant from HotMobile 2023, thank you!<!--]--></li><li><!--[--><strong><!--[-->12/15/2022<!--]--></strong> 🎉 Passed my classes and research qualifications, I&#39;m a Ph.D. candidate now!<!--]--></li><li><!--[--><strong><!--[-->12/09/2022<!--]--></strong> 🎉 Our paper <a href="https://arxiv.org/pdf/2301.06143" rel="nofollow"><!--[-->Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality<!--]--></a> has been accepted by HotMobile 2023!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> 🎉 I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> 🎉 Our paper <a href="/project/litar" class=""><!--[-->LitAR<!--]--></a> has been accepted by UbiComp 2022!<!--]--></li><li><!--[--><strong><!--[-->05/17/2022<!--]--></strong> 🎉 Our paper <a href="/project/privacy-preserving-reflection" class=""><!--[-->Privacy-preserving Reflection Rendering for Augmented Reality<!--]--></a> has been accepted by ACM MM 2022!<!--]--></li><li><!--[--><strong><!--[-->03/04/2022<!--]--></strong> 🎉 I will join Google as a research intern in the summer!<!--]--></li><li><!--[--><strong><!--[-->01/18/2022<!--]--></strong> 🎉 I joined the <a href="http://www.chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern.<!--]--></li><li><!--[--><strong><!--[-->05/24/2021<!--]--></strong> ✨ We just released the <a href="/project/point-ar" class=""><!--[-->Xihe<!--]--></a> source code! Check our <a href="https://github.com/cake-lab/Xihe" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> 🎉 I will join the <a href="http://chongyangma.com/team/index.html" rel="nofollow"><!--[-->Y-tech Graphics AI team<!--]--></a> as a research intern in next spring!<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> 🎉 I&#39;m thrilled to announce that I will continue my Ph.D. study at <a href="https://cake.wpi.edu/" rel="nofollow"><!--[-->The Cake Lab<!--]--></a> with <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a>.<!--]--></li><li><!--[--><strong><!--[-->04/15/2021<!--]--></strong> 🎉 I&#39;ve presented my M.S. Thesis.<!--]--></li><li><!--[--><strong><!--[-->04/03/2021<!--]--></strong> ✨ <a href="/project/point-ar" class=""><!--[-->PointAR<!--]--></a> source code is now released! Check our <a href="https://github.com/cake-lab/PointAR" rel="nofollow"><!--[-->GitHub<!--]--></a> repo.<!--]--></li><li><!--[--><strong><!--[-->03/25/2021<!--]--></strong> 🔥 New paper on mobile system for 3D vision-based lighting estimation has been conditionally accepted to MobiSys 2021.<!--]--></li><li><!--[--><strong><!--[-->08/25/2020<!--]--></strong> 🎙️ I presented our efficient mobile AR lighting estimation paper at ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->07/22/2020<!--]--></strong> 🔥 Our paper on efficient mobile AR lighting estimation neural network has been accepted to ECCV 2020.<!--]--></li><li><!--[--><strong><!--[-->03/03/2020<!--]--></strong> 🎙️ I presented my poster at the HotMobile 2020 conference in Austin, TX.<!--]--></li><li><!--[--><strong><!--[-->02/01/2020<!--]--></strong> 🔥 Our poster on mobile AR lighting estimation has been accepted to HotMobile 2020.<!--]--></li><li><!--[--><strong><!--[-->08/26/2019<!--]--></strong> 🦸🏻‍♂️ I joined Worcester Polytechnic Institute CakeLab.<!--]--></li><li><!--[--><strong><!--[-->10/26/2018<!--]--></strong> 🎙️ I presented our paper on ASMMC-MMAC 2018 workshop.<!--]--></li><li><!--[--><strong><!--[-->10/15/2018<!--]--></strong> 🏆 I received Wang Kechang Technology innovation scholarship (&lt;1%).<!--]--></li><li><!--[--><strong><!--[-->10/13/2018<!--]--></strong> 🏆 I received annual special scholarship at Tianjin Normal University (top 5%).<!--]--></li><li><!--[--><strong><!--[-->08/15/2018<!--]--></strong> 🔥 Our paper about human speech emotion in spectrogram representation has submitted to ACM Multimedia 2018 ASMMC-MMAC workshop!<!--]--></li><li><!--[--><strong><!--[-->07/04/2018<!--]--></strong> 👨🏻‍💻 I joined the DuerOS department at Baidu, Inc as a frontend software engineer intern.<!--]--></li><li><!--[--><strong><!--[-->09/30/2017<!--]--></strong> 🏆 I received third prize of the 2017 China national Mobile Innovation Contest (top 6%).<!--]--></li><li><!--[--><strong><!--[-->09/30/2016<!--]--></strong> 🏆 I received third prize of the 2016 China national Mobile Innovation Contest (top 10%).<!--]--></li><!--]--></ul></div></div><p><!--[--><a href="/news/" class=""><!--[-->More news &gt;&gt;&gt;<!--]--></a><!--]--></p><!--]--></div></div><div class="xl:flex xl:ml-[-37.5%] xl:w-[175%] xl:justify-between"><div class="xl:w-[55%]"><!--[--><h2 id="education"><a href="#education"><!--[-->🏫 Education<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-wpi.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/wpi.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Worcester Polytechnic Institute, Worcester, MA<!--]--></strong><br>
Ph.D. student.<br>
Research assistant in <a href="https://cake.wpi.edu" rel="nofollow"><!--[-->TheCakeLab<!--]--></a>, advised by <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a><br>
Aug 2021 - Present (Expected: summer 2025)<!--]--></p><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-wpi.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/wpi.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Worcester Polytechnic Institute, Worcester, MA<!--]--></strong><br>
M.S. student.<br>
Research assistant  in <a href="https://cake.wpi.edu" rel="nofollow"><!--[-->TheCakeLab<!--]--></a>, advised by <a href="https://tianguo.info" rel="nofollow"><!--[-->Prof. Tian Guo<!--]--></a><br>
Aug 2019 - June, 2021<!--]--></p><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-tjnu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/tjnu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Tianjin Normal University, Tianjin, China<!--]--></strong><br>
Bachelor of Engineering in Software Engineering<br>
Sept, 2015 - Jun, 2019<!--]--></p><!--]--></div></div><!--]--></div><div class="xl:w-[40%]"><!--[--><h2 id="industry-experiences"><a href="#industry-experiences"><!--[-->👨‍💻 Industry Experiences<!--]--></a></h2><div class="flex flex-row py-4 items-center my-5"><img id="publication-adobe.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/adobe.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Adobe Research, San Jose, CA<!--]--></strong><br>
Research Scientist Intern<br>
May 2024 - Aug 2024<!--]--></p><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-google.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/google.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Google, Mountain View, CA<!--]--></strong><br>
Student Researcher<br>
May 2022 - May 2023<!--]--></p><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-kuaishou.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/kuaishou.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Kuaishou Technology, Palo Alto, CA<!--]--></strong><br>
Research Intern<br>
Jan, 2022 - May, 2022<!--]--></p><!--]--></div></div><div class="flex flex-row py-4 items-center my-5"><img id="publication-baidu.png" class="mr-4 w-20 my-0" src="/assets/img/affiliation/baidu.png" alt=""><div class="prose dark:prose-invert [&amp;_p]:my-0 md:text-lg"><!--[--><p><!--[--><strong><!--[-->Baidu, Beijing, China<!--]--></strong><br>
Software Engineering Intern<br>
Jun, 2018 - Sept, 2018<!--]--></p><!--]--></div></div><!--]--></div></div><div><div class="xl:w-[175%] xl:ml-[-37.5%]"><!--[--><h2 id="selected-publications"><a href="#selected-publications"><!--[-->📄 Selected Publications<!--]--></a></h2><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="demo"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">arXiv&#39;24</span></span><span class="font-bold text-2xl md:text-2xl">CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/clear.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Mallesham Dasri</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">arXiv</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2411.02179">arXiv</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="demo"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">HotMobile&#39;24</span></span><span class="font-bold text-2xl md:text-2xl">Demo: ARFlow: A Framework for Simplifying AR Experimentation Workflow</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/arflow.jpeg" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">25th International Workshop on Mobile Computing Systems and Applications</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://cake.wpi.edu/ARFlow/">Website</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/10.1145/3638550.3643617">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/cake-lab/ARFlow">Code</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="conference"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">HotMobile&#39;24</span></span><span class="font-bold text-2xl md:text-2xl">Mobile AR Depth Estimation: Challenges &amp; Prospects</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/depth-estimation.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Ashkan Ganj</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Hang Su</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">25th International Workshop on Mobile Computing Systems and Applications</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/10.1145/3638550.3641122">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2310.14437">arXiv (extended version)</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="conference"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">ImmerCom&#39;23</span></span><span class="font-bold text-2xl md:text-2xl">Toward Scalable and Controllable AR Experimentation</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/expar.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Ashkan Ganj</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Federico Galbiati</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><p><!--[--><span class="text-red-600 font-bold">🏆 Best Paper Runner-up.</span><!--]--></p><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/abs/10.1145/3615452.3617941">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2307.08587">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://cake.wpi.edu/expar/">Website</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="journal"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">IMWUT&#39;22</span></span><span class="font-bold text-2xl md:text-2xl">LitAR: Visually Coherent Lighting for Mobile Augmented Reality</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/litar-ubicomp22.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Chongyang Ma</span><span>, </span></span><span><span class="">Haibin Huang</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/abs/10.1145/3550291">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/pdf/2301.06184.pdf">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE/edit?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://github.com/cake-lab/LitAR">Code</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/litar/">Website</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="conference"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">ACMMM&#39;22</span></span><span class="font-bold text-2xl md:text-2xl">Privacy-preserving Reflection Rendering for Augmented Reality</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/privacy-preserving-reflection.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Sheng Wei</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">30th ACM International Conference on Multimedia</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/abs/10.1145/3503161.3548386">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2207.03056">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://docs.google.com/presentation/d/1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk/edit?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/privacy-preserving-reflection">Website</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="conference"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">MobiSys&#39;21</span></span><span class="font-bold text-2xl md:text-2xl">Xihe: a 3D Vision-Based Lighting Estimation Framework for Mobile Augmented Reality</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/xihe-mobisys2021.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">The 19th ACM International Conference on Mobile Systems, Applications, and Services</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><p><!--[--><span class="text-red-600"><img src="/assets/img/icons/artifacts_evaluated_functional_dl.jpg" alt class="inline w-4 my-0 mt-[-0.2em]"> Artifacts Evaluated – Functional v1.1</span><!--]--></p><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://dl.acm.org/doi/10.1145/3458864.3467886?cid=99659479290">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2106.15280">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa/view?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/xihe/">Website</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8 border-b-2" type="conference"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">ECCV&#39;20</span></span><span class="font-bold text-2xl md:text-2xl">PointAR: Efficient Lighting Estimation for Mobile Augmented Reality</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/pointar-eccv.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Tian Guo</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">16th European Conference on Computer Vision</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2004.00006">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://arxiv.org/abs/2004.00006">arXiv</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://drive.google.com/file/d/1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp/view?usp=sharing">Slides</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/point-ar/">Website</a></span><!--]--></div></div></div></div></div><div class="publication-row flex flex-col md:flex-row items-start mt-4 pb-8" type="conference"><div class="w-full font-normal"><div class="dark:text-white my-4"><span><span class="mr-2 bg-gray-200 text-black py-[0.4em] text-md px-2">INTERSPEECH&#39;18</span></span><span class="font-bold text-2xl md:text-2xl">Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition</span></div><div class="md:flex md:flex-row items-start"><img class="mr-4 w-full md:w-64 mt-1 mb-0 flex-grow-0" src="/assets/img/publications/deep-spectrum-interspeech.png" alt=""><div class="w-full mt-4 md:mt-0"><div class="text-lg"><!--[--><span><span class="">Ziping Zhao</span><span>, </span></span><span><span class="">Yu Zheng</span><span>, </span></span><span><span class="">Zixing Zhang</span><span>, </span></span><span><span class="">Haishuai Wang</span><span>, </span></span><span><span class="font-bold dark:text-white underline">Yiqin Zhao</span><span>, </span></span><span><span class="">Chao Li</span><span> </span></span><!--]--></div><div class="text-gray-500 text-sm">Annual Conference of the International Speech Communication Association</div><div class="prose dark:prose-invert [&amp;_p]:my-0"><!--[--><!--]--></div><div class="flex flex-wrap mt-auto"><!--[--><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1477.html">Proceeding</a></span><span><a class="bg-gray-700 text-white px-2 py-[0.2em] mr-1 no-underline text-sm" href="/project/deep-spectrum/">Website</a></span><!--]--></div></div></div></div></div><p><!--[--><a href="/publication/" class=""><!--[-->Full publication list &gt;&gt;&gt;<!--]--></a><!--]--></p><!--]--></div></div></div></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm text-left"> 赵一勤 | Yiqin (Pronunciation: ee-cheen) <br> CS Ph.D. Candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Incoming Assistant Professor <a href="https://rit.edu">@RIT</a> <br><i>Building dynamic intelligent systems for immersive mobile computing.</i></p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:yiqinzhao@outlook.com">E-Mail</a> <br><a href="https://github.com/YiqinZhao">GitHub</a> <br><a href="https://bsky.app/profile/yiqinzhao.bsky.social">Bluesky</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> © <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2025. Last updated: 3/28/2025. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div></div><!--]--><!--]--></div><div id="teleports"></div><script type="application/json" data-nuxt-data="nuxt-app" data-ssr="true" id="__NUXT_DATA__" data-src="/project/deep-spectrum/_payload.json?2ef8585d-159c-4f13-a4df-aa53e0e600f9">[{"state":1,"once":7,"_errors":8,"serverRendered":5,"path":10,"prerenderedAt":11},["Reactive",2],{"$scolor-mode":3},{"preference":4,"value":4,"unknown":5,"forced":6},"system",true,false,["Set"],["ShallowReactive",9],{"$BPopkF1nvN":-1,"$QtpWXez6C4":-1,"$OToglkIAsf":-1},"/project/deep-spectrum",1743195697444]</script><script>window.__NUXT__={};window.__NUXT__.config={public:{content:{wsUrl:""},mdc:{components:{prose:true,map:{}},headings:{anchorLinks:{h1:false,h2:true,h3:true,h4:true,h5:false,h6:false}}}},app:{baseURL:"/",buildId:"2ef8585d-159c-4f13-a4df-aa53e0e600f9",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>
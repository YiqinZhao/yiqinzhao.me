<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Deep Spectrum Feature Representations for Speech Emotion Recognition - Yiqin Zhao</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
<meta name="og:title" content="Deep Spectrum Feature Representations for Speech Emotion Recognition"><link rel="modulepreload" href="/project/deep-spectrum/_payload.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.19d0c082.js"><link rel="preload" as="style" href="/_nuxt/entry.19f6f2b7.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/query.d9806caa.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/query.78e85590.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/content.3599ac2c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.bf1742d3.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.cb6a7261.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.aaac6da7.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.cb1620ee.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/index.a6ef77ff.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.94209430.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/layout.432161b9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.5c1d85f5.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.bf2e87a9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.678fe890.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/qin-logo.ef293eae.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.23a1ef25.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.989431b6.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.41393a46.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.ee11e501.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.6966b7b9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.f9106b23.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.c27b6911.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.c327cec0.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.ab48f5fe.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseImg.1ac2b688.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseCode.c84104c3.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseHr.27099557.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentNavigation.50378d1b.js"><link rel="prefetch" as="style" href="/_nuxt/ContentNavigation.2ce1c5fc.css"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentSlot.f9f6a2b8.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.e5abb8ec.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/Markdown.893226cc.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.8792bcfc.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.c116c0c7.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.d83c2cb6.js"><link rel="stylesheet" href="/_nuxt/entry.19f6f2b7.css"><style>body{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}.dark body{--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><style>pre code .line{display:block;min-height:1rem}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><!--[--><div class="document-driven-page"><!--[--><!--[--><!--[--><div class="hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class=""><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/"><span class="transition-border hover:border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/research/"><span class="transition-border hover:border-b-2 border-b-gray-400">Research</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/project/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="translate-y-[-100vh] fixed w-full h-full top-0 left-0 z-20 bg-black transform-gpu transition-opacity opacity-0"></div><div class="translate-y-[-100vh] fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20 transform-gpu transition-transform duration-700"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="hover:text-white transition-color py-3" href="/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Home</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/research/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Research</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/project/"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">Projects</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="[&amp;_p_img]:md:max-w-[140%] [&amp;_p_img]:md:mx-[-20%] pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">Deep Spectrum Feature Representations for Speech Emotion Recognition</h1><!----><!--]--><h2 id="deep-spectrum-feature-representations-for-speech-emotion-recognition"><a href="#deep-spectrum-feature-representations-for-speech-emotion-recognition"><!--[-->Deep Spectrum Feature Representations for Speech Emotion Recognition<!--]--></a></h2><p><!--[-->Zhao, Ziping and <strong><!--[-->Zhao, Yiqin<!--]--></strong> and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao<!--]--></p><p><!--[-->Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data (<strong><!--[-->ASMMC-MMAC&#39;18<!--]--></strong>)<!--]--></p><p><!--[--><a href="https://dl.acm.org/doi/10.1145/3267935.3267948" rel="nofollow"><!--[--><strong><!--[--><img src="/assets/img/project/deep-spectrum/thumbnail-asmmc-18.png" alt><!--]--></strong><!--]--></a><!--]--></p><!--[--><pre><code><span class="line"><span class="ct-0eeca8">@inproceedings</span><span class="ct-f63743">{</span><span class="ct-596ce3">deep_spectrum_2018</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">author</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">title</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">Deep Spectrum Feature Representations for Speech Emotion Recognition</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">booktitle</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia</span></span><span class="line"><span class="ct-f63743">    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">series</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">ASMMC-MMAC&#39;18</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">year</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">2018</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">isbn</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">978-1-4503-5985-6</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">location</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">Seoul, Republic of Korea</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">pages</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">27--33</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">numpages</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">7</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">url</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">http://doi.acm.org/10.1145/3267935.3267948</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">doi</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">10.1145/3267935.3267948</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">acmid</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">3267948</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">publisher</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">ACM</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">address</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">New York, NY, USA</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">    </span><span class="ct-596ce3">keywords</span><span class="ct-f63743"> </span><span class="ct-0eeca8">=</span><span class="ct-f63743"> </span><span class="ct-74a42b">{</span><span class="ct-f63743">attention mechanism, bidirectional long short-term memory,</span></span><span class="line"><span class="ct-f63743">    fully convolutional networks, spectrogram representation, speech emotion recognition</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">}</span></span></code></pre><!--]--><hr><h2 id="exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition"><a href="#exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition"><!--[-->Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition<!--]--></a></h2><p><!--[-->Ziping Zhao, Zhongtian Bao, <strong><!--[-->Yiqin Zhao<!--]--></strong>, Zixing Zhang, Nicholas Cummins, Zhao Ren, Björn Schuller<!--]--></p><p><!--[--><strong><!--[-->IEEE Access 2019<!--]--></strong><!--]--></p><p><!--[--><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126" rel="nofollow"><!--[--><strong><!--[--><img src="/assets/img/project/deep-spectrum/thumbnail-ieee-19.png" alt><!--]--></strong><!--]--></a><!--]--></p><!--[--><pre><code><span class="line"><span class="ct-0eeca8">@article</span><span class="ct-f63743">{</span><span class="ct-596ce3">zhao2019exploring</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">title</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">Exploring deep spectrum representations via attention-based recurrent and</span></span><span class="line"><span class="ct-f63743">  convolutional neural networks for speech emotion recognition</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">author</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span></span><span class="line"><span class="ct-f63743">    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,</span></span><span class="line"><span class="ct-f63743">    Nicholas and Ren, Zhao and Schuller, Bj{\&quot;o}rn</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">journal</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">IEEE Access</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">volume</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">7</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">pages</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">97515--97525</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">year</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">2019</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">publisher</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">IEEE</span><span class="ct-74a42b">}</span></span><span class="line"><span class="ct-f63743">}</span></span></code></pre><!--]--><hr><h2 id="exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition"><a href="#exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition"><!--[-->Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition<!--]--></a></h2><p><!--[-->Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, <strong><!--[-->Yiqin Zhao<!--]--></strong>, Chao Li.<!--]--></p><p><!--[-->Annual Conference of the International Speech Communication Association, <strong><!--[-->INTERSPEECH 2018<!--]--></strong><!--]--></p><p><!--[--><a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1477.pdf" rel="nofollow"><!--[--><strong><!--[--><img src="/assets/img/project/deep-spectrum/thumbnail-interspeech-18.png" alt><!--]--></strong><!--]--></a><!--]--></p><!--[--><pre><code><span class="line"><span class="ct-0eeca8">@article</span><span class="ct-f63743">{</span><span class="ct-596ce3">zhao2018exploring</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">title</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">Exploring spatio-temporal representations by integrating</span></span><span class="line"><span class="ct-f63743">  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">author</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao</span><span class="ct-74a42b">}</span><span class="ct-f63743">,</span></span><span class="line"><span class="ct-f63743">  </span><span class="ct-596ce3">year</span><span class="ct-0eeca8">=</span><span class="ct-74a42b">{</span><span class="ct-f63743">2018</span><span class="ct-74a42b">}</span></span><span class="line"><span class="ct-f63743">}</span></span></code></pre><!--]--><h2 id="contact"><a href="#contact"><!--[-->Contact<!--]--></a></h2><p><!--[-->If you have any questions, please feel free to contact <a href="mailto:yiqinzhao@outlook.com" rel="noopener noreferrer"><!--[-->Yiqin Zhao<!--]--></a>.<!--]--></p><style>.ct-74a42b{color:#E9F284}
.ct-596ce3{color:#8BE9FD}
.ct-f63743{color:#F8F8F2}
.ct-0eeca8{color:#FF79C6}</style></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> 赵一勤 | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. Candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https//arvr.google.com">@GoogleVRAR</a> <br> Research Interests: Mobile System, AR, CV, CG </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:yiqinzhao@outlook.com">E-Mail</a> <br><a href="https://github.com/YiqinZhao">GitHub</a> <br><a href="https://twitter.com/yiqin_zhao">Twitter</a> <br><a href="https://www.instagram.com/yiqinzhao1996">Instagram</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> © <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2023. Last updated: 2/23/2023. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div></div><!--]--><!--]--></div><!--]--><!--]--></div><script type="module">import p from "/project/deep-spectrum/_payload.js";window.__NUXT__={...p,...((function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah){return {state:{"$scolor-mode":{preference:O,value:O,unknown:u,forced:o},"$sdd-pages":{"/project/deep-spectrum":{_path:P,_dir:B,_draft:o,_partial:o,_locale:C,_empty:o,title:v,description:p,date:"2018-06-12T00:00:00.000Z",thumbnail:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail.png",tag:Q,layout:s,body:{type:"root",children:[{type:a,tag:"markdown-header",props:{title:v},children:[]},{type:a,tag:y,props:{id:R},children:[{type:c,value:v}]},{type:a,tag:q,props:{},children:[{type:c,value:"Zhao, Ziping and "},{type:a,tag:t,props:{},children:[{type:c,value:"Zhao, Yiqin"}]},{type:c,value:" and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao"}]},{type:a,tag:q,props:{},children:[{type:c,value:"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data ("},{type:a,tag:t,props:{},children:[{type:c,value:S}]},{type:c,value:")"}]},{type:a,tag:q,props:{},children:[{type:a,tag:z,props:{href:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3267935.3267948",rel:[D]},children:[{type:a,tag:t,props:{},children:[{type:a,tag:E,props:{alt:p,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-asmmc-18.png"},children:[]}]}]}]},{type:a,tag:w,props:{code:"@inproceedings{deep_spectrum_2018,\n    author = {Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao},\n    title = {Deep Spectrum Feature Representations for Speech Emotion Recognition},\n    booktitle = {Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia\n    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data},\n    series = {ASMMC-MMAC'18},\n    year = {2018},\n    isbn = {978-1-4503-5985-6},\n    location = {Seoul, Republic of Korea},\n    pages = {27--33},\n    numpages = {7},\n    url = {http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3267935.3267948},\n    doi = {10.1145\u002F3267935.3267948},\n    acmid = {3267948},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n    keywords = {attention mechanism, bidirectional long short-term memory,\n    fully convolutional networks, spectrogram representation, speech emotion recognition},\n}\n",language:A,meta:F},children:[{type:a,tag:G,props:{},children:[{type:a,tag:w,props:{__ignoreMap:p},children:[{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:h},children:[{type:c,value:"@inproceedings"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"deep_spectrum_2018"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:H}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:I}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:v}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"booktitle"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"series"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:S}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:J}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:T}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"isbn"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"978-1-4503-5985-6"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"location"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Seoul, Republic of Korea"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:U}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"27--33"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"numpages"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:V}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"url"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3267935.3267948"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"doi"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"10.1145\u002F3267935.3267948"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"acmid"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"3267948"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:W}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"ACM"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"address"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"New York, NY, USA"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:n}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"keywords"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:g}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"attention mechanism, bidirectional long short-term memory,"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    fully convolutional networks, spectrogram representation, speech emotion recognition"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:k}]}]}]}]}]},{type:a,tag:X,props:{},children:[]},{type:a,tag:y,props:{id:Y},children:[{type:c,value:Z}]},{type:a,tag:q,props:{},children:[{type:c,value:"Ziping Zhao, Zhongtian Bao, "},{type:a,tag:t,props:{},children:[{type:c,value:K}]},{type:c,value:", Zixing Zhang, Nicholas Cummins, Zhao Ren, Björn Schuller"}]},{type:a,tag:q,props:{},children:[{type:a,tag:t,props:{},children:[{type:c,value:"IEEE Access 2019"}]}]},{type:a,tag:q,props:{},children:[{type:a,tag:z,props:{href:"https:\u002F\u002Fieeexplore.ieee.org\u002Fstamp\u002Fstamp.jsp?arnumber=8762126",rel:[D]},children:[{type:a,tag:t,props:{},children:[{type:a,tag:E,props:{alt:p,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-ieee-19.png"},children:[]}]}]}]},{type:a,tag:w,props:{code:"@article{zhao2019exploring,\n  title={Exploring deep spectrum representations via attention-based recurrent and\n  convolutional neural networks for speech emotion recognition},\n  author={\n    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,\n    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn},\n  journal={IEEE Access},\n  volume={7},\n  pages={97515--97525},\n  year={2019},\n  publisher={IEEE}\n}\n",language:A,meta:F},children:[{type:a,tag:G,props:{},children:[{type:a,tag:w,props:{__ignoreMap:p},children:[{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:h},children:[{type:c,value:_}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"zhao2019exploring"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:I}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Exploring deep spectrum representations via attention-based recurrent and"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"  convolutional neural networks for speech emotion recognition"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:H}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"journal"}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"IEEE Access"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"volume"}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:V}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:U}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"97515--97525"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:J}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"2019"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:W}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"IEEE"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:k}]}]}]}]}]},{type:a,tag:X,props:{},children:[]},{type:a,tag:y,props:{id:$},children:[{type:c,value:aa}]},{type:a,tag:q,props:{},children:[{type:c,value:"Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, "},{type:a,tag:t,props:{},children:[{type:c,value:K}]},{type:c,value:", Chao Li."}]},{type:a,tag:q,props:{},children:[{type:c,value:"Annual Conference of the International Speech Communication Association, "},{type:a,tag:t,props:{},children:[{type:c,value:"INTERSPEECH 2018"}]}]},{type:a,tag:q,props:{},children:[{type:a,tag:z,props:{href:"https:\u002F\u002Fwww.isca-speech.org\u002Farchive\u002FInterspeech_2018\u002Fpdfs\u002F1477.pdf",rel:[D]},children:[{type:a,tag:t,props:{},children:[{type:a,tag:E,props:{alt:p,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-interspeech-18.png"},children:[]}]}]}]},{type:a,tag:w,props:{code:"@article{zhao2018exploring,\n  title={Exploring spatio-temporal representations by integrating\n  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition},\n  author={Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao},\n  year={2018}\n}\n",language:A,meta:F},children:[{type:a,tag:G,props:{},children:[{type:a,tag:w,props:{__ignoreMap:p},children:[{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:h},children:[{type:c,value:_}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:"zhao2018exploring"}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:I}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Exploring spatio-temporal representations by integrating"}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:"  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:H}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:"Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao"}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:l}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:r}]},{type:a,tag:b,props:{class:j},children:[{type:c,value:J}]},{type:a,tag:b,props:{class:h},children:[{type:c,value:m}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:i}]},{type:a,tag:b,props:{class:d},children:[{type:c,value:T}]},{type:a,tag:b,props:{class:e},children:[{type:c,value:k}]}]},{type:a,tag:b,props:{class:f},children:[{type:a,tag:b,props:{class:d},children:[{type:c,value:k}]}]}]}]}]},{type:a,tag:y,props:{id:ab},children:[{type:c,value:ac}]},{type:a,tag:q,props:{},children:[{type:c,value:"If you have any questions, please feel free to contact "},{type:a,tag:z,props:{href:"mailto:yiqinzhao@outlook.com"},children:[{type:c,value:K}]},{type:c,value:"."}]},{type:a,tag:"style",children:[{type:c,value:".ct-74a42b{color:#E9F284}\n.ct-596ce3{color:#8BE9FD}\n.ct-f63743{color:#F8F8F2}\n.ct-0eeca8{color:#FF79C6}"}]}],toc:{title:p,searchDepth:x,depth:x,links:[{id:R,depth:x,text:v},{id:Y,depth:x,text:Z},{id:$,depth:x,text:aa},{id:ab,depth:x,text:ac}]}},_type:L,_id:"content:project:deep-spectrum.md",_source:M,_file:"project\u002Fdeep-spectrum.md",_extension:N}},"$sdd-surrounds":{"/project/deep-spectrum":[{_path:ad,_dir:B,_draft:o,_partial:o,_locale:C,_empty:o,title:ae,description:p,date:"2017-05-03T00:00:00.000Z",thumbnail:"\u002Fassets\u002Fimg\u002Fproject\u002F2048\u002Fthumbnail.png",tag:"opensource",layout:s,_type:L,_id:"content:project:2048.md",_source:M,_file:"project\u002F2048.md",_extension:N},{_path:af,_dir:B,_draft:o,_partial:o,_locale:C,_empty:o,title:ag,description:p,date:"2022-07-29T00:00:00.000Z",thumbnail:"\u002Fassets\u002Fimg\u002Fproject\u002Flitar\u002Fthumbnail.png",previewCardDirection:"horizontal",tag:Q,layout:s,_type:L,_id:"content:project:litar.md",_source:M,_file:"project\u002Flitar.md",_extension:N}]},"$sdd-globals":{},"$sdd-navigation":[{title:"Home",_path:ah},{title:"News",_path:"\u002Fnews"},{title:"Project",_path:"\u002Fproject",children:[{title:ae,_path:ad,layout:s},{title:v,_path:P,layout:s},{title:ag,_path:af,layout:s},{title:"PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",_path:"\u002Fproject\u002Fpoint-ar",layout:s},{title:"Privacy-preserving Reflection Rendering for Augmented Reality",_path:"\u002Fproject\u002Fprivacy-preserving-reflection",layout:s},{title:"Xihe: A 3D Vision based Lighting Estimation for Mobile AR",_path:"\u002Fproject\u002Fxihe",layout:s}],layout:"cards"},{title:"Research",_path:"\u002Fresearch"}]},_errors:{},serverRendered:u,config:{public:{content:{locales:[],integrity:1677180871525,experimental:{stripQueryParameters:o,clientDB:o},api:{baseURL:"\u002Fapi\u002F_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:[A]},wsUrl:p,documentDriven:{page:u,navigation:u,surround:u,globals:{},layoutFallbacks:["theme"],injectPage:u},host:p,trailingSlash:o,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:ah,buildAssetsDir:"\u002F_nuxt\u002F",cdnURL:p}},prerenderedAt:void 0}}("element","span","text","ct-f63743","ct-74a42b","line"," ","ct-0eeca8","{","ct-596ce3","}",",","=","    ",false,"","p","  ","default","strong",true,"Deep Spectrum Feature Representations for Speech Emotion Recognition","code",2,"h2","a","bibtex","project","en","nofollow","img",null,"pre","author","title","year","Yiqin Zhao","markdown","content","md","system","\u002Fproject\u002Fdeep-spectrum","research","deep-spectrum-feature-representations-for-speech-emotion-recognition","ASMMC-MMAC'18","2018","pages","7","publisher","hr","exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition","Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition","@article","exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition","Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition","contact","Contact","\u002Fproject\u002F2048",2048,"\u002Fproject\u002Flitar","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","\u002F")))}</script><script type="module" src="/_nuxt/entry.19d0c082.js" crossorigin></script><script type="module" src="/_nuxt/document-driven.bf1742d3.js" crossorigin></script><script type="module" src="/_nuxt/default.bf2e87a9.js" crossorigin></script><script type="module" src="/_nuxt/Navigator.678fe890.js" crossorigin></script><script type="module" src="/_nuxt/ContentDoc.23a1ef25.js" crossorigin></script><script type="module" src="/_nuxt/Footer.41393a46.js" crossorigin></script><script type="module" src="/_nuxt/ContentRenderer.aaac6da7.js" crossorigin></script><script type="module" src="/_nuxt/ContentRendererMarkdown.cb1620ee.js" crossorigin></script><script type="module" src="/_nuxt/MarkdownHeader.ee11e501.js" crossorigin></script><script type="module" src="/_nuxt/ProseH2.6966b7b9.js" crossorigin></script><script type="module" src="/_nuxt/ProseP.f9106b23.js" crossorigin></script><script type="module" src="/_nuxt/ProseStrong.c327cec0.js" crossorigin></script><script type="module" src="/_nuxt/ProseA.ab48f5fe.js" crossorigin></script><script type="module" src="/_nuxt/ProseImg.1ac2b688.js" crossorigin></script><script type="module" src="/_nuxt/ProseCode.c84104c3.js" crossorigin></script><script type="module" src="/_nuxt/ProseHr.27099557.js" crossorigin></script></body>
</html>
<!DOCTYPE html>
<html >
<head><meta charset="utf-8">
<title>Deep Spectrum Feature Representations for Speech Emotion Recognition - Yiqin Zhao</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
<meta property="og:title" content="Deep Spectrum Feature Representations for Speech Emotion Recognition"><link rel="preload" as="fetch" crossorigin="anonymous" href="/project/deep-spectrum/_payload.json"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/entry.5757841a.js"><link rel="preload" as="style" href="/_nuxt/entry.5328c45a.css"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/document-driven.c777ac5c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenEmpty.a18295cb.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRenderer.e640ef4e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentRendererMarkdown.524c43d1.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/index.a6ef77ff.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/DocumentDrivenNotFound.2a335c16.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/head.587d4048.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/default.79639543.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Navigator.e530131f.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/qin-logo.5b1ed4b2.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentDoc.5e98ba61.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ContentQuery.58adc26e.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/asyncData.a75bc970.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Footer.c12c47fe.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/MarkdownHeader.4bdc8bde.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseH2.0b88b931.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseP.26dd3982.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/_plugin-vue_export-helper.c27b6911.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseStrong.51959a18.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseA.4dd527a0.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/nuxt-link.3c26aa84.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseImg.d73bcdf9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseCode.829f38e8.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ProseHr.cdf4c481.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/cards.5cf1691c.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/ContentList.547b377d.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/client-db.28fd0842.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/error-component.6336bcf2.js"><link rel="stylesheet" href="/_nuxt/entry.5328c45a.css"><style>body{--tw-bg-opacity:1;background-color:#fafaf9;background-color:rgb(250 250 249/var(--tw-bg-opacity))}:is(.dark body){--tw-bg-opacity:1;background-color:#1c1917;background-color:rgb(28 25 23/var(--tw-bg-opacity))}p{line-height:1.6em;text-align:justify;text-justify:inter-word}a{text-decoration-color:rgba(0,0,0,.4)!important;transition:opacity .1s linear}a:hover{opacity:.4}h2 a{font-weight:900!important;text-decoration:none!important}h2 a:before{border-top:1px solid #000;content:"";display:block;max-width:100%;padding-bottom:.2em;width:100px}</style><style>pre code .line{display:block;min-height:1rem}</style><script>"use strict";const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,t&&de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o="--"+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),t&&de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script></head>
<body ><div id="__nuxt"><!--[--><!----><!----><div class="document-driven-page"><!--[--><!--[--><div class="hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class=""><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium flex items-center" href="/"><span class="transition-border hover:border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium flex items-center" href="/research/"><span class="transition-border hover:border-b-2 border-b-gray-400">Research</span></a><a class="pl-10 font-medium flex items-center" href="/project/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="translate-y-[-100vh] fixed w-full h-full top-0 left-0 z-20 bg-black transition-opacity opacity-0"></div><div class="duration-0 translate-y-[-100vh] opacity-0 md:hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20 transition-transform duration-500"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="transition-color py-3" href="/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Home</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/research/"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">Research</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/project/"><div class="flex justify-between"><span class="dark:text-white font-medium">Projects</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border :border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="[&amp;_p_img]:md:max-w-[140%] [&amp;_p_img]:md:mx-[-20%] pb-16 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:text-xs font-serif"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:p-0 md:text-xl [&amp;_h1]:mt-12"><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">Deep Spectrum Feature Representations for Speech Emotion Recognition</h1><!----><!--]--><h2 id="deep-spectrum-feature-representations-for-speech-emotion-recognition"><a href="#deep-spectrum-feature-representations-for-speech-emotion-recognition"><!--[-->Deep Spectrum Feature Representations for Speech Emotion Recognition<!--]--></a></h2><p><!--[-->Zhao, Ziping and <strong><!--[-->Zhao, Yiqin<!--]--></strong> and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao<!--]--></p><p><!--[-->Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data (<strong><!--[-->ASMMC-MMAC&#39;18<!--]--></strong>)<!--]--></p><p><!--[--><a href="https://dl.acm.org/doi/10.1145/3267935.3267948" rel="nofollow"><!--[--><strong><!--[--><img src="/assets/img/project/deep-spectrum/thumbnail-asmmc-18.png" alt><!--]--></strong><!--]--></a><!--]--></p><!--[--><pre><code><span class="line" line="1"><span class="ct-ffef9e">@inproceedings</span><span class="ct-aaaf1d">{</span><span class="ct-c36137">deep_spectrum_2018</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="2"><span class="ct-aaaf1d">    </span><span class="ct-c36137">author</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="3"><span class="ct-aaaf1d">    </span><span class="ct-c36137">title</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">Deep Spectrum Feature Representations for Speech Emotion Recognition</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="4"><span class="ct-aaaf1d">    </span><span class="ct-c36137">booktitle</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia
</span></span><span class="line" line="5"><span class="ct-aaaf1d">    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="6"><span class="ct-aaaf1d">    </span><span class="ct-c36137">series</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">ASMMC-MMAC&#39;18</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="7"><span class="ct-aaaf1d">    </span><span class="ct-c36137">year</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">2018</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="8"><span class="ct-aaaf1d">    </span><span class="ct-c36137">isbn</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">978-1-4503-5985-6</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="9"><span class="ct-aaaf1d">    </span><span class="ct-c36137">location</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">Seoul, Republic of Korea</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="10"><span class="ct-aaaf1d">    </span><span class="ct-c36137">pages</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">27--33</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="11"><span class="ct-aaaf1d">    </span><span class="ct-c36137">numpages</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">7</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="12"><span class="ct-aaaf1d">    </span><span class="ct-c36137">url</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">http://doi.acm.org/10.1145/3267935.3267948</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="13"><span class="ct-aaaf1d">    </span><span class="ct-c36137">doi</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">10.1145/3267935.3267948</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="14"><span class="ct-aaaf1d">    </span><span class="ct-c36137">acmid</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">3267948</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="15"><span class="ct-aaaf1d">    </span><span class="ct-c36137">publisher</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">ACM</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="16"><span class="ct-aaaf1d">    </span><span class="ct-c36137">address</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">New York, NY, USA</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="17"><span class="ct-aaaf1d">    </span><span class="ct-c36137">keywords</span><span class="ct-aaaf1d"> </span><span class="ct-ffef9e">=</span><span class="ct-aaaf1d"> </span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">attention mechanism, bidirectional long short-term memory,
</span></span><span class="line" line="18"><span class="ct-aaaf1d">    fully convolutional networks, spectrogram representation, speech emotion recognition</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="19"><span class="ct-aaaf1d">}</span></span></code></pre><!--]--><hr><h2 id="exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition"><a href="#exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition"><!--[-->Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition<!--]--></a></h2><p><!--[-->Ziping Zhao, Zhongtian Bao, <strong><!--[-->Yiqin Zhao<!--]--></strong>, Zixing Zhang, Nicholas Cummins, Zhao Ren, Björn Schuller<!--]--></p><p><!--[--><strong><!--[-->IEEE Access 2019<!--]--></strong><!--]--></p><p><!--[--><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126" rel="nofollow"><!--[--><strong><!--[--><img src="/assets/img/project/deep-spectrum/thumbnail-ieee-19.png" alt><!--]--></strong><!--]--></a><!--]--></p><!--[--><pre><code><span class="line" line="1"><span class="ct-ffef9e">@article</span><span class="ct-aaaf1d">{</span><span class="ct-c36137">zhao2019exploring</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="2"><span class="ct-aaaf1d">  </span><span class="ct-c36137">title</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">Exploring deep spectrum representations via attention-based recurrent and
</span></span><span class="line" line="3"><span class="ct-aaaf1d">  convolutional neural networks for speech emotion recognition</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="4"><span class="ct-aaaf1d">  </span><span class="ct-c36137">author</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{
</span></span><span class="line" line="5"><span class="ct-aaaf1d">    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,
</span></span><span class="line" line="6"><span class="ct-aaaf1d">    Nicholas and Ren, Zhao and Schuller, Bj{\&quot;o}rn</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="7"><span class="ct-aaaf1d">  </span><span class="ct-c36137">journal</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">IEEE Access</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="8"><span class="ct-aaaf1d">  </span><span class="ct-c36137">volume</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">7</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="9"><span class="ct-aaaf1d">  </span><span class="ct-c36137">pages</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">97515--97525</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="10"><span class="ct-aaaf1d">  </span><span class="ct-c36137">year</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">2019</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="11"><span class="ct-aaaf1d">  </span><span class="ct-c36137">publisher</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">IEEE</span><span class="ct-60ba0c">}
</span></span><span class="line" line="12"><span class="ct-aaaf1d">}</span></span></code></pre><!--]--><hr><h2 id="exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition"><a href="#exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition"><!--[-->Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition<!--]--></a></h2><p><!--[-->Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, <strong><!--[-->Yiqin Zhao<!--]--></strong>, Chao Li.<!--]--></p><p><!--[-->Annual Conference of the International Speech Communication Association, <strong><!--[-->INTERSPEECH 2018<!--]--></strong><!--]--></p><p><!--[--><a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1477.pdf" rel="nofollow"><!--[--><strong><!--[--><img src="/assets/img/project/deep-spectrum/thumbnail-interspeech-18.png" alt><!--]--></strong><!--]--></a><!--]--></p><!--[--><pre><code><span class="line" line="1"><span class="ct-ffef9e">@article</span><span class="ct-aaaf1d">{</span><span class="ct-c36137">zhao2018exploring</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="2"><span class="ct-aaaf1d">  </span><span class="ct-c36137">title</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">Exploring spatio-temporal representations by integrating
</span></span><span class="line" line="3"><span class="ct-aaaf1d">  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="4"><span class="ct-aaaf1d">  </span><span class="ct-c36137">author</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao</span><span class="ct-60ba0c">}</span><span class="ct-aaaf1d">,
</span></span><span class="line" line="5"><span class="ct-aaaf1d">  </span><span class="ct-c36137">year</span><span class="ct-ffef9e">=</span><span class="ct-60ba0c">{</span><span class="ct-aaaf1d">2018</span><span class="ct-60ba0c">}
</span></span><span class="line" line="6"><span class="ct-aaaf1d">}</span></span></code></pre><!--]--><h2 id="contact"><a href="#contact"><!--[-->Contact<!--]--></a></h2><p><!--[-->If you have any questions, please feel free to contact <a href="mailto:yiqinzhao@outlook.com" rel="noopener noreferrer"><!--[-->Yiqin Zhao<!--]--></a>.<!--]--></p><style>.ct-60ba0c{color:#E9F284}
.ct-c36137{color:#8BE9FD}
.ct-aaaf1d{color:#F8F8F2}
.ct-ffef9e{color:#FF79C6}</style></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-4"><div class="prose mx-auto dark:prose-invert p-4 md:text-lg opacity-60"><div class="flex-col md:flex-row flex justify-between border-b-2 border-b-gray-300"><div><p class="text-sm"> 赵一勤 | Yiqin (Pronunciation: Yi-Chin) <br> CS Ph.D. Candidate <a href="https://cake.wpi.edu">@wpicakelab</a> <br> Student Researcher <a href="https//arvr.google.com">@GoogleVRAR</a> <br> Research Interests: Mobile System, AR, CV, CG </p></div><div><p class="text-sm md:text-right [&amp;_br]:hidden [&amp;_br]:md:inline"><a href="mailto:yiqinzhao@outlook.com">E-Mail</a> <br><a href="https://github.com/YiqinZhao">GitHub</a> <br><a href="https://twitter.com/yiqin_zhao">Twitter</a> <br><a href="https://www.instagram.com/yiqinzhao1996">Instagram</a> <br></p></div></div><div class="text-gray-500 dark:text-gray-400 mx-auto text-sm"><p> © <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2023. Last updated: 5/18/2023. Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div></div><!--]--></div><!--]--></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true" data-src="/project/deep-spectrum/_payload.json">[{"state":1,"_errors":1365,"serverRendered":5,"prerenderedAt":-1},["Reactive",2],{"$scolor-mode":3,"$sdd-pages":7,"$sdd-surrounds":1319,"$sdd-globals":1337,"$sdd-navigation":1338},{"preference":4,"value":4,"unknown":5,"forced":6},"system",true,false,{"/project/deep-spectrum":8},{"_path":9,"_dir":10,"_draft":6,"_partial":6,"_locale":11,"_empty":6,"title":12,"description":11,"date":13,"thumbnail":14,"tag":15,"layout":16,"body":17,"_type":1314,"_id":1315,"_source":1316,"_file":1317,"_extension":1318},"/project/deep-spectrum","project","","Deep Spectrum Feature Representations for Speech Emotion Recognition","2018-06-12T00:00:00.000Z","/assets/img/project/deep-spectrum/thumbnail.png","research","default",{"type":18,"children":19,"toc":1308},"root",[20,25,32,46,58,76,778,782,788,800,808,823,1104,1107,1113,1124,1134,1149,1285,1291,1303],{"type":21,"tag":22,"props":23,"children":24},"element","markdown-header",{"title":12},[],{"type":21,"tag":26,"props":27,"children":29},"h2",{"id":28},"deep-spectrum-feature-representations-for-speech-emotion-recognition",[30],{"type":31,"value":12},"text",{"type":21,"tag":33,"props":34,"children":35},"p",{},[36,38,44],{"type":31,"value":37},"Zhao, Ziping and ",{"type":21,"tag":39,"props":40,"children":41},"strong",{},[42],{"type":31,"value":43},"Zhao, Yiqin",{"type":31,"value":45}," and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao",{"type":21,"tag":33,"props":47,"children":48},{},[49,51,56],{"type":31,"value":50},"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data (",{"type":21,"tag":39,"props":52,"children":53},{},[54],{"type":31,"value":55},"ASMMC-MMAC'18",{"type":31,"value":57},")",{"type":21,"tag":33,"props":59,"children":60},{},[61],{"type":21,"tag":62,"props":63,"children":67},"a",{"href":64,"rel":65},"https://dl.acm.org/doi/10.1145/3267935.3267948",[66],"nofollow",[68],{"type":21,"tag":39,"props":69,"children":70},{},[71],{"type":21,"tag":72,"props":73,"children":75},"img",{"alt":11,"src":74},"/assets/img/project/deep-spectrum/thumbnail-asmmc-18.png",[],{"type":21,"tag":77,"props":78,"children":82},"code",{"code":79,"language":80,"meta":81},"@inproceedings{deep_spectrum_2018,\n    author = {Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao},\n    title = {Deep Spectrum Feature Representations for Speech Emotion Recognition},\n    booktitle = {Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia\n    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data},\n    series = {ASMMC-MMAC'18},\n    year = {2018},\n    isbn = {978-1-4503-5985-6},\n    location = {Seoul, Republic of Korea},\n    pages = {27--33},\n    numpages = {7},\n    url = {http://doi.acm.org/10.1145/3267935.3267948},\n    doi = {10.1145/3267935.3267948},\n    acmid = {3267948},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n    keywords = {attention mechanism, bidirectional long short-term memory,\n    fully convolutional networks, spectrogram representation, speech emotion recognition},\n}\n","bibtex",null,[83],{"type":21,"tag":84,"props":85,"children":86},"pre",{},[87],{"type":21,"tag":77,"props":88,"children":89},{"__ignoreMap":11},[90,119,166,207,241,258,299,341,383,425,467,509,551,593,635,677,719,753,770],{"type":21,"tag":91,"props":92,"children":95},"span",{"class":93,"line":94},"line",1,[96,102,108,114],{"type":21,"tag":91,"props":97,"children":99},{"class":98},"ct-ffef9e",[100],{"type":31,"value":101},"@inproceedings",{"type":21,"tag":91,"props":103,"children":105},{"class":104},"ct-aaaf1d",[106],{"type":31,"value":107},"{",{"type":21,"tag":91,"props":109,"children":111},{"class":110},"ct-c36137",[112],{"type":31,"value":113},"deep_spectrum_2018",{"type":21,"tag":91,"props":115,"children":116},{"class":104},[117],{"type":31,"value":118},",\n",{"type":21,"tag":91,"props":120,"children":122},{"class":93,"line":121},2,[123,128,133,138,143,147,152,157,162],{"type":21,"tag":91,"props":124,"children":125},{"class":104},[126],{"type":31,"value":127},"    ",{"type":21,"tag":91,"props":129,"children":130},{"class":110},[131],{"type":31,"value":132},"author",{"type":21,"tag":91,"props":134,"children":135},{"class":104},[136],{"type":31,"value":137}," ",{"type":21,"tag":91,"props":139,"children":140},{"class":98},[141],{"type":31,"value":142},"=",{"type":21,"tag":91,"props":144,"children":145},{"class":104},[146],{"type":31,"value":137},{"type":21,"tag":91,"props":148,"children":150},{"class":149},"ct-60ba0c",[151],{"type":31,"value":107},{"type":21,"tag":91,"props":153,"children":154},{"class":104},[155],{"type":31,"value":156},"Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao",{"type":21,"tag":91,"props":158,"children":159},{"class":149},[160],{"type":31,"value":161},"}",{"type":21,"tag":91,"props":163,"children":164},{"class":104},[165],{"type":31,"value":118},{"type":21,"tag":91,"props":167,"children":169},{"class":93,"line":168},3,[170,174,179,183,187,191,195,199,203],{"type":21,"tag":91,"props":171,"children":172},{"class":104},[173],{"type":31,"value":127},{"type":21,"tag":91,"props":175,"children":176},{"class":110},[177],{"type":31,"value":178},"title",{"type":21,"tag":91,"props":180,"children":181},{"class":104},[182],{"type":31,"value":137},{"type":21,"tag":91,"props":184,"children":185},{"class":98},[186],{"type":31,"value":142},{"type":21,"tag":91,"props":188,"children":189},{"class":104},[190],{"type":31,"value":137},{"type":21,"tag":91,"props":192,"children":193},{"class":149},[194],{"type":31,"value":107},{"type":21,"tag":91,"props":196,"children":197},{"class":104},[198],{"type":31,"value":12},{"type":21,"tag":91,"props":200,"children":201},{"class":149},[202],{"type":31,"value":161},{"type":21,"tag":91,"props":204,"children":205},{"class":104},[206],{"type":31,"value":118},{"type":21,"tag":91,"props":208,"children":210},{"class":93,"line":209},4,[211,215,220,224,228,232,236],{"type":21,"tag":91,"props":212,"children":213},{"class":104},[214],{"type":31,"value":127},{"type":21,"tag":91,"props":216,"children":217},{"class":110},[218],{"type":31,"value":219},"booktitle",{"type":21,"tag":91,"props":221,"children":222},{"class":104},[223],{"type":31,"value":137},{"type":21,"tag":91,"props":225,"children":226},{"class":98},[227],{"type":31,"value":142},{"type":21,"tag":91,"props":229,"children":230},{"class":104},[231],{"type":31,"value":137},{"type":21,"tag":91,"props":233,"children":234},{"class":149},[235],{"type":31,"value":107},{"type":21,"tag":91,"props":237,"children":238},{"class":104},[239],{"type":31,"value":240},"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia\n",{"type":21,"tag":91,"props":242,"children":244},{"class":93,"line":243},5,[245,250,254],{"type":21,"tag":91,"props":246,"children":247},{"class":104},[248],{"type":31,"value":249},"    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data",{"type":21,"tag":91,"props":251,"children":252},{"class":149},[253],{"type":31,"value":161},{"type":21,"tag":91,"props":255,"children":256},{"class":104},[257],{"type":31,"value":118},{"type":21,"tag":91,"props":259,"children":261},{"class":93,"line":260},6,[262,266,271,275,279,283,287,291,295],{"type":21,"tag":91,"props":263,"children":264},{"class":104},[265],{"type":31,"value":127},{"type":21,"tag":91,"props":267,"children":268},{"class":110},[269],{"type":31,"value":270},"series",{"type":21,"tag":91,"props":272,"children":273},{"class":104},[274],{"type":31,"value":137},{"type":21,"tag":91,"props":276,"children":277},{"class":98},[278],{"type":31,"value":142},{"type":21,"tag":91,"props":280,"children":281},{"class":104},[282],{"type":31,"value":137},{"type":21,"tag":91,"props":284,"children":285},{"class":149},[286],{"type":31,"value":107},{"type":21,"tag":91,"props":288,"children":289},{"class":104},[290],{"type":31,"value":55},{"type":21,"tag":91,"props":292,"children":293},{"class":149},[294],{"type":31,"value":161},{"type":21,"tag":91,"props":296,"children":297},{"class":104},[298],{"type":31,"value":118},{"type":21,"tag":91,"props":300,"children":302},{"class":93,"line":301},7,[303,307,312,316,320,324,328,333,337],{"type":21,"tag":91,"props":304,"children":305},{"class":104},[306],{"type":31,"value":127},{"type":21,"tag":91,"props":308,"children":309},{"class":110},[310],{"type":31,"value":311},"year",{"type":21,"tag":91,"props":313,"children":314},{"class":104},[315],{"type":31,"value":137},{"type":21,"tag":91,"props":317,"children":318},{"class":98},[319],{"type":31,"value":142},{"type":21,"tag":91,"props":321,"children":322},{"class":104},[323],{"type":31,"value":137},{"type":21,"tag":91,"props":325,"children":326},{"class":149},[327],{"type":31,"value":107},{"type":21,"tag":91,"props":329,"children":330},{"class":104},[331],{"type":31,"value":332},"2018",{"type":21,"tag":91,"props":334,"children":335},{"class":149},[336],{"type":31,"value":161},{"type":21,"tag":91,"props":338,"children":339},{"class":104},[340],{"type":31,"value":118},{"type":21,"tag":91,"props":342,"children":344},{"class":93,"line":343},8,[345,349,354,358,362,366,370,375,379],{"type":21,"tag":91,"props":346,"children":347},{"class":104},[348],{"type":31,"value":127},{"type":21,"tag":91,"props":350,"children":351},{"class":110},[352],{"type":31,"value":353},"isbn",{"type":21,"tag":91,"props":355,"children":356},{"class":104},[357],{"type":31,"value":137},{"type":21,"tag":91,"props":359,"children":360},{"class":98},[361],{"type":31,"value":142},{"type":21,"tag":91,"props":363,"children":364},{"class":104},[365],{"type":31,"value":137},{"type":21,"tag":91,"props":367,"children":368},{"class":149},[369],{"type":31,"value":107},{"type":21,"tag":91,"props":371,"children":372},{"class":104},[373],{"type":31,"value":374},"978-1-4503-5985-6",{"type":21,"tag":91,"props":376,"children":377},{"class":149},[378],{"type":31,"value":161},{"type":21,"tag":91,"props":380,"children":381},{"class":104},[382],{"type":31,"value":118},{"type":21,"tag":91,"props":384,"children":386},{"class":93,"line":385},9,[387,391,396,400,404,408,412,417,421],{"type":21,"tag":91,"props":388,"children":389},{"class":104},[390],{"type":31,"value":127},{"type":21,"tag":91,"props":392,"children":393},{"class":110},[394],{"type":31,"value":395},"location",{"type":21,"tag":91,"props":397,"children":398},{"class":104},[399],{"type":31,"value":137},{"type":21,"tag":91,"props":401,"children":402},{"class":98},[403],{"type":31,"value":142},{"type":21,"tag":91,"props":405,"children":406},{"class":104},[407],{"type":31,"value":137},{"type":21,"tag":91,"props":409,"children":410},{"class":149},[411],{"type":31,"value":107},{"type":21,"tag":91,"props":413,"children":414},{"class":104},[415],{"type":31,"value":416},"Seoul, Republic of Korea",{"type":21,"tag":91,"props":418,"children":419},{"class":149},[420],{"type":31,"value":161},{"type":21,"tag":91,"props":422,"children":423},{"class":104},[424],{"type":31,"value":118},{"type":21,"tag":91,"props":426,"children":428},{"class":93,"line":427},10,[429,433,438,442,446,450,454,459,463],{"type":21,"tag":91,"props":430,"children":431},{"class":104},[432],{"type":31,"value":127},{"type":21,"tag":91,"props":434,"children":435},{"class":110},[436],{"type":31,"value":437},"pages",{"type":21,"tag":91,"props":439,"children":440},{"class":104},[441],{"type":31,"value":137},{"type":21,"tag":91,"props":443,"children":444},{"class":98},[445],{"type":31,"value":142},{"type":21,"tag":91,"props":447,"children":448},{"class":104},[449],{"type":31,"value":137},{"type":21,"tag":91,"props":451,"children":452},{"class":149},[453],{"type":31,"value":107},{"type":21,"tag":91,"props":455,"children":456},{"class":104},[457],{"type":31,"value":458},"27--33",{"type":21,"tag":91,"props":460,"children":461},{"class":149},[462],{"type":31,"value":161},{"type":21,"tag":91,"props":464,"children":465},{"class":104},[466],{"type":31,"value":118},{"type":21,"tag":91,"props":468,"children":470},{"class":93,"line":469},11,[471,475,480,484,488,492,496,501,505],{"type":21,"tag":91,"props":472,"children":473},{"class":104},[474],{"type":31,"value":127},{"type":21,"tag":91,"props":476,"children":477},{"class":110},[478],{"type":31,"value":479},"numpages",{"type":21,"tag":91,"props":481,"children":482},{"class":104},[483],{"type":31,"value":137},{"type":21,"tag":91,"props":485,"children":486},{"class":98},[487],{"type":31,"value":142},{"type":21,"tag":91,"props":489,"children":490},{"class":104},[491],{"type":31,"value":137},{"type":21,"tag":91,"props":493,"children":494},{"class":149},[495],{"type":31,"value":107},{"type":21,"tag":91,"props":497,"children":498},{"class":104},[499],{"type":31,"value":500},"7",{"type":21,"tag":91,"props":502,"children":503},{"class":149},[504],{"type":31,"value":161},{"type":21,"tag":91,"props":506,"children":507},{"class":104},[508],{"type":31,"value":118},{"type":21,"tag":91,"props":510,"children":512},{"class":93,"line":511},12,[513,517,522,526,530,534,538,543,547],{"type":21,"tag":91,"props":514,"children":515},{"class":104},[516],{"type":31,"value":127},{"type":21,"tag":91,"props":518,"children":519},{"class":110},[520],{"type":31,"value":521},"url",{"type":21,"tag":91,"props":523,"children":524},{"class":104},[525],{"type":31,"value":137},{"type":21,"tag":91,"props":527,"children":528},{"class":98},[529],{"type":31,"value":142},{"type":21,"tag":91,"props":531,"children":532},{"class":104},[533],{"type":31,"value":137},{"type":21,"tag":91,"props":535,"children":536},{"class":149},[537],{"type":31,"value":107},{"type":21,"tag":91,"props":539,"children":540},{"class":104},[541],{"type":31,"value":542},"http://doi.acm.org/10.1145/3267935.3267948",{"type":21,"tag":91,"props":544,"children":545},{"class":149},[546],{"type":31,"value":161},{"type":21,"tag":91,"props":548,"children":549},{"class":104},[550],{"type":31,"value":118},{"type":21,"tag":91,"props":552,"children":554},{"class":93,"line":553},13,[555,559,564,568,572,576,580,585,589],{"type":21,"tag":91,"props":556,"children":557},{"class":104},[558],{"type":31,"value":127},{"type":21,"tag":91,"props":560,"children":561},{"class":110},[562],{"type":31,"value":563},"doi",{"type":21,"tag":91,"props":565,"children":566},{"class":104},[567],{"type":31,"value":137},{"type":21,"tag":91,"props":569,"children":570},{"class":98},[571],{"type":31,"value":142},{"type":21,"tag":91,"props":573,"children":574},{"class":104},[575],{"type":31,"value":137},{"type":21,"tag":91,"props":577,"children":578},{"class":149},[579],{"type":31,"value":107},{"type":21,"tag":91,"props":581,"children":582},{"class":104},[583],{"type":31,"value":584},"10.1145/3267935.3267948",{"type":21,"tag":91,"props":586,"children":587},{"class":149},[588],{"type":31,"value":161},{"type":21,"tag":91,"props":590,"children":591},{"class":104},[592],{"type":31,"value":118},{"type":21,"tag":91,"props":594,"children":596},{"class":93,"line":595},14,[597,601,606,610,614,618,622,627,631],{"type":21,"tag":91,"props":598,"children":599},{"class":104},[600],{"type":31,"value":127},{"type":21,"tag":91,"props":602,"children":603},{"class":110},[604],{"type":31,"value":605},"acmid",{"type":21,"tag":91,"props":607,"children":608},{"class":104},[609],{"type":31,"value":137},{"type":21,"tag":91,"props":611,"children":612},{"class":98},[613],{"type":31,"value":142},{"type":21,"tag":91,"props":615,"children":616},{"class":104},[617],{"type":31,"value":137},{"type":21,"tag":91,"props":619,"children":620},{"class":149},[621],{"type":31,"value":107},{"type":21,"tag":91,"props":623,"children":624},{"class":104},[625],{"type":31,"value":626},"3267948",{"type":21,"tag":91,"props":628,"children":629},{"class":149},[630],{"type":31,"value":161},{"type":21,"tag":91,"props":632,"children":633},{"class":104},[634],{"type":31,"value":118},{"type":21,"tag":91,"props":636,"children":638},{"class":93,"line":637},15,[639,643,648,652,656,660,664,669,673],{"type":21,"tag":91,"props":640,"children":641},{"class":104},[642],{"type":31,"value":127},{"type":21,"tag":91,"props":644,"children":645},{"class":110},[646],{"type":31,"value":647},"publisher",{"type":21,"tag":91,"props":649,"children":650},{"class":104},[651],{"type":31,"value":137},{"type":21,"tag":91,"props":653,"children":654},{"class":98},[655],{"type":31,"value":142},{"type":21,"tag":91,"props":657,"children":658},{"class":104},[659],{"type":31,"value":137},{"type":21,"tag":91,"props":661,"children":662},{"class":149},[663],{"type":31,"value":107},{"type":21,"tag":91,"props":665,"children":666},{"class":104},[667],{"type":31,"value":668},"ACM",{"type":21,"tag":91,"props":670,"children":671},{"class":149},[672],{"type":31,"value":161},{"type":21,"tag":91,"props":674,"children":675},{"class":104},[676],{"type":31,"value":118},{"type":21,"tag":91,"props":678,"children":680},{"class":93,"line":679},16,[681,685,690,694,698,702,706,711,715],{"type":21,"tag":91,"props":682,"children":683},{"class":104},[684],{"type":31,"value":127},{"type":21,"tag":91,"props":686,"children":687},{"class":110},[688],{"type":31,"value":689},"address",{"type":21,"tag":91,"props":691,"children":692},{"class":104},[693],{"type":31,"value":137},{"type":21,"tag":91,"props":695,"children":696},{"class":98},[697],{"type":31,"value":142},{"type":21,"tag":91,"props":699,"children":700},{"class":104},[701],{"type":31,"value":137},{"type":21,"tag":91,"props":703,"children":704},{"class":149},[705],{"type":31,"value":107},{"type":21,"tag":91,"props":707,"children":708},{"class":104},[709],{"type":31,"value":710},"New York, NY, USA",{"type":21,"tag":91,"props":712,"children":713},{"class":149},[714],{"type":31,"value":161},{"type":21,"tag":91,"props":716,"children":717},{"class":104},[718],{"type":31,"value":118},{"type":21,"tag":91,"props":720,"children":722},{"class":93,"line":721},17,[723,727,732,736,740,744,748],{"type":21,"tag":91,"props":724,"children":725},{"class":104},[726],{"type":31,"value":127},{"type":21,"tag":91,"props":728,"children":729},{"class":110},[730],{"type":31,"value":731},"keywords",{"type":21,"tag":91,"props":733,"children":734},{"class":104},[735],{"type":31,"value":137},{"type":21,"tag":91,"props":737,"children":738},{"class":98},[739],{"type":31,"value":142},{"type":21,"tag":91,"props":741,"children":742},{"class":104},[743],{"type":31,"value":137},{"type":21,"tag":91,"props":745,"children":746},{"class":149},[747],{"type":31,"value":107},{"type":21,"tag":91,"props":749,"children":750},{"class":104},[751],{"type":31,"value":752},"attention mechanism, bidirectional long short-term memory,\n",{"type":21,"tag":91,"props":754,"children":756},{"class":93,"line":755},18,[757,762,766],{"type":21,"tag":91,"props":758,"children":759},{"class":104},[760],{"type":31,"value":761},"    fully convolutional networks, spectrogram representation, speech emotion recognition",{"type":21,"tag":91,"props":763,"children":764},{"class":149},[765],{"type":31,"value":161},{"type":21,"tag":91,"props":767,"children":768},{"class":104},[769],{"type":31,"value":118},{"type":21,"tag":91,"props":771,"children":773},{"class":93,"line":772},19,[774],{"type":21,"tag":91,"props":775,"children":776},{"class":104},[777],{"type":31,"value":161},{"type":21,"tag":779,"props":780,"children":781},"hr",{},[],{"type":21,"tag":26,"props":783,"children":785},{"id":784},"exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition",[786],{"type":31,"value":787},"Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",{"type":21,"tag":33,"props":789,"children":790},{},[791,793,798],{"type":31,"value":792},"Ziping Zhao, Zhongtian Bao, ",{"type":21,"tag":39,"props":794,"children":795},{},[796],{"type":31,"value":797},"Yiqin Zhao",{"type":31,"value":799},", Zixing Zhang, Nicholas Cummins, Zhao Ren, Björn Schuller",{"type":21,"tag":33,"props":801,"children":802},{},[803],{"type":21,"tag":39,"props":804,"children":805},{},[806],{"type":31,"value":807},"IEEE Access 2019",{"type":21,"tag":33,"props":809,"children":810},{},[811],{"type":21,"tag":62,"props":812,"children":815},{"href":813,"rel":814},"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126",[66],[816],{"type":21,"tag":39,"props":817,"children":818},{},[819],{"type":21,"tag":72,"props":820,"children":822},{"alt":11,"src":821},"/assets/img/project/deep-spectrum/thumbnail-ieee-19.png",[],{"type":21,"tag":77,"props":824,"children":826},{"code":825,"language":80,"meta":81},"@article{zhao2019exploring,\n  title={Exploring deep spectrum representations via attention-based recurrent and\n  convolutional neural networks for speech emotion recognition},\n  author={\n    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,\n    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn},\n  journal={IEEE Access},\n  volume={7},\n  pages={97515--97525},\n  year={2019},\n  publisher={IEEE}\n}\n",[827],{"type":21,"tag":84,"props":828,"children":829},{},[830],{"type":21,"tag":77,"props":831,"children":832},{"__ignoreMap":11},[833,854,879,895,915,923,939,972,1004,1036,1068,1097],{"type":21,"tag":91,"props":834,"children":835},{"class":93,"line":94},[836,841,845,850],{"type":21,"tag":91,"props":837,"children":838},{"class":98},[839],{"type":31,"value":840},"@article",{"type":21,"tag":91,"props":842,"children":843},{"class":104},[844],{"type":31,"value":107},{"type":21,"tag":91,"props":846,"children":847},{"class":110},[848],{"type":31,"value":849},"zhao2019exploring",{"type":21,"tag":91,"props":851,"children":852},{"class":104},[853],{"type":31,"value":118},{"type":21,"tag":91,"props":855,"children":856},{"class":93,"line":121},[857,862,866,870,874],{"type":21,"tag":91,"props":858,"children":859},{"class":104},[860],{"type":31,"value":861},"  ",{"type":21,"tag":91,"props":863,"children":864},{"class":110},[865],{"type":31,"value":178},{"type":21,"tag":91,"props":867,"children":868},{"class":98},[869],{"type":31,"value":142},{"type":21,"tag":91,"props":871,"children":872},{"class":149},[873],{"type":31,"value":107},{"type":21,"tag":91,"props":875,"children":876},{"class":104},[877],{"type":31,"value":878},"Exploring deep spectrum representations via attention-based recurrent and\n",{"type":21,"tag":91,"props":880,"children":881},{"class":93,"line":168},[882,887,891],{"type":21,"tag":91,"props":883,"children":884},{"class":104},[885],{"type":31,"value":886},"  convolutional neural networks for speech emotion recognition",{"type":21,"tag":91,"props":888,"children":889},{"class":149},[890],{"type":31,"value":161},{"type":21,"tag":91,"props":892,"children":893},{"class":104},[894],{"type":31,"value":118},{"type":21,"tag":91,"props":896,"children":897},{"class":93,"line":209},[898,902,906,910],{"type":21,"tag":91,"props":899,"children":900},{"class":104},[901],{"type":31,"value":861},{"type":21,"tag":91,"props":903,"children":904},{"class":110},[905],{"type":31,"value":132},{"type":21,"tag":91,"props":907,"children":908},{"class":98},[909],{"type":31,"value":142},{"type":21,"tag":91,"props":911,"children":912},{"class":149},[913],{"type":31,"value":914},"{\n",{"type":21,"tag":91,"props":916,"children":917},{"class":93,"line":243},[918],{"type":21,"tag":91,"props":919,"children":920},{"class":104},[921],{"type":31,"value":922},"    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,\n",{"type":21,"tag":91,"props":924,"children":925},{"class":93,"line":260},[926,931,935],{"type":21,"tag":91,"props":927,"children":928},{"class":104},[929],{"type":31,"value":930},"    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn",{"type":21,"tag":91,"props":932,"children":933},{"class":149},[934],{"type":31,"value":161},{"type":21,"tag":91,"props":936,"children":937},{"class":104},[938],{"type":31,"value":118},{"type":21,"tag":91,"props":940,"children":941},{"class":93,"line":301},[942,946,951,955,959,964,968],{"type":21,"tag":91,"props":943,"children":944},{"class":104},[945],{"type":31,"value":861},{"type":21,"tag":91,"props":947,"children":948},{"class":110},[949],{"type":31,"value":950},"journal",{"type":21,"tag":91,"props":952,"children":953},{"class":98},[954],{"type":31,"value":142},{"type":21,"tag":91,"props":956,"children":957},{"class":149},[958],{"type":31,"value":107},{"type":21,"tag":91,"props":960,"children":961},{"class":104},[962],{"type":31,"value":963},"IEEE Access",{"type":21,"tag":91,"props":965,"children":966},{"class":149},[967],{"type":31,"value":161},{"type":21,"tag":91,"props":969,"children":970},{"class":104},[971],{"type":31,"value":118},{"type":21,"tag":91,"props":973,"children":974},{"class":93,"line":343},[975,979,984,988,992,996,1000],{"type":21,"tag":91,"props":976,"children":977},{"class":104},[978],{"type":31,"value":861},{"type":21,"tag":91,"props":980,"children":981},{"class":110},[982],{"type":31,"value":983},"volume",{"type":21,"tag":91,"props":985,"children":986},{"class":98},[987],{"type":31,"value":142},{"type":21,"tag":91,"props":989,"children":990},{"class":149},[991],{"type":31,"value":107},{"type":21,"tag":91,"props":993,"children":994},{"class":104},[995],{"type":31,"value":500},{"type":21,"tag":91,"props":997,"children":998},{"class":149},[999],{"type":31,"value":161},{"type":21,"tag":91,"props":1001,"children":1002},{"class":104},[1003],{"type":31,"value":118},{"type":21,"tag":91,"props":1005,"children":1006},{"class":93,"line":385},[1007,1011,1015,1019,1023,1028,1032],{"type":21,"tag":91,"props":1008,"children":1009},{"class":104},[1010],{"type":31,"value":861},{"type":21,"tag":91,"props":1012,"children":1013},{"class":110},[1014],{"type":31,"value":437},{"type":21,"tag":91,"props":1016,"children":1017},{"class":98},[1018],{"type":31,"value":142},{"type":21,"tag":91,"props":1020,"children":1021},{"class":149},[1022],{"type":31,"value":107},{"type":21,"tag":91,"props":1024,"children":1025},{"class":104},[1026],{"type":31,"value":1027},"97515--97525",{"type":21,"tag":91,"props":1029,"children":1030},{"class":149},[1031],{"type":31,"value":161},{"type":21,"tag":91,"props":1033,"children":1034},{"class":104},[1035],{"type":31,"value":118},{"type":21,"tag":91,"props":1037,"children":1038},{"class":93,"line":427},[1039,1043,1047,1051,1055,1060,1064],{"type":21,"tag":91,"props":1040,"children":1041},{"class":104},[1042],{"type":31,"value":861},{"type":21,"tag":91,"props":1044,"children":1045},{"class":110},[1046],{"type":31,"value":311},{"type":21,"tag":91,"props":1048,"children":1049},{"class":98},[1050],{"type":31,"value":142},{"type":21,"tag":91,"props":1052,"children":1053},{"class":149},[1054],{"type":31,"value":107},{"type":21,"tag":91,"props":1056,"children":1057},{"class":104},[1058],{"type":31,"value":1059},"2019",{"type":21,"tag":91,"props":1061,"children":1062},{"class":149},[1063],{"type":31,"value":161},{"type":21,"tag":91,"props":1065,"children":1066},{"class":104},[1067],{"type":31,"value":118},{"type":21,"tag":91,"props":1069,"children":1070},{"class":93,"line":469},[1071,1075,1079,1083,1087,1092],{"type":21,"tag":91,"props":1072,"children":1073},{"class":104},[1074],{"type":31,"value":861},{"type":21,"tag":91,"props":1076,"children":1077},{"class":110},[1078],{"type":31,"value":647},{"type":21,"tag":91,"props":1080,"children":1081},{"class":98},[1082],{"type":31,"value":142},{"type":21,"tag":91,"props":1084,"children":1085},{"class":149},[1086],{"type":31,"value":107},{"type":21,"tag":91,"props":1088,"children":1089},{"class":104},[1090],{"type":31,"value":1091},"IEEE",{"type":21,"tag":91,"props":1093,"children":1094},{"class":149},[1095],{"type":31,"value":1096},"}\n",{"type":21,"tag":91,"props":1098,"children":1099},{"class":93,"line":511},[1100],{"type":21,"tag":91,"props":1101,"children":1102},{"class":104},[1103],{"type":31,"value":161},{"type":21,"tag":779,"props":1105,"children":1106},{},[],{"type":21,"tag":26,"props":1108,"children":1110},{"id":1109},"exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition",[1111],{"type":31,"value":1112},"Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition",{"type":21,"tag":33,"props":1114,"children":1115},{},[1116,1118,1122],{"type":31,"value":1117},"Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, ",{"type":21,"tag":39,"props":1119,"children":1120},{},[1121],{"type":31,"value":797},{"type":31,"value":1123},", Chao Li.",{"type":21,"tag":33,"props":1125,"children":1126},{},[1127,1129],{"type":31,"value":1128},"Annual Conference of the International Speech Communication Association, ",{"type":21,"tag":39,"props":1130,"children":1131},{},[1132],{"type":31,"value":1133},"INTERSPEECH 2018",{"type":21,"tag":33,"props":1135,"children":1136},{},[1137],{"type":21,"tag":62,"props":1138,"children":1141},{"href":1139,"rel":1140},"https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1477.pdf",[66],[1142],{"type":21,"tag":39,"props":1143,"children":1144},{},[1145],{"type":21,"tag":72,"props":1146,"children":1148},{"alt":11,"src":1147},"/assets/img/project/deep-spectrum/thumbnail-interspeech-18.png",[],{"type":21,"tag":77,"props":1150,"children":1152},{"code":1151,"language":80,"meta":81},"@article{zhao2018exploring,\n  title={Exploring spatio-temporal representations by integrating\n  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition},\n  author={Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao},\n  year={2018}\n}\n",[1153],{"type":21,"tag":84,"props":1154,"children":1155},{},[1156],{"type":21,"tag":77,"props":1157,"children":1158},{"__ignoreMap":11},[1159,1179,1203,1219,1251,1278],{"type":21,"tag":91,"props":1160,"children":1161},{"class":93,"line":94},[1162,1166,1170,1175],{"type":21,"tag":91,"props":1163,"children":1164},{"class":98},[1165],{"type":31,"value":840},{"type":21,"tag":91,"props":1167,"children":1168},{"class":104},[1169],{"type":31,"value":107},{"type":21,"tag":91,"props":1171,"children":1172},{"class":110},[1173],{"type":31,"value":1174},"zhao2018exploring",{"type":21,"tag":91,"props":1176,"children":1177},{"class":104},[1178],{"type":31,"value":118},{"type":21,"tag":91,"props":1180,"children":1181},{"class":93,"line":121},[1182,1186,1190,1194,1198],{"type":21,"tag":91,"props":1183,"children":1184},{"class":104},[1185],{"type":31,"value":861},{"type":21,"tag":91,"props":1187,"children":1188},{"class":110},[1189],{"type":31,"value":178},{"type":21,"tag":91,"props":1191,"children":1192},{"class":98},[1193],{"type":31,"value":142},{"type":21,"tag":91,"props":1195,"children":1196},{"class":149},[1197],{"type":31,"value":107},{"type":21,"tag":91,"props":1199,"children":1200},{"class":104},[1201],{"type":31,"value":1202},"Exploring spatio-temporal representations by integrating\n",{"type":21,"tag":91,"props":1204,"children":1205},{"class":93,"line":168},[1206,1211,1215],{"type":21,"tag":91,"props":1207,"children":1208},{"class":104},[1209],{"type":31,"value":1210},"  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition",{"type":21,"tag":91,"props":1212,"children":1213},{"class":149},[1214],{"type":31,"value":161},{"type":21,"tag":91,"props":1216,"children":1217},{"class":104},[1218],{"type":31,"value":118},{"type":21,"tag":91,"props":1220,"children":1221},{"class":93,"line":209},[1222,1226,1230,1234,1238,1243,1247],{"type":21,"tag":91,"props":1223,"children":1224},{"class":104},[1225],{"type":31,"value":861},{"type":21,"tag":91,"props":1227,"children":1228},{"class":110},[1229],{"type":31,"value":132},{"type":21,"tag":91,"props":1231,"children":1232},{"class":98},[1233],{"type":31,"value":142},{"type":21,"tag":91,"props":1235,"children":1236},{"class":149},[1237],{"type":31,"value":107},{"type":21,"tag":91,"props":1239,"children":1240},{"class":104},[1241],{"type":31,"value":1242},"Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao",{"type":21,"tag":91,"props":1244,"children":1245},{"class":149},[1246],{"type":31,"value":161},{"type":21,"tag":91,"props":1248,"children":1249},{"class":104},[1250],{"type":31,"value":118},{"type":21,"tag":91,"props":1252,"children":1253},{"class":93,"line":243},[1254,1258,1262,1266,1270,1274],{"type":21,"tag":91,"props":1255,"children":1256},{"class":104},[1257],{"type":31,"value":861},{"type":21,"tag":91,"props":1259,"children":1260},{"class":110},[1261],{"type":31,"value":311},{"type":21,"tag":91,"props":1263,"children":1264},{"class":98},[1265],{"type":31,"value":142},{"type":21,"tag":91,"props":1267,"children":1268},{"class":149},[1269],{"type":31,"value":107},{"type":21,"tag":91,"props":1271,"children":1272},{"class":104},[1273],{"type":31,"value":332},{"type":21,"tag":91,"props":1275,"children":1276},{"class":149},[1277],{"type":31,"value":1096},{"type":21,"tag":91,"props":1279,"children":1280},{"class":93,"line":260},[1281],{"type":21,"tag":91,"props":1282,"children":1283},{"class":104},[1284],{"type":31,"value":161},{"type":21,"tag":26,"props":1286,"children":1288},{"id":1287},"contact",[1289],{"type":31,"value":1290},"Contact",{"type":21,"tag":33,"props":1292,"children":1293},{},[1294,1296,1301],{"type":31,"value":1295},"If you have any questions, please feel free to contact ",{"type":21,"tag":62,"props":1297,"children":1299},{"href":1298},"mailto:yiqinzhao@outlook.com",[1300],{"type":31,"value":797},{"type":31,"value":1302},".",{"type":21,"tag":1304,"children":1305},"style",[1306],{"type":31,"value":1307},".ct-60ba0c{color:#E9F284}\n.ct-c36137{color:#8BE9FD}\n.ct-aaaf1d{color:#F8F8F2}\n.ct-ffef9e{color:#FF79C6}",{"title":11,"searchDepth":121,"depth":121,"links":1309},[1310,1311,1312,1313],{"id":28,"depth":121,"text":12},{"id":784,"depth":121,"text":787},{"id":1109,"depth":121,"text":1112},{"id":1287,"depth":121,"text":1290},"markdown","content:project:deep-spectrum.md","content","project/deep-spectrum.md","md",{"/project/deep-spectrum":1320},[1321,1329],{"_path":1322,"_dir":10,"_draft":6,"_partial":6,"_locale":11,"_empty":6,"title":1323,"description":11,"date":1324,"thumbnail":1325,"tag":1326,"layout":16,"_type":1314,"_id":1327,"_source":1316,"_file":1328,"_extension":1318},"/project/2048",2048,"2017-05-03T00:00:00.000Z","/assets/img/project/2048/thumbnail.png","opensource","content:project:2048.md","project/2048.md",{"_path":1330,"_dir":10,"_draft":6,"_partial":6,"_locale":11,"_empty":6,"title":1331,"description":11,"date":1332,"thumbnail":1333,"previewCardDirection":1334,"tag":15,"layout":16,"_type":1314,"_id":1335,"_source":1316,"_file":1336,"_extension":1318},"/project/litar","LitAR: Visually Coherent Lighting for Mobile Augmented Reality","2022-07-29T00:00:00.000Z","/assets/img/project/litar/thumbnail.png","horizontal","content:project:litar.md","project/litar.md",{},[1339,1342,1345,1362],{"title":1340,"_path":1341},"Home","/",{"title":1343,"_path":1344},"News","/news",{"title":1346,"_path":1347,"children":1348,"layout":1361},"Project","/project",[1349,1350,1351,1352,1355,1358],{"title":1323,"_path":1322,"layout":16},{"title":12,"_path":9,"layout":16},{"title":1331,"_path":1330,"layout":16},{"title":1353,"_path":1354,"layout":16},"PointAR: Efficient Lighting Estimation for Mobile Augmented Reality","/project/point-ar",{"title":1356,"_path":1357,"layout":16},"Privacy-preserving Reflection Rendering for Augmented Reality","/project/privacy-preserving-reflection",{"title":1359,"_path":1360,"layout":16},"Xihe: A 3D Vision based Lighting Estimation for Mobile AR","/project/xihe","cards",{"title":1363,"_path":1364},"Research","/research",["Reactive",1366],{"content-query-PXuiWKKLR0":81}]</script><script>window.__NUXT__={};window.__NUXT__.config={public:{content:{locales:[],defaultLocale:"",integrity:1684421366486,experimental:{stripQueryParameters:false,clientDB:false,advancedIgnoresPattern:false},api:{baseURL:"/api/_content"},navigation:{fields:["navTitle","layout"]},tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:["bibtex"]},wsUrl:"",documentDriven:{page:true,navigation:true,surround:true,globals:{},layoutFallbacks:["theme"],injectPage:true},host:"",trailingSlash:false,anchorLinks:{depth:4,exclude:[1]}}},app:{baseURL:"/",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script><script type="module" src="/_nuxt/entry.5757841a.js" crossorigin></script></body>
</html>
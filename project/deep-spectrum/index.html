<html><head><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta charset="utf-8"><link rel="stylesheet" href="/assets/css/base.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css"><link rel="stylesheet" media="(prefers-color-scheme:light)" href="https://cdn.jsdelivr.net/npm/highlightjs@9.16.2/styles/tomorrow.css"><link rel="stylesheet" media="(prefers-color-scheme:dark)" href="https://cdn.jsdelivr.net/npm/highlightjs@9.16.2/styles/atom-one-dark.css"><script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.15.10/build/highlight.min.js"></script><title>Deep Spectrum | Yiqin Zhao</title><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="apple-mobile-web-app-title" content="YiqinZhao"><link rel="apple-touch-icon" sizes="180x180" href="/assets/site-icons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/site-icons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/site-icons/favicon-16x16.png"><link rel="manifest" href="/assets/site.webmanifest"><link rel="shortcut icon" href="/assets/site-icons/favicon.ico" type="image/x-icon"><meta name="msapplication-TileColor" content="#ffffff"><meta name="theme-color" content="#ffffff"><style>body{margin:0}img{width:100%}a{color:var(--font-color)}</style><style>.title{font-size:3rem;font-weight:700;margin:0 0 10px 0}.meta-row{border-bottom:1px dashed rgba(0,0,0,.4);margin-bottom:20px;opacity:.7;font-style:italic;flex-wrap:wrap;padding:10px 0}.meta-row>*{line-height:1.5rem}.date{margin-right:.5rem}.tag{margin-right:.5rem}.markdown strong>img{border:1px solid rgba(0,0,0,.6)}.hero-wrapper{background-color:#f4f5f7;padding:0 0 40px 0}.hero-container{padding:20px 0;position:relative;align-items:flex-start}.markdown strong>img{border:1px solid rgba(0,0,0,.6)}@media (max-width:480px){.meta-row{flex-wrap:wrap}}@media (prefers-color-scheme:dark){.label-icon{filter:invert(1)}.markdown strong>img{filter:invert(.85)}}</style><style>.nav-container{width:100%;height:60px;padding:20px 0;display:flex;flex-direction:row;align-items:center;justify-content:space-between}.logo{font-size:1.5rem;font-weight:700;opacity:.7;cursor:pointer;color:var(--font-color);transition:opacity .1s linear}.logo:hover{opacity:1}.menu-item{font-size:1.3rem;font-weight:700;opacity:.7;text-transform:capitalize;margin:0 17px;padding:0 5px;cursor:pointer;transition:opacity .1s linear,border-bottom .1s linear}.menu-item:hover{opacity:1;border-bottom:3px solid #979797}.menu-item-active{opacity:1;border-bottom:3px solid #979797}.menu-item:nth-last-child(1){margin-right:0}.menu-row>a{color:var(--font-color)}.menu-row>a:hover{text-decoration:none}.menu-button{display:none}.mobile-nav{width:100%;display:none}@media (prefers-color-scheme:dark){#menu-button-icon{filter:invert()}.nav-container{background-color:transparent}}@media (min-width:320px) and (max-width:768px){body{padding-top:61px}.hero-header{overflow:hidden}.logo{display:none}.nav-container{padding:0 0;background-color:rgba(57,57,57,.1);position:fixed;top:0;border-bottom:1px solid #636363;backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px);z-index:1;justify-content:flex-end}.menu-item-active{border-bottom:none}.menu-button{display:block;margin-right:20px}#menu-button-icon{height:17px;width:24px}.mobile-nav{height:60px;display:flex}.mobile-nav>.nav-title{font-size:1.3rem;font-weight:700;text-transform:capitalize;margin:0 17px;padding:0 5px}.nav-container{height:auto;flex-direction:column}.menu-row{padding:5px 0;flex-wrap:wrap;overflow:hidden;justify-content:space-between}.hide-menu-row{height:0;padding:0}.menu-row>.menu-item{margin:10px 17px}}</style><style>.foot{opacity:.6;border-top:1px solid var(--line-color);margin-top:20px;padding:20px 0;font-size:.8rem}.foot a{color:var(--font-color);text-decoration:underline}</style><link rel="stylesheet" href="/assets/css/dark-mode.css"></head><body><header><div class="nav-container"><a class="logo" href="/" style="visibility:visible">Yiqin Zhao</a><div class="mobile-nav stack" horizontal-layout="space-between" vertical-layout="center"><div class="stack nav-title">project</div><div class="menu-button" onclick="onMenuButtonClick()"><img id="menu-button-icon" src="/assets/img/menu.svg" alt=""></div></div><div class="stack menu-row hide-menu-row"><a class="menu-item" href="/">home</a> <a class="menu-item" href="/news/">news</a> <a class="menu-item menu-item-active" href="/project/">project</a> <a class="menu-item" href="/publication/">publication</a> <a class="menu-item" href="/blog/">blog</a> <a class="menu-item" href="/assets/yiqinzhao-cv.pdf">CV</a></div></div><script>function onMenuButtonClick(){let e=document.querySelector(".menu-row").classList;e.contains("hide-menu-row")?(e.remove("hide-menu-row"),document.querySelector("#menu-button-icon").setAttribute("src","/assets/img/close.svg")):(e.add("hide-menu-row"),document.querySelector("#menu-button-icon").setAttribute("src","/assets/img/menu.svg"))}</script></header><article class="stack" direction="column"><div class="stack" direction="column"><div class="title">Deep Spectrum</div><div class="stack meta-row" vertical-layout="center"><div class="date">Nov 19, 2019</div><span class="tag stack" vertical-layout="center"><img class="vector-image" src="/assets/icons/tag.svg" alt=""> Research</span><div class="eta">ETA: 2min(s)</div></div></div><div class="markdown"><h1 id="paper">Paper</h1><p>Zhao, Ziping and <strong>Zhao, Yiqin</strong> and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao</p><p><strong>Deep Spectrum Feature Representations for Speech Emotion Recognition</strong></p><p>Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data (<strong>ASMMC-MMAC'18</strong>)</p><p><a href="https://dl.acm.org/doi/10.1145/3267935.3267948"><strong><img src="thumbnail-asmmc-18.png" alt=""></strong></a></p><pre class="hljs"><code>@inproceedings{
    Zhao:2018:DSF:3267935.3267948,
    author = {Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao},
    title = {Deep Spectrum Feature Representations for Speech Emotion Recognition},
    booktitle = {Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data},
    series = {ASMMC-MMAC'18},
    year = {2018},
    isbn = {978-1-4503-5985-6},
    location = {Seoul, Republic of Korea},
    pages = {27--33},
    numpages = {7},
    url = {http://doi.acm.org/10.1145/3267935.3267948},
    doi = {10.1145/3267935.3267948},
    acmid = {3267948},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {attention mechanism, bidirectional long short-term memory, fully convolutional networks, spectrogram representation, speech emotion recognition},
}
</code></pre><hr><p>Ziping Zhao, Zhongtian Bao, <strong>Yiqin Zhao</strong>, Zixing Zhang, Nicholas Cummins, Zhao Ren, Björn Schuller</p><p><strong>Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition</strong></p><p><strong>IEEE Access 2019</strong></p><p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762126"><strong><img src="thumbnail-ieee-19.png" alt=""></strong></a></p><pre class="hljs"><code>@article{zhao2019exploring,
  title={Exploring deep spectrum representations via attention-based recurrent and convolutional neural networks for speech emotion recognition},
  author={Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins, Nicholas and Ren, Zhao and Schuller, Bj{\&quot;o}rn},
  journal={IEEE Access},
  volume={7},
  pages={97515--97525},
  year={2019},
  publisher={IEEE}
}
</code></pre><hr><p>Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, <strong>Yiqin Zhao</strong>, Chao Li.</p><p><strong>Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition</strong></p><p>Annual Conference of the International Speech Communication Association, <strong>INTERSPEECH 2018</strong></p><p><a href="https://www.isca-speech.org/archive/Interspeech_2018/pdfs/1477.pdf"><strong><img src="thumbnail-interspeech-18.png" alt=""></strong></a></p><pre class="hljs"><code>@article{zhao2018exploring,
  title={Exploring spatio-temporal representations by integrating attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition},
  author={Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao},
  year={2018}
}
</code></pre><h1 id="contact">Contact</h1><p>If you have any questions, please feel free to contact <a href="mailto:yiqinzhao@outlook.com">Yiqin Zhao</a>.</p></div></article><footer class="stack foot" direction="column" horizontal-layout="center"><span>© <a href="/">Yiqin Zhao</a> 2021. Last Updated: Apr 6, 2021</span> <span>Proudly Powered by <a href="https://github.com/YiqinZhao/Ploceus">Ploceus</a></span></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/sweetalert/2.1.2/sweetalert.min.js" integrity="sha512-AA1Bzp5Q0K1KanKKmvN/4d3IRKVlv9PYgwFPvm32nPO6QS8yH1HO7LbgB1pgiOxPtfeg5zEn2ba64MUcqJx6CA==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/crypto-js/4.0.0/crypto-js.min.js" integrity="sha512-nOQuvD9nKirvxDdvQ9OMqe2dgapbPB7vYAMrzJihw5m+aNcf0dX53m6YxM4LgA9u8e9eg9QX+/+mPu8kCNpV2A==" crossorigin="anonymous"></script><script>window.addEventListener("load",function(){document.querySelectorAll(".encrypted").forEach(e=>{e.addEventListener("click",function(){this.classList.contains("encrypted")&&swal("Password",{content:"input"}).then(t=>{let e=this;for(;!e.classList.contains("markdown");)e=e.parentNode;e.querySelectorAll(".encrypted").forEach(e=>{e.innerHTML=CryptoJS.AES.decrypt(e.innerHTML,t).toString(CryptoJS.enc.Utf8),e.classList.remove("encrypted"),e.classList.add("decrypted")})})})})})</script></body></html>
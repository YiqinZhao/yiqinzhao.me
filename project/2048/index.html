<!DOCTYPE html>
<html  data-head-attrs="">

<head >
  <title>2048 - Yiqin Zhao</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><script>const w=window,de=document.documentElement,knownColorSchemes=["dark","light"],preference=window.localStorage.getItem("nuxt-color-mode")||"system";let value=preference==="system"?getColorScheme():preference;const forcedColorMode=de.getAttribute("data-color-mode-forced");forcedColorMode&&(value=forcedColorMode),addColorScheme(value),w["__NUXT_COLOR_MODE__"]={preference,value,getColorScheme,addColorScheme,removeColorScheme};function addColorScheme(e){const o=""+e+"",t="";de.classList?de.classList.add(o):de.className+=" "+o,de.setAttribute("data-"+t,e)}function removeColorScheme(e){const o=""+e+"",t="";de.classList?de.classList.remove(o):de.className=de.className.replace(new RegExp(o,"g"),""),de.removeAttribute("data-"+t)}function prefersColorScheme(e){return w.matchMedia("(prefers-color-scheme"+e+")")}function getColorScheme(){if(w.matchMedia&&prefersColorScheme("").media!=="not all"){for(const e of knownColorSchemes)if(prefersColorScheme(":"+e).matches)return e}return"light"}
</script><link rel="prefetch" href="/api/_content/navigation"><link rel="prefetch" href="/api/_content/query/974547485"><link rel="prefetch" href="/api/_content/query/2308430125"><link rel="icon" type="image/x-icon" href="/site-icons/favicon.ico"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css"><meta name="theme-color" content="#292525" media="(prefers-color-scheme: dark)"><link rel="prefetch" href="/api/_content/query/974547485"><meta name="head:count" content="10"><link rel="modulepreload" href="/_nuxt/entry-9e31c386.mjs" as="script" crossorigin><link rel="preload" href="/_nuxt/entry.7bd4a776.css" as="style"><link rel="modulepreload" href="/_nuxt/document-driven-bdb91279.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/head-b981332b.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/default-b50e60ff.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/Navigator-5333eb4d.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/ContentDoc-5d6037f2.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/ContentQuery-897bd602.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/asyncData-9ad6a369.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/Footer-2b6f07e5.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/MarkdownHeader-630b7bbe.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/ProseP-32d2804f.mjs" as="script" crossorigin><link rel="modulepreload" href="/_nuxt/ProseA-3670aa8a.mjs" as="script" crossorigin><link rel="prefetch" as="script" href="/_nuxt/ContactItem-b5eef43c.mjs"><link rel="prefetch" as="script" href="/_nuxt/Markdown-e4b7a499.mjs"><link rel="prefetch" as="script" href="/_nuxt/ExperienceRow-e1b85240.mjs"><link rel="prefetch" as="script" href="/_nuxt/MoreProjects-84ebba0b.mjs"><link rel="prefetch" as="script" href="/_nuxt/ContentList-9df62ca6.mjs"><link rel="prefetch" as="script" href="/_nuxt/PublicationRow-626fbe5d.mjs"><link rel="prefetch" as="script" href="/_nuxt/ShortNews-c61c7249.mjs"><link rel="prefetch" as="script" href="/_nuxt/IndexHeader-b68ce623.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProjectHeader-7719ac05.mjs"><link rel="prefetch" as="script" href="/_nuxt/ContentNavigation-f0220137.mjs"><link rel="prefetch stylesheet" href="/_nuxt/ContentNavigation.9afc708c.css"><link rel="prefetch stylesheet" href="/_nuxt/ProseCode.c12da1e5.css"><link rel="prefetch" as="script" href="/_nuxt/ProseCode-ec17a6ad.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseBlockquote-9b7094ae.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseCodeInline-2a3f569a.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseEm-429eac59.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseH1-63dd92d2.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseH2-0633b9af.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseH3-4f7ee582.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseH4-ab5361e5.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseH5-8e2cee5e.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseH6-3d7e3b99.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseHr-9965c375.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseImg-b3442da1.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseLi-dd6e1caa.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseOl-a99f08bf.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseStrong-3810780e.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseTable-91c0e939.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseTbody-27a58c6d.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseTd-c970ad47.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseTh-c348d8e5.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseThead-8a3eed15.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseTr-ece20e9b.mjs"><link rel="prefetch" as="script" href="/_nuxt/ProseUl-37083323.mjs"><link rel="prefetch" as="script" href="/_nuxt/cards-d9a929c8.mjs"><link rel="prefetch" as="script" href="/_nuxt/web-socket-138557ce.mjs"><link rel="stylesheet" href="/_nuxt/entry.7bd4a776.css">
</head>

<body  data-head-attrs="">
  <div id="__nuxt"><!--[--><!----><!----><!----><!----><div class="document-driven-page"><!--[--><!--[--><div class="hidden md:block text-normal px-4 py-2 text-gray-500 dark:text-gray-400 mx-auto bg-gray-100 dark:bg-gray-800"><div class="md:flex justify-between max-w-6xl mx-auto"><a class="text-xl font-bold hover:dark:text-white hover:text-black transition-colors" href="/"><span class=""><img class="inline w-10 dark:invert transition-opacity opacity-60 hover:opacity-100" src="/assets/img/qin-logo.svg" alt=""></span></a><div class="flex flex-row justify-center"><!--[--><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/"><span class="transition-border hover:border-b-2 border-b-gray-400">Home</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/news/"><span class="transition-border hover:border-b-2 border-b-gray-400">News</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/research/"><span class="transition-border hover:border-b-2 border-b-gray-400">Research</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/project/"><span class="transition-border text-black dark:text-white border-b-2 border-b-gray-400">Projects</span></a><a class="pl-10 font-medium hover:dark:text-white hover:text-black transition-colors flex items-center" href="/yiqinzhao-cv.pdf"><span class="transition-border hover:border-b-2 border-b-gray-400">CV</span></a><!--]--></div></div></div><div class="fixed flex md:hidden flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="flex md:hidden opacity-0 flex-row justify-between p-5 text-black dark:text-white bg-gray-100 dark:bg-gray-800 z-30 w-full top-0"><span class="text-xl font-bold">Projects</span><span><img class="inline dark:invert" src="/assets/img/icons/menu.svg" alt=""></span></div><div class="hidden fixed flex flex-col justify-between w-full h-full top-0 left-0 bg-gray-100 dark:bg-gray-800 z-20"><div class="flex flex-col p-5 pt-24 text-xl text-gray-400 dark:text-gray-500"><!--[--><a class="hover:text-white transition-color py-3" href="/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Home</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/news/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">News</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/research/"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">Research</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/project/"><div class="flex justify-between"><span class="text-black dark:text-white font-medium">Projects</span><img class="opacity-100 dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><a class="hover:text-white transition-color py-3" href="/yiqinzhao-cv.pdf"><div class="flex justify-between"><span class="transition-border hover:border-b-4 border-b-gray-400">CV</span><img class="dark:invert w-6 opacity-50" src="/assets/img/icons/arrow-right-bold.svg" alt=""></div></a><!--]--></div><div class="text-gray-400 dark:text-gray-500 text-center py-4">Yiqin Zhao</div></div><!--]--><article class="[&amp;_p_img]:md:max-w-[140%] [&amp;_p_img]:md:mx-[-20%] pb-8 min-h-[100vh] [&amp;_header]:md:max-w-[140%] [&amp;_header]:md:mx-[-20%] [&amp;_pre]:md:max-w-[140%] [&amp;_pre]:md:mx-[-20%]"><!--[--><div class="prose dark:prose-invert mx-auto p-4 md:text-lg [&amp;_h1]:mt-12"><!--[--><h1 class="dark:text-white text-center text-4xl md:text-5xl font-bold mb-0 mt-0 md:mt-10 max-w-5xl mx-auto">2048</h1><!----><!--]--><p><!--[-->Source: <a href="https://github.com/coden-hk/2048" rel="nofollow noopener noreferrer" target="_blank"><!--[-->GitHub<!--]--></a><!--]--></p><p><!--[-->Online address: <a href="https://2048.coden.hk" rel="nofollow noopener noreferrer" target="_blank"><!--[-->https://2048.coden.hk<!--]--></a> (If you are on mobile phone, use this link.)<!--]--></p><iframe style="width: 100%; height: min(calc(100vw / 4 * 3), 900px); border: none" src="https://2048.coden.hk"></iframe></div><!--]--></article><div class="bg-gray-100 dark:bg-gray-800 py-12"><div class="text-center text-gray-500 dark:text-gray-400 max-w-6xl mx-auto"><p>© <a href="https://yiqinzhao.me">Yiqin Zhao</a> 2022. Last updated: 7/9/2022</p><p>Use my website <a class="underline" href="https://github.com/YiqinZhao/yiqinzhao.me-source">template</a>. </p></div></div><!--]--></div><!--]--></div><script>window.__NUXT__=(function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z){return {data:{"content-query-3972461203":{_path:G,_draft:e,_partial:e,_empty:e,title:H,description:d,excerpt:{type:o,children:[{type:a,tag:q,props:{":title":r},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:s},{type:a,tag:f,props:{href:t,rel:[h,i,j],target:k},children:[{type:b,value:u}]}]},{type:a,tag:c,props:{},children:[{type:b,value:v},{type:a,tag:f,props:{href:g,rel:[h,i,j],target:k},children:[{type:b,value:g}]},{type:b,value:w}]},{type:a,tag:x,props:{style:y,src:g},children:[]}]},date:L,thumbnail:M,tag:N,layout:m,body:{type:o,children:[{type:a,tag:q,props:{":title":r},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:s},{type:a,tag:f,props:{href:t,rel:[h,i,j],target:k},children:[{type:b,value:u}]}]},{type:a,tag:c,props:{},children:[{type:b,value:v},{type:a,tag:f,props:{href:g,rel:[h,i,j],target:k},children:[{type:b,value:g}]},{type:b,value:w}]},{type:a,tag:x,props:{style:y,src:g},children:[]}],toc:{title:d,searchDepth:z,depth:z,links:[]}},_type:A,_id:O,_source:B,_file:P,_extension:C}},state:{error:null,"color-mode":{preference:Q,value:Q,unknown:n,forced:e},"dd-pages":{"/project/2048":{_path:G,_draft:e,_partial:e,_empty:e,title:H,description:d,excerpt:{type:o,children:[{type:a,tag:q,props:{":title":r},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:s},{type:a,tag:f,props:{href:t,rel:[h,i,j],target:k},children:[{type:b,value:u}]}]},{type:a,tag:c,props:{},children:[{type:b,value:v},{type:a,tag:f,props:{href:g,rel:[h,i,j],target:k},children:[{type:b,value:g}]},{type:b,value:w}]},{type:a,tag:x,props:{style:y,src:g},children:[]}]},date:L,thumbnail:M,tag:N,layout:m,body:{type:o,children:[{type:a,tag:q,props:{":title":r},children:[]},{type:a,tag:c,props:{},children:[{type:b,value:s},{type:a,tag:f,props:{href:t,rel:[h,i,j],target:k},children:[{type:b,value:u}]}]},{type:a,tag:c,props:{},children:[{type:b,value:v},{type:a,tag:f,props:{href:g,rel:[h,i,j],target:k},children:[{type:b,value:g}]},{type:b,value:w}]},{type:a,tag:x,props:{style:y,src:g},children:[]}],toc:{title:d,searchDepth:z,depth:z,links:[]}},_type:A,_id:O,_source:B,_file:P,_extension:C}},"dd-surrounds":{"/project/2048":[{_path:R,_draft:e,_partial:e,_empty:n,title:S,description:d,excerpt:{type:o,children:[]},layout:T,hideTitle:n,_type:A,_id:"content:project.md",_source:B,_file:"project.md",_extension:C},{_path:U,_draft:e,_partial:e,_empty:e,title:D,description:d,excerpt:{type:o,children:[{type:a,tag:q,props:{title:D},children:[]},{type:a,tag:E,props:{id:"deep-spectrum-feature-representations-for-speech-emotion-recognition"},children:[{type:b,value:D}]},{type:a,tag:c,props:{},children:[{type:b,value:"Zhao, Ziping and "},{type:a,tag:l,props:{},children:[{type:b,value:"Zhao, Yiqin"}]},{type:b,value:" and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao"}]},{type:a,tag:c,props:{},children:[{type:b,value:"Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data ("},{type:a,tag:l,props:{},children:[{type:b,value:"ASMMC-MMAC'18"}]},{type:b,value:")"}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{href:"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3267935.3267948",rel:[h,i,j],target:k},children:[{type:a,tag:l,props:{},children:[{type:a,tag:I,props:{alt:d,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-asmmc-18.png"},children:[]}]}]}]},{type:a,tag:p,props:{code:V,language:F},children:[{type:a,tag:J,props:{},children:[{type:a,tag:p,props:{__ignoreMap:d},children:[{type:b,value:V}]}]}]},{type:a,tag:W,props:{},children:[]},{type:a,tag:E,props:{id:"exploring-deep-spectrum-representations-via-attention-based-recurrent-and-convolutional-neural-networks-for-speech-emotion-recognition"},children:[{type:b,value:"Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition"}]},{type:a,tag:c,props:{},children:[{type:b,value:"Ziping Zhao, Zhongtian Bao, "},{type:a,tag:l,props:{},children:[{type:b,value:K}]},{type:b,value:", Zixing Zhang, Nicholas Cummins, Zhao Ren, Björn Schuller"}]},{type:a,tag:c,props:{},children:[{type:a,tag:l,props:{},children:[{type:b,value:"IEEE Access 2019"}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{href:"https:\u002F\u002Fieeexplore.ieee.org\u002Fstamp\u002Fstamp.jsp?arnumber=8762126",rel:[h,i,j],target:k},children:[{type:a,tag:l,props:{},children:[{type:a,tag:I,props:{alt:d,src:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail-ieee-19.png"},children:[]}]}]}]},{type:a,tag:p,props:{code:X,language:F},children:[{type:a,tag:J,props:{},children:[{type:a,tag:p,props:{__ignoreMap:d},children:[{type:b,value:X}]}]}]},{type:a,tag:W,props:{},children:[]},{type:a,tag:E,props:{id:"exploring-spatio-temporal-representations-by-integrating-attention-based-bidirectional-lstm-rnns-and-fcns-for-speech-emotion-recognition"},children:[{type:b,value:"Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition"}]},{type:a,tag:c,props:{},children:[{type:b,value:"Ziping Zhao, Yu Zheng, Zixing Zhang, Haishuai Wang, "},{type:a,tag:l,props:{},children:[{type:b,value:K}]},{type:b,value:", Chao Li."}]},{type:a,tag:c,props:{},children:[{type:b,value:"Annual Conference of the International Speech Communication Association, "},{type:a,tag:l,props:{},children:[{type:b,value:"INTERSPEECH 2018"}]}]},{type:a,tag:c,props:{},children:[{type:a,tag:f,props:{href:"https:\u002F\u002Fwww.isca-speech.org\u002Farchive\u002FInterspeech_2018\u002Fpdfs\u002F1477.pdf",rel:[h,i,j],target:k},children:[{type:a,tag:l,props:{},children:[{type:a,tag:I,props:{alt:d,src:"thumbnail-interspeech-18.png"},children:[]}]}]}]},{type:a,tag:p,props:{code:Y,language:F},children:[{type:a,tag:J,props:{},children:[{type:a,tag:p,props:{__ignoreMap:d},children:[{type:b,value:Y}]}]}]},{type:a,tag:E,props:{id:"contact"},children:[{type:b,value:"Contact"}]},{type:a,tag:c,props:{},children:[{type:b,value:"If you have any questions, please feel free to contact "},{type:a,tag:f,props:{href:"mailto:yiqinzhao@outlook.com"},children:[{type:b,value:K}]},{type:b,value:"."}]}]},date:"2018-06-12T00:00:00.000Z",thumbnail:"\u002Fassets\u002Fimg\u002Fproject\u002Fdeep-spectrum\u002Fthumbnail.png",tag:"research",layout:m,_type:A,_id:"content:project:deep-spectrum.md",_source:B,_file:"project\u002Fdeep-spectrum.md",_extension:C}]},"dd-globals":{},"dd-navigation":[{title:"Home",_path:Z},{title:"News",_path:"\u002Fnews"},{title:S,_path:R,children:[{title:H,_path:G,layout:m},{title:D,_path:U,layout:m},{title:"PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",_path:"\u002Fproject\u002Fpoint-ar",layout:m},{title:"Privacy-preserving Reflection Rendering for Augmented Reality",_path:"\u002Fproject\u002Fprivacy-preserving-reflection",layout:m},{title:"Xihe: A 3D Vision based Lighting Estimation for Mobile AR",_path:"\u002Fproject\u002Fxihe",layout:m}],layout:T},{title:"Research",_path:"\u002Fresearch"}]},_errors:{},serverRendered:n,config:{public:{content:{base:"_content",tags:{p:"prose-p",a:"prose-a",blockquote:"prose-blockquote","code-inline":"prose-code-inline",code:"prose-code",em:"prose-em",h1:"prose-h1",h2:"prose-h2",h3:"prose-h3",h4:"prose-h4",h5:"prose-h5",h6:"prose-h6",hr:"prose-hr",img:"prose-img",ul:"prose-ul",ol:"prose-ol",li:"prose-li",strong:"prose-strong",table:"prose-table",thead:"prose-thead",tbody:"prose-tbody",td:"prose-td",th:"prose-th",tr:"prose-tr"},highlight:{theme:"dracula",preload:[F]},wsUrl:d,documentDriven:{page:n,navigation:n,surround:n,globals:{},layoutFallbacks:["theme"],injectPage:n}}},app:{baseURL:Z,buildAssetsDir:"\u002F_nuxt\u002F",cdnURL:d}}}}("element","text","p","",false,"a","https:\u002F\u002F2048.coden.hk","nofollow","noopener","noreferrer","_blank","strong","default",true,"root","code","markdown-header","2048","Source: ","https:\u002F\u002Fgithub.com\u002Fcoden-hk\u002F2048","GitHub","Online address: "," (If you are on mobile phone, use this link.)","iframe","width: 100%; height: min(calc(100vw \u002F 4 * 3), 900px); border: none",2,"markdown","content","md","Deep Spectrum Feature Representations for Speech Emotion Recognition","h2","bibtex","\u002Fproject\u002F2048",2048,"img","pre","Yiqin Zhao","2017-05-03T00:00:00.000Z","\u002Fassets\u002Fimg\u002Fproject\u002F2048\u002Fthumbnail.png","opensource","content:project:2048.md","project\u002F2048.md","system","\u002Fproject","Project","cards","\u002Fproject\u002Fdeep-spectrum","@inproceedings{deep_spectrum_2018,\n    author = {Zhao, Ziping and Zhao, Yiqin and Bao, Zhongtian and Wang, Haishuai and Zhang, Zixing and Li, Chao},\n    title = {Deep Spectrum Feature Representations for Speech Emotion Recognition},\n    booktitle = {Proceedings of the Joint Workshop of the 4th Workshop on Affective Social Multimedia\n    Computing and First Multi-Modal Affective Computing of Large-Scale Multimedia Data},\n    series = {ASMMC-MMAC'18},\n    year = {2018},\n    isbn = {978-1-4503-5985-6},\n    location = {Seoul, Republic of Korea},\n    pages = {27--33},\n    numpages = {7},\n    url = {http:\u002F\u002Fdoi.acm.org\u002F10.1145\u002F3267935.3267948},\n    doi = {10.1145\u002F3267935.3267948},\n    acmid = {3267948},\n    publisher = {ACM},\n    address = {New York, NY, USA},\n    keywords = {attention mechanism, bidirectional long short-term memory,\n    fully convolutional networks, spectrogram representation, speech emotion recognition},\n}\n","hr","@article{zhao2019exploring,\n  title={Exploring deep spectrum representations via attention-based recurrent and\n  convolutional neural networks for speech emotion recognition},\n  author={\n    Zhao, Ziping and Bao, Zhongtian and Zhao, Yiqin and Zhang, Zixing and Cummins,\n    Nicholas and Ren, Zhao and Schuller, Bj{\\\"o}rn},\n  journal={IEEE Access},\n  volume={7},\n  pages={97515--97525},\n  year={2019},\n  publisher={IEEE}\n}\n","@article{zhao2018exploring,\n  title={Exploring spatio-temporal representations by integrating\n  attention-based bidirectional-LSTM-RNNs and FCNs for speech emotion recognition},\n  author={Zhao, Ziping and Zheng, Yu and Zhang, Zixing and Wang, Haishuai and Zhao, Yiqin and Li, Chao},\n  year={2018}\n}\n","\u002F"))</script><script type="module" src="/_nuxt/entry-9e31c386.mjs" crossorigin></script><script type="module" src="/_nuxt/document-driven-bdb91279.mjs" crossorigin></script><script type="module" src="/_nuxt/default-b50e60ff.mjs" crossorigin></script><script type="module" src="/_nuxt/Navigator-5333eb4d.mjs" crossorigin></script><script type="module" src="/_nuxt/Footer-2b6f07e5.mjs" crossorigin></script><script type="module" src="/_nuxt/MarkdownHeader-630b7bbe.mjs" crossorigin></script><script type="module" src="/_nuxt/ProseP-32d2804f.mjs" crossorigin></script><script type="module" src="/_nuxt/ProseA-3670aa8a.mjs" crossorigin></script>
</body>

</html>
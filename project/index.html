<html><style>
    body {
        margin: 0;
    }

    img {
        width: 100%;
    }

    a {
        color: rgba(86, 150, 231, 100);
    }
</style><head><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta charset="utf-8"><link rel="stylesheet" href="/assets/base.css"><title>Project | Yiqin Zhao</title></head><style>
        .title {
            font-size: 3rem;
            font-weight: bold;
            margin: 20px 0 10px 0;
        }

        .meta-row {
            height: 35px;
            border-bottom: 1px dashed rgba(0, 0, 0, 0.4);
            margin-bottom: 20px;
        }

        .meta-row > div {
            margin-right: 10px;
        }

        .category {
            font-weight: 600;
        }

        .eta {
            color: rgba(0, 0, 0, 0.3);
        }
    </style><body><style>
    .responsive-container {
        margin: 0 auto;
    }

    @media (min-width: 768px) {
        .responsive-container {
            max-width: 1200px;
        }
    }
</style><div class="responsive-container" style="display:flex;flex-direction:column;"><style>
    .nav-container {
        width: calc(100%);
        height: 60px;
        padding: 20px 0;

        display: flex;
        align-items: center;
    }

    .qin {
        width: 50px;
        height: 50px;

        padding: 7px;

        box-sizing: border-box;

        border: 1px dashed rgba(0, 0, 0, 0.3);

        position: relative;
    }

    .qin > img {
        position: absolute;
        width: 34px;
        z-index: 1;
    }

    .qin:before {
        width: 25px;
        height: 25px;
        border-right: 1px dashed rgba(0, 0, 0, 0.3);
        border-bottom: 1px dashed rgba(0, 0, 0, 0.3);
        box-sizing: border-box;

        position: absolute;
        top: 0;
        left: 0;

        content: "";

        z-index: 0;
    }

    .qin:after {
        width: 24px;
        height: 24px;
        border-top: 1px dashed rgba(0, 0, 0, 0.3);
        border-left: 1px dashed rgba(0, 0, 0, 0.3);
        box-sizing: border-box;

        position: absolute;
        right: 0;
        bottom: 0;

        content: "";

        z-index: 0;
    }

    .menu-item {
        font-size: 1.2rem;
        text-transform: uppercase;

        margin: 0 20px;
        cursor: pointer;

        transition: color 100ms linear;
    }

    .menu-item:hover {
        color: rgba(86, 150, 231, 100);
    }

    .menu-item-active {
        color: rgba(86, 150, 231, 100);
    }

    .icon {
        width: 100px;
        height: 50px;

        padding: 7px;

        box-sizing: border-box;

        opacity: 0.8;
    }

    .icon > img {
        width: 50px;
    }
</style><div class="nav-container" style="display:flex;align-items:center;justify-content:space-between;"><div class="qin" style="display:flex;"><img src="/assets/qin.svg"></div><div style="display:flex;"><div class="menu-item" onclick="onMenuItemClick('/')">home</div><div class="menu-item" onclick="onMenuItemClick('/news')">news</div><div class="menu-item menu-item-active" onclick="onMenuItemClick('/project')">project</div><div class="menu-item" onclick="onMenuItemClick('/publication')">publication</div><div class="menu-item" onclick="onMenuItemClick('/posts')">posts</div><div class="menu-item" onclick="onMenuItemClick('/cv')">CV</div></div><div class="icon" style="display:flex;justify-content:space-between;"><img src="/assets/twitter.svg"><img src="/assets/github.svg"></div></div><script>
function onMenuItemClick(target) {
    if (target === '/cv') window.open('/assets/yiqinzhao-cv.pdf')
    else window.location.href = target
}
</script><div class="markdown"><h1>Introduction</h1>
<p>Currently I'm a research student in Worcester Polytechnic Institute <a href="https://cake-lab.github.io">CakeLab</a>, my research interests include the broad area of computer system and machine learning. You can see the <a href="#System-and-Machine-Learning">projects</a> I'm working on now. Previously in my undergraduate study, I'm a student in the cognition and affective computing lab, Tianjin Normal University. In there, my research <a href="#-Affective-Computing">project</a> is focused on speech emotion recognition with deep learning.</p>
<p>Besides my research, I'm also a geek and a developer. I love to explore and play with popular programming languages and frameworks. Specifically, I love JavaScript and Swift. And I also do creative artworks. <a href="##Hackathon-Projects">Here</a> are serval hackathon and open source projects I created.</p>
<h2>System and Machine Learning</h2>
<p>Still Working on it...</p>
<h2>Affective Computing</h2>
<h3><a href="/projects/deep-spectrum">Deep Spectrum Feature Representations for Speech Emotion Recognition</a></h3>
<p>Automatically detecting emotional state in human speech, which plays an effective role in areas of human machine interactions, has been a difficult task for machine learning algorithms. Previous work for emotion recognition have mostly focused on the extraction of carefully hand-crafted and tailored features. Recently, spectrogram representations of emotion speech have achieved competitive per- formance for automatic speech emotion recognition. In this work we propose a method to tackle the problem of deep features, herein denoted as deep spectrum features, extraction from the spectrogram by leveraging Attention-based Bidirectional Long Short-Term Mem- ory Recurrent Neural Networks with fully convolutional networks. The learned deep spectrum features are then fed into a deep neural network (DNN) to predict the final emotion. The proposed model is then evaluated on the Interactive Emotional Dyadic Motion Cap- ture (IEMOCAP) dataset to validate its effectiveness. Promising results indicate that our deep spectrum representations extracted from the proposed model perform the best, 65.2% for weighted accuracy and 68.0% for unweighted accuracy when compared to other existing methods. We then compare the performance of our deep spectrum features with two standard acoustic feature repre- sentations for speech-based emotion recognition. When combined with a support vector classifier, the performance of the deep feature representations extracted are comparable with the conventional features. Moreover, we also investigate the impact of different fre- quency resolutions of the input spectrogram on the performance of the system.</p>
<h2>Hackathon Projects</h2>
<h3><a href="/projects/blog">My Personal Blog yiqinzhao.me</a></h3>
<p><strong>TODO</strong></p>
</div><style>
    .foot {
        border-top: 1px solid rgba(0, 0, 0, 0.1);
        margin-top: 20px;
        padding: 20px 0;

        color: rgba(0, 0, 0, 0.4);

        font-size: 0.8rem;
    }
</style><div class="foot" style="display:flex;justify-content:center;">Â© Yiqin Zhao 2020. Last Updated: Mar 11, 2020</div></div></body></html>
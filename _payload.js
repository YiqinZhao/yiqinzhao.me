export default (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa){return {data:{"content-query-1DxZ1vYQk5":{_path:"\u002F",_dir:j,_draft:l,_partial:l,_locale:j,_empty:l,title:"Home",description:j,hideTitle:r,disableFancyImage:r,body:{type:z,children:[{type:a,tag:"index-header",props:{},children:[]},{type:a,tag:m,props:{id:A},children:[{type:b,value:B}]},{type:a,tag:f,props:{},children:[{type:b,value:"üîä "},{type:a,tag:"em",props:{},children:[{type:b,value:"My name pounces as: Yi-Chin"}]}]},{type:a,tag:f,props:{},children:[{type:b,value:"I am a fourth-year Computer Science M.S.\u002FPh.D. candidate at "},{type:a,tag:e,props:{href:"https:\u002F\u002Fwpi.edu",rel:[g]},children:[{type:b,value:"Worcester Polytechnic Institute (WPI)"}]},{type:b,value:" and a proud member of "},{type:a,tag:e,props:{href:"https:\u002F\u002Fcake-lab.github.io",rel:[g]},children:[{type:b,value:C}]},{type:b,value:" research group.\nI feel extremely fortunate to be advised by my kind and wise advisor "},{type:a,tag:e,props:{href:s,rel:[g]},children:[{type:b,value:t}]},{type:b,value:".\nI am interested in designing system supports and optimizations for Augmented Reality (AR) applications.\nMy recent research has a strong focus on designing system support for AR environment lighting understanding and photorealistic rendering."}]},{type:a,tag:f,props:{},children:[{type:b,value:"In the past, I have interned at "},{type:a,tag:e,props:{href:"https:\u002F\u002Fbaidu.com",rel:[g]},children:[{type:b,value:"Baidu"}]},{type:b,value:" (Summer 2018), "},{type:a,tag:e,props:{href:u,rel:[g]},children:[{type:b,value:"Kuaishou Y-tech Graphics AI team"}]},{type:b,value:" in Spring 2022, and "},{type:a,tag:e,props:{href:"https:\u002F\u002Farvr.google.com",rel:[g]},children:[{type:b,value:"GoogleARVR"}]},{type:b,value:" in Summer\u002FFall 2022.\nIn my spare time, I enjoy hiking, road tripping, and work on my "},{type:a,tag:e,props:{href:"https:\u002F\u002Fgithub.com\u002FYiqinZhao\u002Fyiqinzhao.me-source",rel:[g]},children:[{type:b,value:"website templates"}]},{type:b,value:D}]},{type:a,tag:m,props:{id:E},children:[{type:b,value:F}]},{type:a,tag:"short-news",props:{},children:[]},{type:a,tag:f,props:{},children:[{type:a,tag:e,props:{href:"\u002Fnews\u002F"},children:[{type:b,value:"More news \u003E\u003E\u003E"}]}]},{type:a,tag:m,props:{id:G},children:[{type:b,value:H}]},{type:a,tag:o,props:{icon:"google.png"},children:[{type:a,tag:f,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Google, Mountain View, CA"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nStudent Researcher"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nMay 2022 - Present"}]}]},{type:a,tag:o,props:{icon:"wpi.png"},children:[{type:a,tag:f,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Worcester Polytechnic Institute, Worcester, MA"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nPh.D. Student in "},{type:a,tag:e,props:{href:"https:\u002F\u002Fcake.wpi.edu",rel:[g]},children:[{type:b,value:"TheCakeLab"}]},{type:b,value:", advised by "},{type:a,tag:e,props:{href:s,rel:[g]},children:[{type:b,value:t}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nAug 2021 - Present"}]}]},{type:a,tag:o,props:{icon:"kuaishou.png"},children:[{type:a,tag:f,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Kuaishou Technology, Palo Alto, CA"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nResearch Intern"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nJan, 2022 - May, 2022"}]}]},{type:a,tag:o,props:{icon:"baidu.png"},children:[{type:a,tag:f,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Baidu, Beijing, China"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nSoftware Engineering Intern"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nJun, 2018 - Sept, 2018"}]}]},{type:a,tag:o,props:{icon:"tjnu.png"},children:[{type:a,tag:f,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Tianjin Normal University, Tianjin, China"}]},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nBachelor of Engineering in Software Engineering"},{type:a,tag:h,props:{},children:[]},{type:b,value:"\nSept, 2015 - Jun, 2019"}]}]},{type:a,tag:m,props:{id:I},children:[{type:b,value:J}]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3572864.3580337\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2301.06143.pdf\",\"Poster\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1KtCARV-pV8DKFMGCRE0Qw6rgR3esFdX6\u002Fview?usp=sharing\",\"Slides\":\"https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1Hu4WWFL4gnMPgSf68ntfeSme2KnY3MQKopG9w4BirQI\u002Fedit?usp=sharing\"}",":authors":"[\"Yiqin Zhao\",\"Sean Fanello\",\"Tian Guo\"]",":venue":"{\"acronym\":\"HotMobile\",\"year\":2023,\"name\":\"The Twenty-fourth International Workshop on Mobile Computing Systems and Applications\"}",thumbnail:"dual-light-hotmobile2023.png",title:"Multi-Camera Lighting Estimation for Photorealistic Front-Facing Mobile Augmented Reality",type:n},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3550291\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2301.06184.pdf\",\"Slides\":\"https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1wrHaZorkVvMyE2NENwS43vlrEm2Vt4iaAH3X-wsYBuE\u002Fedit?usp=sharing\",\"Code (coming soon)\":\"\u002Fproject\u002Flitar\u002F\",\"Project\":\"\u002Fproject\u002Flitar\u002F\"}",":authors":"[\"Yiqin Zhao\",\"Chongyang Ma\",\"Haibin Huang\",\"Tian Guo\"]",":venue":"{\"acronym\":\"IMWUT\",\"year\":2022,\"name\":\"The Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies\"}",thumbnail:"litar-ubicomp22.png",title:"LitAR: Visually Coherent Lighting for Mobile Augmented Reality",type:K},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002Fabs\u002F10.1145\u002F3503161.3548386\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2207.03056\",\"Slides\":\"https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1goYpS9PXr0YLLPQUJcF9P-q8n0iV1A1UvReFDSuV3dk\u002Fedit?usp=sharing\",\"Project\":\"\u002Fproject\u002Fprivacy-preserving-reflection\"}",":authors":"[\"Yiqin Zhao\",\"Sheng Wei\",\"Tian Guo\"]",":venue":"{\"acronym\":\"ACMMM\",\"year\":2022,\"name\":\"30th ACM International Conference on Multimedia\"}",thumbnail:"privacy-preserving-reflection.png",title:L,type:n},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fieeexplore.ieee.org\u002Fdocument\u002F9757380\",\"Poster\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1HeFelhKlv2ZXxKI-hCxk4pI_4-v_26KA\u002Fview?usp=sharing\"}",":authors":v,":venue":"{\"acronym\":\"IEEEVRW\",\"year\":2022,\"name\":\"IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\"}",thumbnail:"fusedar-ieeevrw22.png",title:"FusedAR: Adaptive Environment Lighting Reconstruction for Visually Coherent Mobile AR Rendering",type:"workshop"},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fdoi\u002F10.1145\u002F3458864.3467886?cid=99659479290\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2106.15280\",\"Slides\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1iWW6l6XQu_LL-EuA323jecwnVPOa3mWa\u002Fview?usp=sharing\",\"Project\":\"\u002Fproject\u002Fxihe\u002F\"}",":authors":v,":venue":"{\"acronym\":\"MobiSys\",\"year\":2021,\"name\":\"The 19th ACM International Conference on Mobile Systems, Applications, and Services\"}",thumbnail:"xihe-mobisys2021.png",title:"Xihe: a 3D vision-based lighting estimation framework for mobile augmented reality",type:n},children:[{type:a,tag:f,props:{},children:[{type:a,tag:"span",props:{className:["text-red-600"]},children:[{type:a,tag:M,props:{className:["inline","w-4","my-0","mt-[-0.2em]"],src:"https:\u002F\u002Fwww.acm.org\u002Fbinaries\u002Fcontent\u002Fgallery\u002Facm\u002Fpublications\u002Freplication-badges\u002Fartifacts_evaluated_functional_dl.jpg"},children:[]},{type:b,value:" Artifacts Evaluated ‚Äì Functional v1.1"}]}]}]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.00006\",\"arXiv\":\"https:\u002F\u002Farxiv.org\u002Fabs\u002F2004.00006\",\"Slides\":\"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1NUHDf3uxNuXwvqFjXw6BGFADgQdOc9tp\u002Fview?usp=sharing\",\"Project\":\"\u002Fproject\u002Fpoint-ar\u002F\"}",":authors":v,":venue":"{\"acronym\":\"ECCV\",\"year\":2020,\"name\":\"16th European Conference on Computer Vision\"}",thumbnail:"pointar-eccv.png",title:"PointAR: Efficient Lighting Estimation for Mobile Augmented Reality",type:n},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fieeexplore.ieee.org\u002Fstamp\u002Fstamp.jsp?arnumber=8762126\",\"Project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Zhongtian Bao\",\"Yiqin Zhao\",\"Zixing Zhang\",\"Nicholas Cummins\",\"Zhao Ren\",\"Bj√∂rn Schuller\"]",":venue":"{\"acronym\":\"Access\",\"year\":2019,\"name\":\"IEEE Access\"}",thumbnail:"deep-spectrum-ieee.png",title:"Exploring Deep Spectrum Representations via Attention-Based Recurrent and Convolutional Neural Networks for Speech Emotion Recognition",type:K},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fdl.acm.org\u002Fcitation.cfm?doid=3267935.3267948\",\"Project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Yiqin Zhao\",\"Zhongtian Bao\",\"Haishuai Wang\",\"Zixing Zhang\",\"Chao Li\"]",":venue":"{\"acronym\":\"ASMMC-MMAC\",\"year\":2018,\"name\":\"4th Workshop on Affective Social Multimedia Computing and first Multi-Modal Affective Computing of Large-Scale Multimedia Data\"}",thumbnail:"deep-spectrum-acmmm.png",title:"Deep Spectrum Feature Representations for Speech Emotion Recognition",type:n},children:[]},{type:a,tag:k,props:{":artifactLinks":"{\"Paper\":\"https:\u002F\u002Fwww.isca-speech.org\u002Farchive_v0\u002FInterspeech_2018\u002Fabstracts\u002F1477.html\",\"Project\":\"\u002Fproject\u002Fdeep-spectrum\u002F\"}",":authors":"[\"Ziping Zhao\",\"Yu Zheng\",\"Zixing Zhang\",\"Haishuai Wang\",\"Yiqin Zhao\",\"Chao Li\"]",":venue":"{\"acronym\":\"INTERSPEECH\",\"year\":2018,\"name\":\"Annual Conference of the International Speech Communication Association\"}",thumbnail:"deep-spectrum-interspeech.png",title:"Exploring Spatio-Temporal Representations by Integrating Attention-based Bidirectional-LSTM-RNNs and FCNs for Speech Emotion Recognition",type:n,":hideBottomBorder":"true"},children:[]},{type:a,tag:m,props:{id:N},children:[{type:b,value:O}]},{type:a,tag:f,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Academic services"}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:"UbiComp 2022 student volunteer."}]}]},{type:a,tag:f,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"Awards"}]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:"ACM HotMobile 2023 Student Travel Grant."}]},{type:a,tag:c,props:{},children:[{type:b,value:"ACM HotMobile 2020 Student Travel Grant."}]},{type:a,tag:c,props:{},children:[{type:b,value:"China Collegiate Computing Contest, jointly held by Tsinghua University, Zhejiang University and Apple, Inc."},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:"2017 national third prize, top 6%"}]},{type:a,tag:c,props:{},children:[{type:b,value:"2016 national third prize, top 10%"}]}]}]},{type:a,tag:c,props:{},children:[{type:b,value:"University Scholarship, Tianjin Normal University"},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:b,value:"2018 - 2019 academic first grade scholarship, top 10%"}]},{type:a,tag:c,props:{},children:[{type:b,value:"Wang Kechang Culture and Technology Innovation Scholarship, ‚â§ 1%"}]},{type:a,tag:c,props:{},children:[{type:b,value:"2017 - 2018 academic year top grade scholarship, top 5%"}]},{type:a,tag:c,props:{},children:[{type:b,value:"2016 - 2017 academic year second grade scholarship, top 20%"}]},{type:a,tag:c,props:{},children:[{type:b,value:"2015 - 2016 academic year first grade scholarship, top 10%"}]}]}]}]},{type:a,tag:m,props:{id:P},children:[{type:b,value:Q}]},{type:a,tag:q,props:{icon:"email",url:"mailto:yiqinzhao@outlook.com"},children:[{type:a,tag:f,props:{},children:[{type:b,value:"Email"}]}]},{type:a,tag:q,props:{icon:"github",url:"https:\u002F\u002Fgithub.com\u002FYiqinZhao"},children:[{type:a,tag:f,props:{},children:[{type:b,value:w}]}]},{type:a,tag:q,props:{icon:"twitter",url:"https:\u002F\u002Ftwitter.com\u002Fyiqin_zhao"},children:[{type:a,tag:f,props:{},children:[{type:b,value:"Twitter"}]}]},{type:a,tag:q,props:{icon:"instagram",url:"https:\u002F\u002Fwww.instagram.com\u002Fyiqinzhao1996"},children:[{type:a,tag:f,props:{},children:[{type:b,value:"Instagram"}]}]}],toc:{title:j,searchDepth:i,depth:i,links:[{id:A,depth:i,text:B},{id:E,depth:i,text:F},{id:G,depth:i,text:H},{id:I,depth:i,text:J},{id:N,depth:i,text:O},{id:P,depth:i,text:Q}]}},_type:R,_id:"content:index.md",_source:S,_file:"index.md",_extension:T},"content-query-B6mqoO8PxR":{_path:"\u002Fnews",_dir:j,_draft:l,_partial:l,_locale:j,_empty:l,title:U,description:j,leadingImage:"me-news-google.png",disableFancyImage:r,body:{type:z,children:[{type:a,tag:"markdown-header",props:{subtitle:"üì¢ Latest: I'm a Ph.D. candidate now!",title:U},children:[]},{type:a,tag:f,props:{},children:[{type:a,tag:M,props:{alt:j,src:"\u002Fassets\u002Fimg\u002Fme-news-google.png"},children:[]}]},{type:a,tag:p,props:{},children:[{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:V}]},{type:b,value:" üéâ Received student travel grant from HotMobile 2023, thank you!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:V}]},{type:b,value:" üéâ Passed my classes and research qualifications, I'm a Ph.D. candidate now!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"12\u002F09\u002F2022"}]},{type:b,value:" üéâ One paper accepted by HotMobile 2023!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:W}]},{type:b,value:X},{type:a,tag:e,props:{href:u,rel:[g]},children:[{type:b,value:x}]},{type:b,value:Y}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:Z}]},{type:b,value:_},{type:a,tag:e,props:{href:"\u002Fproject\u002Flitar"},children:[{type:b,value:"LitAR"}]},{type:b,value:" is accepted by UbiComp 2022!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:Z}]},{type:b,value:_},{type:a,tag:e,props:{href:"\u002Fproject\u002Fprivacy-preserving-reflection"},children:[{type:b,value:L}]},{type:b,value:" is accepted by ACM MM 2022!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"03\u002F04\u002F2022"}]},{type:b,value:" üéâ I will join Google as a research intern in the summer!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:W}]},{type:b,value:X},{type:a,tag:e,props:{href:u,rel:[g]},children:[{type:b,value:x}]},{type:b,value:Y}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"05\u002F24\u002F2021"}]},{type:b,value:" ‚ú® We just released the "},{type:a,tag:e,props:{href:$},children:[{type:b,value:"Xihe"}]},{type:b,value:" source code! Check our "},{type:a,tag:e,props:{href:"https:\u002F\u002Fgithub.com\u002Fcake-lab\u002FXihe",rel:[g]},children:[{type:b,value:w}]},{type:b,value:aa}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:y}]},{type:b,value:" üéâ I will join the "},{type:a,tag:e,props:{href:"http:\u002F\u002Fchongyangma.com\u002Fteam\u002Findex.html",rel:[g]},children:[{type:b,value:x}]},{type:b,value:" as a research intern in next spring!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:y}]},{type:b,value:" üéâ I'm thrilled to announce that I will continue my Ph.D. study at "},{type:a,tag:e,props:{href:"https:\u002F\u002Fcake.wpi.edu\u002F",rel:[g]},children:[{type:b,value:C}]},{type:b,value:" with "},{type:a,tag:e,props:{href:s,rel:[g]},children:[{type:b,value:t}]},{type:b,value:D}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:y}]},{type:b,value:" üéâ I've presented my M.S. Thesis."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"04\u002F03\u002F2021"}]},{type:b,value:" ‚ú® "},{type:a,tag:e,props:{href:$},children:[{type:b,value:"PointAR"}]},{type:b,value:" source code is now released! Check our "},{type:a,tag:e,props:{href:"https:\u002F\u002Fgithub.com\u002Fcake-lab\u002FPointAR",rel:[g]},children:[{type:b,value:w}]},{type:b,value:aa}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"03\u002F25\u002F2021"}]},{type:b,value:" üî• New paper on mobile system for 3D vision-based lighting estimation has been conditionally accepted to MobiSys 2021."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"08\u002F25\u002F2020"}]},{type:b,value:" üéôÔ∏è I presented our efficient mobile AR lighting estimation paper at ECCV 2020."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"07\u002F22\u002F2020"}]},{type:b,value:" üî• Our paper on efficient mobile AR lighting estimation neural network has been accepted to ECCV 2020."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"03\u002F03\u002F2020"}]},{type:b,value:" üéôÔ∏è I presented my poster at the HotMobile 2020 conference in Austin, TX."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"02\u002F01\u002F2020"}]},{type:b,value:" üî• Our poster on mobile AR lighting estimation has been accepted to HotMobile 2020."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"08\u002F26\u002F2019"}]},{type:b,value:" ü¶∏üèª‚Äç‚ôÇÔ∏è I joined Worcester Polytechnic Institute CakeLab."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"10\u002F26\u002F2018"}]},{type:b,value:" üéôÔ∏è I presented our paper on ASMMC-MMAC 2018 workshop."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"10\u002F15\u002F2018"}]},{type:b,value:" üèÜ I received Wang Kechang Technology innovation scholarship (\u003C1%)."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"10\u002F13\u002F2018"}]},{type:b,value:" üèÜ I received annual special scholarship at Tianjin Normal University (top 5%)."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"08\u002F15\u002F2018"}]},{type:b,value:" üî• Our paper about human speech emotion in spectrogram representation has submitted to ACM Multimedia 2018 ASMMC-MMAC workshop!"}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"07\u002F04\u002F2018"}]},{type:b,value:" üë®üèª‚Äçüíª I joined the DuerOS department at Baidu, Inc as a frontend software engineer intern."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"09\u002F30\u002F2017"}]},{type:b,value:" üèÜ Ô£ø I received third prize of the 2017 China national Mobile Innovation Contest (top 6%)."}]},{type:a,tag:c,props:{},children:[{type:a,tag:d,props:{},children:[{type:b,value:"09\u002F30\u002F2016"}]},{type:b,value:" üèÜ Ô£ø I received third prize of the 2016 China national Mobile Innovation Contest (top 10%)."}]}]}],toc:{title:j,searchDepth:i,depth:i,links:[]}},_type:R,_id:"content:news.md",_source:S,_file:"news.md",_extension:T}},prerenderedAt:void 0}}("element","text","li","strong","a","p","nofollow","br",2,"","publication-row",false,"h2","conference","experience-row","ul","contact-item",true,"https:\u002F\u002Ftianguo.info","Prof. Tian Guo","http:\u002F\u002Fwww.chongyangma.com\u002Fteam\u002Findex.html","[\"Yiqin Zhao\",\"Tian Guo\"]","GitHub","Y-tech Graphics AI team","04\u002F15\u002F2021","root","Ô∏è-about-me","ü¶∏üèª‚Äç‚ôÇÔ∏è About Me","The Cake Lab",".","news","üì∞ News","experiences","ü•∑ Experiences","publications","üìÑ Publications","journal","Privacy-preserving Reflection Rendering for Augmented Reality","img","Ô∏è-services-and-awards","‚ù§Ô∏è Services and Awards","find-me","üìß Find Me","markdown","content","md","News","12\u002F15\u002F2022","01\u002F18\u002F2022"," üéâ I joined the "," as a research intern.","05\u002F17\u002F2022"," üéâ Our paper ","\u002Fproject\u002Fpoint-ar"," repo."))